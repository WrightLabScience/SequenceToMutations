
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | p4_out/07_error_calibration/80.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | p4_out/output/calibration/80.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00331862 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 8 to 26.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  19.80645  Size:  10000 
8   26 
19.80645   10000 
8   26 
19.80645   10000 
8   26 
19.80647   10000 
8   26 
19.80645   10000.01 
8   26 
19.80809   10000 
8   26 
19.80811   10000 
8   26 
19.80809   10000.01 
8   26 
20.17578   10000 
8   26 
20.1758   10000 
8   26 
20.17578   10000.01 
8   26 
20.19107   10000 
8   26 
20.19109   10000 
8   26 
20.19107   10000.01 
8   26 
20.19176   10000 
8   26 
20.19179   10000 
8   26 
20.19176   10000.01 
8   26 
20.19177   10000 
8   26 
20.19179   10000 
8   26 
20.19177   10000.01 
Fit Mean:  20.19177  Size:  10000  Code:  2 
Try Mean:  19.80645  Size:  1000 
8   26 
19.80645   1000 
8   26 
19.80645   1000 
8   26 
19.80647   1000 
8   26 
19.80645   1000.001 
8   26 
19.80823   1000 
8   26 
19.80825   1000 
8   26 
19.80823   1000.001 
8   26 
20.21576   1000 
8   26 
20.21578   1000 
8   26 
20.21576   1000.001 
8   26 
20.23439   1000 
8   26 
20.23441   1000 
8   26 
20.23439   1000.001 
8   26 
20.23533   1000 
8   26 
20.23535   1000 
8   26 
20.23533   1000.001 
8   26 
20.23534   1000 
8   26 
20.23536   1000 
8   26 
20.23534   1000.001 
Fit Mean:  20.23534  Size:  1000  Code:  2 
Try Mean:  19.80645  Size:  100 
8   26 
19.80645   100 
8   26 
19.80645   100 
8   26 
19.80647   100 
8   26 
19.80645   100.0001 
8   26 
19.8093   100 
8   26 
19.80932   100 
8   26 
19.8093   100.0001 
8   26 
20.59992   100.0125 
8   26 
20.59994   100.0125 
8   26 
20.59992   100.0126 
8   26 
20.66615   100.018 
8   26 
20.66617   100.018 
8   26 
20.66615   100.0181 
8   26 
20.67317   100.023 
8   26 
20.67319   100.023 
8   26 
20.67317   100.0231 
8   26 
20.67648   100.0318 
8   26 
20.6765   100.0318 
8   26 
20.67648   100.0319 
8   26 
20.68634   100.0843 
8   26 
20.68636   100.0843 
8   26 
20.68634   100.0844 
8   26 
20.69913   100.2139 
8   26 
20.69915   100.2139 
8   26 
20.69913   100.214 
8   26 
20.72049   100.6038 
8   26 
20.72051   100.6038 
8   26 
20.72049   100.6039 
8   26 
20.75109   101.6223 
8   26 
20.75111   101.6223 
8   26 
20.75109   101.6224 
8   26 
20.79246   104.289 
8   26 
20.79249   104.289 
8   26 
20.79246   104.2891 
8   26 
20.83574   110.8862 
8   26 
20.83576   110.8862 
8   26 
20.83574   110.8863 
8   26 
20.85108   126.7987 
8   26 
20.8511   126.7987 
8   26 
20.85108   126.7988 
8   26 
20.76259   165.8827 
8   26 
20.76261   165.8827 
8   26 
20.76259   165.8828 
8   26 
20.44947   254.4702 
8   26 
20.44949   254.4702 
8   26 
20.44947   254.4705 
8   26 
20.2149   330.3851 
8   26 
20.21492   330.3851 
8   26 
20.2149   330.3854 
8   26 
20.19827   355.0885 
8   26 
20.19829   355.0885 
8   26 
20.19827   355.0888 
8   26 
20.21339   491.0793 
8   26 
20.21341   491.0793 
8   26 
20.21339   491.0798 
8   26 
20.24477   625.7231 
8   26 
20.24479   625.7231 
8   26 
20.24477   625.7237 
8   26 
20.2494   821.2987 
8   26 
20.24942   821.2987 
8   26 
20.2494   821.2995 
8   26 
20.23086   1086.855 
8   26 
20.23088   1086.855 
8   26 
20.23086   1086.857 
8   26 
20.21043   1442.945 
8   26 
20.21045   1442.945 
8   26 
20.21043   1442.946 
8   26 
20.20006   1904.229 
8   26 
20.20008   1904.229 
8   26 
20.20006   1904.231 
8   26 
20.1975   2517.145 
8   26 
20.19752   2517.145 
8   26 
20.1975   2517.148 
8   26 
20.19703   3327.909 
8   26 
20.19705   3327.909 
8   26 
20.19703   3327.912 
8   26 
20.19557   4403.684 
8   26 
20.19559   4403.684 
8   26 
20.19557   4403.688 
8   26 
20.19332   5831.252 
8   26 
20.19334   5831.252 
8   26 
20.19332   5831.258 
8   26 
20.19134   7722.376 
8   26 
20.19136   7722.376 
8   26 
20.19134   7722.384 
8   26 
20.19007   10226.67 
8   26 
20.19009   10226.67 
8   26 
20.19007   10226.68 
8   26 
20.18933   13543.92 
8   26 
20.18935   13543.92 
8   26 
20.18933   13543.93 
8   26 
20.18881   17936.45 
8   26 
20.18883   17936.45 
8   26 
20.18881   17936.47 
8   26 
20.18839   23753 
8   26 
20.18841   23753 
8   26 
20.18839   23753.03 
8   26 
20.18802   31470.17 
8   26 
20.18804   31470.17 
8   26 
20.18802   31470.2 
8   26 
20.18774   41661.88 
8   26 
20.18776   41661.88 
8   26 
20.18774   41661.92 
8   26 
20.18753   55195.2 
8   26 
20.18755   55195.2 
8   26 
20.18753   55195.26 
8   26 
20.18738   73223.72 
8   26 
20.1874   73223.72 
8   26 
20.18738   73223.79 
8   26 
20.18727   97006.29 
8   26 
20.18729   97006.29 
8   26 
20.18727   97006.39 
8   26 
20.18719   128799.4 
8   26 
20.18721   128799.4 
8   26 
20.18719   128799.5 
8   26 
20.18713   168913.9 
8   26 
20.18715   168913.9 
8   26 
20.18713   168914 
8   26 
20.18707   230007 
8   26 
20.18709   230007 
8   26 
20.18707   230007.2 
8   26 
20.18704   296604.6 
8   26 
20.18706   296604.6 
8   26 
20.18704   296604.9 
8   26 
20.18701   398547.2 
8   26 
20.18703   398547.2 
8   26 
20.18701   398547.6 
8   26 
20.187   500489.9 
8   26 
20.18702   500489.9 
8   26 
20.187   500490.4 
8   26 
20.18698   602432.5 
8   26 
20.187   602432.5 
8   26 
20.18698   602433.1 
8   26 
20.18699   694115.8 
8   26 
20.18701   694115.8 
8   26 
20.18699   694116.4 
Fit Mean:  20.18699  Size:  694115.8  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  20.18699  Size:  694115.8  Code:  1  Try Size:  100 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
8 26
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
694115.8   20.18699 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 694115.8
> print(nb_fit_mu);
[1] 20.18699
> 
> print(m)
[1] 22
> print(v)
[1] 28.65
> print(D)
[1] 1.302273
> 
> print(deletion_propagation_coverage)
[1] 9
> 
> warnings()
> 

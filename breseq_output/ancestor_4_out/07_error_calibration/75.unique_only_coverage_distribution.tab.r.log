
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | p4_out/07_error_calibration/75.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | p4_out/output/calibration/75.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00310685 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 7 to 23.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  16.84615  Size:  10000 
7   23 
16.84615   10000 
7   23 
16.84615   10000 
7   23 
16.84617   10000 
7   23 
16.84615   10000.01 
7   23 
16.84534   10000 
7   23 
16.84536   10000 
7   23 
16.84534   10000.01 
7   23 
16.6945   10000 
7   23 
16.69452   10000 
7   23 
16.6945   10000.01 
7   23 
16.69717   10000 
7   23 
16.69719   10000 
7   23 
16.69717   10000.01 
7   23 
16.69713   10000 
7   23 
16.69714   10000 
7   23 
16.69713   10000.01 
7   23 
16.69713   10000 
7   23 
16.69879   10000 
7   23 
16.69546   10000 
7   23 
16.69713   10001 
7   23 
16.69713   9999 
7   23 
16.69713   10000 
7   23 
16.6988   10000 
7   23 
16.69546   10000 
7   23 
16.69713   10001 
7   23 
16.69713   9999 
Fit Mean:  16.69713  Size:  10000  Code:  2 
Try Mean:  16.84615  Size:  1000 
7   23 
16.84615   1000 
7   23 
16.84615   1000 
7   23 
16.84617   1000 
7   23 
16.84615   1000.001 
7   23 
16.84548   1000 
7   23 
16.8455   1000 
7   23 
16.84548   1000.001 
7   23 
16.71866   1000 
7   23 
16.71867   1000 
7   23 
16.71866   1000.001 
7   23 
16.72054   1000 
7   23 
16.72056   1000 
7   23 
16.72054   1000.001 
7   23 
16.72052   1000 
7   23 
16.72053   1000 
7   23 
16.72052   1000.001 
7   23 
16.72047   1000 
7   23 
16.72049   1000 
7   23 
16.72047   1000.001 
7   23 
16.72041   1000.001 
7   23 
16.72042   1000.001 
7   23 
16.72041   1000.002 
7   23 
16.7203   1000.002 
7   23 
16.72032   1000.002 
7   23 
16.7203   1000.003 
7   23 
16.72012   1000.006 
7   23 
16.72014   1000.006 
7   23 
16.72012   1000.007 
7   23 
16.71984   1000.016 
7   23 
16.71985   1000.016 
7   23 
16.71984   1000.017 
7   23 
16.71938   1000.042 
7   23 
16.71939   1000.042 
7   23 
16.71938   1000.043 
7   23 
16.71863   1000.114 
7   23 
16.71864   1000.114 
7   23 
16.71863   1000.115 
7   23 
16.71742   1000.301 
7   23 
16.71743   1000.301 
7   23 
16.71742   1000.302 
7   23 
16.71546   1000.794 
7   23 
16.71547   1000.794 
7   23 
16.71546   1000.795 
7   23 
16.71228   1002.086 
7   23 
16.7123   1002.086 
7   23 
16.71228   1002.087 
7   23 
16.70717   1005.459 
7   23 
16.70718   1005.459 
7   23 
16.70717   1005.46 
7   23 
16.69902   1014.184 
7   23 
16.69904   1014.184 
7   23 
16.69902   1014.185 
7   23 
16.6865   1036.284 
7   23 
16.68652   1036.284 
7   23 
16.6865   1036.285 
7   23 
16.66891   1089.703 
7   23 
16.66893   1089.703 
7   23 
16.66891   1089.704 
7   23 
16.64897   1208.393 
7   23 
16.64899   1208.393 
7   23 
16.64897   1208.395 
7   23 
16.6361   1446.904 
7   23 
16.63611   1446.904 
7   23 
16.6361   1446.906 
7   23 
16.64559   1879.329 
7   23 
16.64561   1879.329 
7   23 
16.64559   1879.331 
7   23 
16.67947   2514.536 
7   23 
16.67949   2514.536 
7   23 
16.67947   2514.538 
7   23 
16.70892   3212.985 
7   23 
16.70894   3212.985 
7   23 
16.70892   3212.989 
7   23 
16.72267   3948.664 
7   23 
16.72268   3948.664 
7   23 
16.72267   3948.667 
7   23 
16.72531   5021.862 
7   23 
16.72533   5021.862 
7   23 
16.72531   5021.867 
7   23 
16.71563   6707.396 
7   23 
16.71565   6707.396 
7   23 
16.71563   6707.403 
7   23 
16.6998   8956.73 
7   23 
16.69982   8956.73 
7   23 
16.6998   8956.739 
7   23 
16.68858   11483.38 
7   23 
16.6886   11483.38 
7   23 
16.68858   11483.39 
7   23 
16.68376   14557.66 
7   23 
16.68378   14557.66 
7   23 
16.68376   14557.67 
7   23 
16.68476   19052.22 
7   23 
16.68478   19052.22 
7   23 
16.68476   19052.24 
7   23 
16.69045   25387.78 
7   23 
16.69047   25387.78 
7   23 
16.69045   25387.8 
7   23 
16.69637   33289.88 
7   23 
16.69639   33289.88 
7   23 
16.69637   33289.91 
7   23 
16.69965   42867.3 
7   23 
16.69967   42867.3 
7   23 
16.69965   42867.34 
7   23 
16.70007   55879.85 
7   23 
16.70009   55879.85 
7   23 
16.70007   55879.9 
7   23 
16.698   74293.41 
7   23 
16.69801   74293.41 
7   23 
16.698   74293.48 
7   23 
16.695   98549.28 
7   23 
16.69502   98549.28 
7   23 
16.695   98549.37 
7   23 
16.69287   128382.7 
7   23 
16.69289   128382.7 
7   23 
16.69287   128382.9 
7   23 
16.69208   168041.4 
7   23 
16.69209   168041.4 
7   23 
16.69208   168041.6 
7   23 
16.69262   221192.6 
7   23 
16.69264   221192.6 
7   23 
16.69262   221192.8 
7   23 
16.69391   288480.6 
7   23 
16.69393   288480.6 
7   23 
16.69391   288480.9 
7   23 
16.69521   385043.1 
7   23 
16.69523   385043.1 
7   23 
16.69521   385043.4 
7   23 
16.69589   515580.8 
7   23 
16.69591   515580.8 
7   23 
16.69589   515581.3 
7   23 
16.69577   680593.7 
7   23 
16.69579   680593.7 
7   23 
16.69577   680594.4 
7   23 
16.69515   851205.2 
7   23 
16.69517   851205.2 
7   23 
16.69515   851206 
7   23 
16.6941   1243542 
7   23 
16.69411   1243542 
7   23 
16.6941   1243543 
7   23 
16.69399   1452452 
7   23 
16.694   1452452 
7   23 
16.69399   1452454 
7   23 
16.69378   1762399 
7   23 
16.69379   1762399 
7   23 
16.69378   1762400 
7   23 
16.69334   2285535 
7   23 
16.69336   2285535 
7   23 
16.69334   2285537 
7   23 
16.69364   2817710 
7   23 
16.69365   2817710 
7   23 
16.69364   2817713 
7   23 
16.69374   3475223 
7   23 
16.69376   3475223 
7   23 
16.69374   3475226 
7   23 
16.69411   3471557 
7   23 
16.69412   3471557 
7   23 
16.69411   3471560 
7   23 
16.73148   3958709 
7   23 
16.69784   3520272 
7   23 
16.69477   3480259 
7   23 
16.69479   3480259 
7   23 
16.69477   3480262 
7   23 
16.69461   3481366 
7   23 
16.69462   3481366 
7   23 
16.69461   3481369 
7   23 
16.69437   3479183 
7   23 
16.69453   3480638 
7   23 
16.69457   3481028 
7   23 
16.69459   3481028 
7   23 
16.69457   3481031 
7   23 
16.69453   3480991 
7   23 
16.69455   3480991 
7   23 
16.69453   3480995 
Fit Mean:  16.69453  Size:  3480991  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  16.69453  Size:  3480991  Code:  1  Try Size:  1000 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
7 23
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
3480991   16.69453 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 3480991
> print(nb_fit_mu);
[1] 16.69453
> 
> print(m)
[1] 17.50505
> print(v)
[1] 12.59946
> print(D)
[1] 0.7197616
> 
> print(deletion_propagation_coverage)
[1] 7
> 
> warnings()
> 

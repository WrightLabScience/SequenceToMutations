
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | p4_out/07_error_calibration/74.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | p4_out/output/calibration/74.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00301511 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 23 to 51.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  35.93659  Size:  10000 
23   51 
35.93659   10000 
23   51 
35.93659   10000 
23   51 
35.93662   10000 
23   51 
35.93659   10000.01 
23   51 
35.94166   10000 
23   51 
35.9417   10000 
23   51 
35.94166   10000.01 
23   51 
35.94673   10000 
23   51 
35.94677   10000 
23   51 
35.94673   10000.01 
23   51 
35.95181   10000 
23   51 
35.95184   10000 
23   51 
35.95181   10000.01 
23   51 
35.95688   10000 
23   51 
35.95692   10000 
23   51 
35.95688   10000.01 
23   51 
35.96196   10000 
23   51 
35.96199   10000 
23   51 
35.96196   10000.01 
23   51 
35.96703   10000 
23   51 
35.96707   10000 
23   51 
35.96703   10000.01 
23   51 
35.97211   10000 
23   51 
35.97215   10000 
23   51 
35.97211   10000.01 
23   51 
35.97718   10000 
23   51 
35.97722   10000 
23   51 
35.97718   10000.01 
23   51 
35.98226   10000 
23   51 
35.9823   10000 
23   51 
35.98226   10000.01 
23   51 
35.98734   10000 
23   51 
35.98737   10000 
23   51 
35.98734   10000.01 
23   51 
35.99241   10000 
23   51 
35.99245   10000 
23   51 
35.99241   10000.01 
23   51 
35.99749   10000 
23   51 
35.99752   10000 
23   51 
35.99749   10000.01 
23   51 
36.00256   10000 
23   51 
36.0026   10000 
23   51 
36.00256   10000.01 
23   51 
36.00764   10000 
23   51 
36.00768   10000 
23   51 
36.00764   10000.01 
23   51 
36.01272   10000 
23   51 
36.01275   10000 
23   51 
36.01272   10000.01 
23   51 
36.01779   10000 
23   51 
36.01783   10000 
23   51 
36.01779   10000.01 
23   51 
36.02287   10000 
23   51 
36.02291   10000 
23   51 
36.02287   10000.01 
23   51 
36.02795   10000 
23   51 
36.02798   10000 
23   51 
36.02795   10000.01 
23   51 
36.03302   10000 
23   51 
36.03306   10000 
23   51 
36.03302   10000.01 
23   51 
36.0381   10000 
23   51 
36.03814   10000 
23   51 
36.0381   10000.01 
23   51 
36.04318   10000 
23   51 
36.04322   10000 
23   51 
36.04318   10000.01 
23   51 
36.04826   10000 
23   51 
36.04829   10000 
23   51 
36.04826   10000.01 
23   51 
36.05333   10000 
23   51 
36.05337   10000 
23   51 
36.05333   10000.01 
23   51 
36.05841   10000 
23   51 
36.05845   10000 
23   51 
36.05841   10000.01 
23   51 
36.06349   10000 
23   51 
36.06353   10000 
23   51 
36.06349   10000.01 
23   51 
36.06857   10000 
23   51 
36.0686   10000 
23   51 
36.06857   10000.01 
23   51 
36.07365   10000 
23   51 
36.07368   10000 
23   51 
36.07365   10000.01 
23   51 
36.07872   10000 
23   51 
36.07876   10000 
23   51 
36.07872   10000.01 
23   51 
36.0838   10000 
23   51 
36.08384   10000 
23   51 
36.0838   10000.01 
23   51 
36.08888   10000 
23   51 
36.08892   10000 
23   51 
36.08888   10000.01 
23   51 
36.09396   10000 
23   51 
36.094   10000 
23   51 
36.09396   10000.01 
23   51 
36.09904   10000 
23   51 
36.09908   10000 
23   51 
36.09904   10000.01 
23   51 
36.10412   10000 
23   51 
36.10415   10000 
23   51 
36.10412   10000.01 
23   51 
36.1092   10000 
23   51 
36.10923   10000 
23   51 
36.1092   10000.01 
23   51 
36.11428   10000 
23   51 
36.11431   10000 
23   51 
36.11428   10000.01 
23   51 
36.11936   10000 
23   51 
36.11939   10000 
23   51 
36.11936   10000.01 
23   51 
36.12444   10000 
23   51 
36.12447   10000 
23   51 
36.12444   10000.01 
23   51 
36.12952   10000 
23   51 
36.12955   10000 
23   51 
36.12952   10000.01 
23   51 
36.1346   10000 
23   51 
36.13463   10000 
23   51 
36.1346   10000.01 
23   51 
36.13968   10000 
23   51 
36.13971   10000 
23   51 
36.13968   10000.01 
23   51 
36.14476   10000 
23   51 
36.14479   10000 
23   51 
36.14476   10000.01 
23   51 
36.14984   10000 
23   51 
36.14987   10000 
23   51 
36.14984   10000.01 
23   51 
36.15492   10000 
23   51 
36.15495   10000 
23   51 
36.15492   10000.01 
23   51 
36.16   10000 
23   51 
36.16003   10000 
23   51 
36.16   10000.01 
23   51 
36.16508   10000 
23   51 
36.16511   10000 
23   51 
36.16508   10000.01 
23   51 
36.17016   10000 
23   51 
36.17019   10000 
23   51 
36.17016   10000.01 
23   51 
36.17524   10000 
23   51 
36.17527   10000 
23   51 
36.17524   10000.01 
23   51 
36.18032   10000 
23   51 
36.18036   10000 
23   51 
36.18032   10000.01 
23   51 
36.1854   10000 
23   51 
36.18544   10000 
23   51 
36.1854   10000.01 
23   51 
36.19048   10000 
23   51 
36.19052   10000 
23   51 
36.19048   10000.01 
23   51 
36.19556   10000 
23   51 
36.1956   10000 
23   51 
36.19556   10000.01 
23   51 
36.20064   10000 
23   51 
36.20068   10000 
23   51 
36.20064   10000.01 
23   51 
36.20573   10000 
23   51 
36.20576   10000 
23   51 
36.20573   10000.01 
23   51 
36.21081   10000 
23   51 
36.21084   10000 
23   51 
36.21081   10000.01 
23   51 
36.21589   10000 
23   51 
36.21592   10000 
23   51 
36.21589   10000.01 
23   51 
36.22097   10000 
23   51 
36.22101   10000 
23   51 
36.22097   10000.01 
23   51 
36.22605   10000 
23   51 
36.22609   10000 
23   51 
36.22605   10000.01 
23   51 
36.23113   10000 
23   51 
36.23117   10000 
23   51 
36.23113   10000.01 
23   51 
36.23622   10000 
23   51 
36.23625   10000 
23   51 
36.23622   10000.01 
23   51 
36.2413   10000 
23   51 
36.24133   10000 
23   51 
36.2413   10000.01 
23   51 
36.24638   10000 
23   51 
36.24642   10000 
23   51 
36.24638   10000.01 
23   51 
36.25146   10000 
23   51 
36.2515   10000 
23   51 
36.25146   10000.01 
23   51 
36.25655   10000 
23   51 
36.25658   10000 
23   51 
36.25655   10000.01 
23   51 
36.26163   10000 
23   51 
36.26166   10000 
23   51 
36.26163   10000.01 
23   51 
36.26671   10000 
23   51 
36.26675   10000 
23   51 
36.26671   10000.01 
23   51 
36.27179   10000 
23   51 
36.27183   10000 
23   51 
36.27179   10000.01 
23   51 
36.27688   10000 
23   51 
36.27691   10000 
23   51 
36.27688   10000.01 
23   51 
36.28196   10000 
23   51 
36.282   10000 
23   51 
36.28196   10000.01 
23   51 
36.28704   10000 
23   51 
36.28708   10000 
23   51 
36.28704   10000.01 
23   51 
36.29213   10000 
23   51 
36.29216   10000 
23   51 
36.29213   10000.01 
23   51 
36.29721   10000 
23   51 
36.29725   10000 
23   51 
36.29721   10000.01 
23   51 
36.30229   10000 
23   51 
36.30233   10000 
23   51 
36.30229   10000.01 
23   51 
36.30738   10000 
23   51 
36.30741   10000 
23   51 
36.30738   10000.01 
23   51 
36.31246   10000 
23   51 
36.3125   10000 
23   51 
36.31246   10000.01 
23   51 
36.31754   10000 
23   51 
36.31758   10000 
23   51 
36.31754   10000.01 
23   51 
36.32263   10000 
23   51 
36.32266   10000 
23   51 
36.32263   10000.01 
23   51 
36.32771   10000 
23   51 
36.32775   10000 
23   51 
36.32771   10000.01 
23   51 
36.33279   10000 
23   51 
36.33283   10000 
23   51 
36.33279   10000.01 
23   51 
36.33788   10000 
23   51 
36.33791   10000 
23   51 
36.33788   10000.01 
23   51 
36.34296   10000 
23   51 
36.343   10000 
23   51 
36.34296   10000.01 
23   51 
36.34805   10000 
23   51 
36.34808   10000 
23   51 
36.34805   10000.01 
23   51 
36.35313   10000 
23   51 
36.35317   10000 
23   51 
36.35313   10000.01 
23   51 
36.35821   10000 
23   51 
36.35825   10000 
23   51 
36.35821   10000.01 
23   51 
36.3633   10000 
23   51 
36.36333   10000 
23   51 
36.3633   10000.01 
23   51 
36.36838   10000 
23   51 
36.36842   10000 
23   51 
36.36838   10000.01 
23   51 
36.37347   10000 
23   51 
36.3735   10000 
23   51 
36.37347   10000.01 
23   51 
36.37855   10000 
23   51 
36.37859   10000 
23   51 
36.37855   10000.01 
23   51 
36.38364   10000 
23   51 
36.38367   10000 
23   51 
36.38364   10000.01 
23   51 
36.38872   10000 
23   51 
36.38876   10000 
23   51 
36.38872   10000.01 
23   51 
36.39381   10000 
23   51 
36.39384   10000 
23   51 
36.39381   10000.01 
23   51 
36.39889   10000 
23   51 
36.39893   10000 
23   51 
36.39889   10000.01 
23   51 
36.40398   10000 
23   51 
36.40401   10000 
23   51 
36.40398   10000.01 
23   51 
36.40906   10000 
23   51 
36.4091   10000 
23   51 
36.40906   10000.01 
23   51 
36.41415   10000 
23   51 
36.41418   10000 
23   51 
36.41415   10000.01 
23   51 
36.41923   10000 
23   51 
36.41927   10000 
23   51 
36.41923   10000.01 
23   51 
36.42432   10000 
23   51 
36.42435   10000 
23   51 
36.42432   10000.01 
23   51 
36.4294   10000 
23   51 
36.42944   10000 
23   51 
36.4294   10000.01 
23   51 
36.43449   10000 
23   51 
36.43452   10000 
23   51 
36.43449   10000.01 
23   51 
36.43957   10000 
23   51 
36.43961   10000 
23   51 
36.43957   10000.01 
23   51 
36.44466   10000 
23   51 
36.44469   10000 
23   51 
36.44466   10000.01 
23   51 
36.44974   10000 
23   51 
36.44978   10000 
23   51 
36.44974   10000.01 
23   51 
36.45483   10000 
23   51 
36.45486   10000 
23   51 
36.45483   10000.01 
23   51 
36.45991   10000 
23   51 
36.45995   10000 
23   51 
36.45991   10000.01 
23   51 
36.465   10000 
23   51 
36.46503   10000 
23   51 
36.465   10000.01 
23   51 
36.47008   10000 
23   51 
36.47012   10000 
23   51 
36.47008   10000.01 
23   51 
36.47517   10000 
23   51 
36.47521   10000 
23   51 
36.47517   10000.01 
23   51 
36.48025   10000 
23   51 
36.48029   10000 
23   51 
36.48025   10000.01 
23   51 
36.48534   10000 
23   51 
36.48538   10000 
23   51 
36.48534   10000.01 
23   51 
36.49043   10000 
23   51 
36.49046   10000 
23   51 
36.49043   10000.01 
23   51 
36.49551   10000 
23   51 
36.49555   10000 
23   51 
36.49551   10000.01 
23   51 
36.5006   10000 
23   51 
36.50063   10000 
23   51 
36.5006   10000.01 
23   51 
36.50568   10000 
23   51 
36.50572   10000 
23   51 
36.50568   10000.01 
23   51 
36.51077   10000 
23   51 
36.51081   10000 
23   51 
36.51077   10000.01 
23   51 
36.51585   10000 
23   51 
36.51589   10000 
23   51 
36.51585   10000.01 
23   51 
36.52094   10000 
23   51 
36.52098   10000 
23   51 
36.52094   10000.01 
23   51 
36.52603   10000 
23   51 
36.52606   10000 
23   51 
36.52603   10000.01 
23   51 
36.53111   10000 
23   51 
36.53115   10000 
23   51 
36.53111   10000.01 
23   51 
36.5362   10000 
23   51 
36.53624   10000 
23   51 
36.5362   10000.01 
23   51 
36.54128   10000 
23   51 
36.54132   10000 
23   51 
36.54128   10000.01 
23   51 
36.54637   10000 
23   51 
36.54641   10000 
23   51 
36.54637   10000.01 
23   51 
36.55146   10000 
23   51 
36.55149   10000 
23   51 
36.55146   10000.01 
23   51 
36.55654   10000 
23   51 
36.55658   10000 
23   51 
36.55654   10000.01 
23   51 
36.56163   10000 
23   51 
36.56167   10000 
23   51 
36.56163   10000.01 
23   51 
36.56671   10000 
23   51 
36.56675   10000 
23   51 
36.56671   10000.01 
23   51 
36.5718   10000 
23   51 
36.57184   10000 
23   51 
36.5718   10000.01 
23   51 
36.57689   10000 
23   51 
36.57692   10000 
23   51 
36.57689   10000.01 
23   51 
36.58197   10000 
23   51 
36.58201   10000 
23   51 
36.58197   10000.01 
23   51 
36.58706   10000 
23   51 
36.5871   10000 
23   51 
36.58706   10000.01 
23   51 
36.59215   10000 
23   51 
36.59218   10000 
23   51 
36.59215   10000.01 
23   51 
36.59723   10000 
23   51 
36.59727   10000 
23   51 
36.59723   10000.01 
23   51 
36.60232   10000 
23   51 
36.60235   10000 
23   51 
36.60232   10000.01 
23   51 
36.6074   10000 
23   51 
36.60744   10000 
23   51 
36.6074   10000.01 
23   51 
36.61249   10000 
23   51 
36.61253   10000 
23   51 
36.61249   10000.01 
23   51 
123165.2   9999.792 
23   51 
12349.47   9999.979 
23   51 
1267.898   9999.998 
23   51 
159.7411   10000 
23   51 
98.12709   10000 
23   51 
48.12495   10000 
23   51 
48.125   10000 
23   51 
48.12495   10000.01 
23   51 
44.91007   10000 
23   51 
44.91011   10000 
23   51 
44.91007   10000.01 
23   51 
45.96862   10000 
23   51 
45.96866   10000 
23   51 
45.96862   10000.01 
23   51 
45.95548   10000 
23   51 
45.95553   10000 
23   51 
45.95548   10000.01 
23   51 
45.95555   10000 
23   51 
45.95559   10000 
23   51 
45.95555   10000.01 
23   51 
45.95555   10000 
23   51 
45.95559   10000 
23   51 
45.95555   10000.01 
Fit Mean:  45.95555  Size:  10000  Code:  2 
Try Mean:  35.93659  Size:  1000 
23   51 
35.93659   1000 
23   51 
35.93659   1000 
23   51 
35.93662   1000 
23   51 
35.93659   1000.001 
23   51 
35.94163   1000 
23   51 
35.94167   1000 
23   51 
35.94163   1000.001 
23   51 
35.94668   1000 
23   51 
35.94672   1000 
23   51 
35.94668   1000.001 
23   51 
35.95173   1000 
23   51 
35.95176   1000 
23   51 
35.95173   1000.001 
23   51 
151756.6   975.0726 
23   51 
15208.01   997.5073 
23   51 
1553.158   999.7507 
23   51 
187.6723   999.9751 
23   51 
111.7604   999.9875 
23   51 
50.68536   999.9976 
23   51 
50.68541   999.9976 
23   51 
50.68536   999.9986 
23   51 
44.4726   999.9986 
23   51 
44.47264   999.9986 
23   51 
44.4726   999.9996 
23   51 
46.12815   999.9983 
23   51 
46.1282   999.9983 
23   51 
46.12815   999.9993 
23   51 
46.0163   999.9983 
23   51 
46.01634   999.9983 
23   51 
46.0163   999.9993 
23   51 
46.01692   999.9983 
23   51 
46.01697   999.9983 
23   51 
46.01692   999.9993 
23   51 
46.01692   999.9983 
23   51 
46.02152   999.9983 
23   51 
46.01232   999.9983 
23   51 
46.01692   1000.098 
23   51 
46.01692   999.8983 
23   51 
46.01694   999.9983 
23   51 
46.02155   999.9983 
23   51 
46.01234   999.9983 
23   51 
46.01694   1000.098 
23   51 
46.01694   999.8983 
Fit Mean:  46.01694  Size:  999.9983  Code:  2 
Try Mean:  35.93659  Size:  100 
23   51 
35.93659   100 
23   51 
35.93659   100 
23   51 
35.93662   100 
23   51 
35.93659   100.0001 
23   51 
35.94123   99.99996 
23   51 
35.94126   99.99996 
23   51 
35.94123   100.0001 
23   51 
58.74814   100.1309 
23   51 
58.7482   100.1309 
23   51 
58.74814   100.131 
23   51 
48.6944   99.44933 
23   51 
48.69445   99.44933 
23   51 
48.6944   99.44943 
23   51 
45.42004   99.45319 
23   51 
45.42008   99.45319 
23   51 
45.42004   99.45329 
23   51 
46.8524   99.44094 
23   51 
46.85245   99.44094 
23   51 
46.8524   99.44104 
23   51 
46.7902   99.44805 
23   51 
46.79024   99.44805 
23   51 
46.7902   99.44815 
23   51 
46.78807   99.45548 
23   51 
46.78812   99.45548 
23   51 
46.78807   99.45558 
23   51 
46.77701   99.53595 
23   51 
46.77705   99.53595 
23   51 
46.77701   99.53605 
23   51 
46.76288   99.72688 
23   51 
46.76293   99.72688 
23   51 
46.76288   99.72698 
23   51 
46.73494   100.3371 
23   51 
46.73498   100.3371 
23   51 
46.73494   100.3372 
23   51 
46.68827   101.8888 
23   51 
46.68831   101.8888 
23   51 
46.68827   101.8889 
23   51 
46.60977   105.7021 
23   51 
46.60982   105.7021 
23   51 
46.60977   105.7022 
23   51 
46.50222   113.4642 
23   51 
46.50227   113.4642 
23   51 
46.50222   113.4643 
23   51 
46.38842   127.1462 
23   51 
46.38847   127.1462 
23   51 
46.38842   127.1464 
23   51 
46.30617   150.1558 
23   51 
46.30621   150.1558 
23   51 
46.30617   150.156 
23   51 
46.29334   183.1192 
23   51 
46.29339   183.1192 
23   51 
46.29334   183.1194 
23   51 
46.2425   227.0644 
23   51 
46.24254   227.0644 
23   51 
46.2425   227.0646 
23   51 
46.14538   295.0092 
23   51 
46.14542   295.0092 
23   51 
46.14538   295.0095 
23   51 
46.10383   380.3238 
23   51 
46.10388   380.3238 
23   51 
46.10383   380.3242 
23   51 
46.06513   493.1106 
23   51 
46.06518   493.1106 
23   51 
46.06513   493.1111 
23   51 
46.04068   645.4299 
23   51 
46.04073   645.4299 
23   51 
46.04068   645.4305 
23   51 
46.01164   849.8226 
23   51 
46.01169   849.8226 
23   51 
46.01164   849.8235 
23   51 
46.00975   1121.17 
23   51 
46.00979   1121.17 
23   51 
46.00975   1121.171 
23   51 
45.96577   1512.284 
23   51 
45.96582   1512.284 
23   51 
45.96577   1512.286 
23   51 
45.98508   2014.89 
23   51 
45.98512   2014.89 
23   51 
45.98508   2014.892 
23   51 
45.96887   2643.471 
23   51 
45.96891   2643.471 
23   51 
45.96887   2643.474 
23   51 
45.96221   3520.58 
23   51 
45.96225   3520.58 
23   51 
45.96221   3520.583 
23   51 
45.95959   4641.749 
23   51 
45.95964   4641.749 
23   51 
45.95959   4641.754 
23   51 
45.9571   6145.89 
23   51 
45.95714   6145.89 
23   51 
45.9571   6145.896 
23   51 
45.95509   8132.298 
23   51 
45.95513   8132.298 
23   51 
45.95509   8132.306 
23   51 
45.95358   10767.77 
23   51 
45.95363   10767.77 
23   51 
45.95358   10767.78 
23   51 
45.95244   14256.72 
23   51 
45.95249   14256.72 
23   51 
45.95244   14256.73 
23   51 
45.95158   18880.57 
23   51 
45.95163   18880.57 
23   51 
45.95158   18880.59 
23   51 
45.95093   25006.82 
23   51 
45.95098   25006.82 
23   51 
45.95093   25006.85 
23   51 
45.95044   33129.79 
23   51 
45.95048   33129.79 
23   51 
45.95044   33129.82 
23   51 
45.95007   43844.97 
23   51 
45.95012   43844.97 
23   51 
45.95007   43845.01 
23   51 
45.94979   58128.12 
23   51 
45.94983   58128.12 
23   51 
45.94979   58128.18 
23   51 
45.94958   76917.18 
23   51 
45.94962   76917.18 
23   51 
45.94958   76917.26 
23   51 
45.94941   102187.4 
23   51 
45.94946   102187.4 
23   51 
45.94941   102187.5 
23   51 
45.9493   134513.4 
23   51 
45.94935   134513.4 
23   51 
45.9493   134513.5 
23   51 
45.9492   179751 
23   51 
45.94924   179751 
23   51 
45.9492   179751.2 
23   51 
45.94914   236339.4 
23   51 
45.94918   236339.4 
23   51 
45.94914   236339.6 
23   51 
45.94908   318093 
23   51 
45.94912   318093 
23   51 
45.94908   318093.3 
23   51 
45.94905   410258.5 
23   51 
45.9491   410258.5 
23   51 
45.94905   410258.9 
23   51 
45.94901   516519.6 
23   51 
45.94906   516519.6 
23   51 
45.94901   516520.2 
23   51 
45.94901   622780.8 
23   51 
45.94906   622780.8 
23   51 
45.94901   622781.4 
Fit Mean:  45.94901  Size:  622780.8  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  45.94901  Size:  622780.8  Code:  1  Try Size:  100 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
23 51
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
622780.8   45.94901 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 622780.8
> print(nb_fit_mu);
[1] 45.94901
> 
> print(m)
[1] 35.93659
> print(v)
[1] 180.6773
> print(D)
[1] 5.027671
> 
> print(deletion_propagation_coverage)
[1] 28
> 
> warnings()
> 


R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | p3_out/07_error_calibration/114.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | p3_out/output/calibration/114.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00422577 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 6 to 15.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  8.220779  Size:  10000 
6   15 
8.220779   10000 
6   15 
8.220779   10000 
6   15 
8.220787   10000 
6   15 
8.220779   10000.01 
6   15 
8.239842   10000 
6   15 
8.23985   10000 
6   15 
8.239842   10000.01 
6   15 
11.62616   10000 
6   15 
11.62617   10000 
6   15 
11.62616   10000.01 
6   15 
11.40648   10000 
6   15 
11.40649   10000 
6   15 
11.40648   10000.01 
6   15 
11.39307   10000 
6   15 
11.39309   10000 
6   15 
11.39307   10000.01 
6   15 
11.39327   10000 
6   15 
11.39328   10000 
6   15 
11.39327   10000.01 
6   15 
11.39327   10000 
6   15 
11.39441   10000 
6   15 
11.39213   10000 
6   15 
11.39327   10001 
6   15 
11.39327   9999 
6   15 
11.39328   10000 
6   15 
11.39442   10000 
6   15 
11.39214   10000 
6   15 
11.39328   10001 
6   15 
11.39328   9999 
Fit Mean:  11.39328  Size:  10000  Code:  2 
Try Mean:  8.220779  Size:  1000 
6   15 
8.220779   1000 
6   15 
8.220779   1000 
6   15 
8.220787   1000 
6   15 
8.220779   1000.001 
6   15 
8.239734   1000 
6   15 
8.239743   1000 
6   15 
8.239734   1000.001 
6   15 
11.59767   999.9999 
6   15 
11.59769   999.9999 
6   15 
11.59767   1000.001 
6   15 
11.40958   999.9999 
6   15 
11.40959   999.9999 
6   15 
11.40958   1000.001 
6   15 
11.3967   999.9999 
6   15 
11.39671   999.9999 
6   15 
11.3967   1000.001 
6   15 
11.39686   999.9999 
6   15 
11.39688   999.9999 
6   15 
11.39686   1000.001 
6   15 
11.39687   999.9999 
6   15 
11.39688   999.9999 
6   15 
11.39687   1000.001 
Fit Mean:  11.39687  Size:  999.9999  Code:  2 
Try Mean:  8.220779  Size:  100 
6   15 
8.220779   100 
6   15 
8.220779   100 
6   15 
8.220787   100 
6   15 
8.220779   100.0001 
6   15 
8.238688   99.99997 
6   15 
8.238696   99.99997 
6   15 
8.238688   100.0001 
6   15 
11.35803   99.99503 
6   15 
11.35804   99.99503 
6   15 
11.35803   99.99513 
6   15 
11.42614   99.99328 
6   15 
11.42615   99.99328 
6   15 
11.42614   99.99338 
6   15 
11.43582   99.99128 
6   15 
11.43583   99.99128 
6   15 
11.43582   99.99138 
6   15 
11.43625   99.98938 
6   15 
11.43626   99.98938 
6   15 
11.43625   99.98948 
6   15 
11.44494   99.91307 
6   15 
11.44495   99.91307 
6   15 
11.44494   99.91317 
6   15 
11.45415   99.75421 
6   15 
11.45416   99.75421 
6   15 
11.45415   99.75431 
6   15 
11.47251   99.20833 
6   15 
11.47253   99.20833 
6   15 
11.47251   99.20843 
6   15 
11.50182   97.76325 
6   15 
11.50183   97.76325 
6   15 
11.50182   97.76334 
6   15 
11.55763   93.4869 
6   15 
11.55764   93.4869 
6   15 
11.55763   93.48699 
6   15 
11.69283   79.0293 
6   15 
11.69284   79.0293 
6   15 
11.69283   79.02938 
Fit Mean:  24.3874  Size:  -1339.055  Code:  1 
Try Mean:  8.220779  Size:  10 
6   15 
8.220779   10 
6   15 
8.220779   10 
6   15 
8.220787   10 
6   15 
8.220779   10.00001 
6   15 
8.231557   9.998984 
6   15 
8.231565   9.998984 
6   15 
8.231557   9.998994 
6   15 
10.5786   9.820078 
6   15 
10.57861   9.820078 
6   15 
10.5786   9.820087 
6   15 
11.40663   9.745719 
6   15 
11.40665   9.745719 
6   15 
11.40663   9.745729 
6   15 
11.94046   9.637789 
6   15 
11.94047   9.637789 
6   15 
11.94046   9.637798 
6   15 
12.11476   9.524819 
6   15 
12.11477   9.524819 
6   15 
12.11476   9.524828 
6   15 
12.28469   9.287199 
6   15 
12.2847   9.287199 
6   15 
12.28469   9.287208 
6   15 
12.70923   8.366815 
6   15 
12.70924   8.366815 
6   15 
12.70923   8.366823 
Fit Mean:  16.73515  Size:  -1.666116  Code:  1 
Try Mean:  8.220779  Size:  1 
6   15 
8.220779   1 
6   15 
8.220779   1 
6   15 
8.220787   1 
6   15 
8.220779   1.000001 
6   15 
8.222529   0.9970782 
6   15 
8.222537   0.9970782 
6   15 
8.222529   0.9970792 
Fit Mean:  8.597105  Size:  -3.701036  Code:  1 
Try Mean:  8.220779  Size:  0.1 
6   15 
8.220779   0.1 
6   15 
8.220779   0.1 
6   15 
8.220787   0.1 
6   15 
8.220779   0.100001 
6   15 
8.220956   0.09678615 
6   15 
8.220964   0.09678615 
6   15 
8.220956   0.09678715 
6   15 
8.221127   0.09357168 
6   15 
8.221135   0.09357168 
6   15 
8.221127   0.09357268 
6   15 
8.221292   0.09035656 
6   15 
8.2213   0.09035656 
6   15 
8.221292   0.09035756 
6   15 
8.221451   0.08714079 
6   15 
8.221459   0.08714079 
6   15 
8.221451   0.08714179 
6   15 
8.221605   0.08392437 
6   15 
8.221613   0.08392437 
6   15 
8.221605   0.08392537 
6   15 
8.221753   0.08070728 
6   15 
8.221761   0.08070728 
6   15 
8.221753   0.08070828 
6   15 
8.221895   0.07748951 
6   15 
8.221904   0.07748951 
6   15 
8.221895   0.07749051 
6   15 
8.222032   0.07427105 
6   15 
8.22204   0.07427105 
6   15 
8.222032   0.07427205 
6   15 
8.222163   0.0710519 
6   15 
8.222171   0.0710519 
6   15 
8.222163   0.0710529 
6   15 
8.222288   0.06783204 
6   15 
8.222297   0.06783204 
6   15 
8.222288   0.06783304 
6   15 
8.222408   0.06461148 
6   15 
8.222416   0.06461148 
6   15 
8.222408   0.06461248 
6   15 
8.222522   0.06139019 
6   15 
8.22253   0.06139019 
6   15 
8.222522   0.06139119 
6   15 
8.22263   0.05816817 
6   15 
8.222639   0.05816817 
6   15 
8.22263   0.05816917 
6   15 
8.222733   0.0549454 
6   15 
8.222741   0.0549454 
6   15 
8.222733   0.0549464 
6   15 
8.22283   0.05172189 
6   15 
8.222838   0.05172189 
6   15 
8.22283   0.05172289 
6   15 
8.222921   0.04849762 
6   15 
8.222929   0.04849762 
6   15 
8.222921   0.04849862 
6   15 
8.223006   0.04527258 
6   15 
8.223015   0.04527258 
6   15 
8.223006   0.04527358 
6   15 
8.223086   0.04204677 
6   15 
8.223094   0.04204677 
6   15 
8.223086   0.04204777 
6   15 
8.22316   0.03882017 
6   15 
8.223169   0.03882017 
6   15 
8.22316   0.03882117 
6   15 
8.223229   0.03559277 
6   15 
8.223237   0.03559277 
6   15 
8.223229   0.03559377 
6   15 
8.223292   0.03236457 
6   15 
8.2233   0.03236457 
6   15 
8.223292   0.03236557 
6   15 
8.223349   0.02913556 
6   15 
8.223357   0.02913556 
6   15 
8.223349   0.02913656 
6   15 
8.2234   0.02590573 
6   15 
8.223408   0.02590573 
6   15 
8.2234   0.02590673 
6   15 
8.223446   0.02267506 
6   15 
8.223454   0.02267506 
6   15 
8.223446   0.02267606 
6   15 
8.223486   0.01944356 
6   15 
8.223494   0.01944356 
6   15 
8.223486   0.01944456 
6   15 
8.22352   0.01621121 
6   15 
8.223528   0.01621121 
6   15 
8.22352   0.01621221 
6   15 
8.223548   0.01297799 
6   15 
8.223557   0.01297799 
6   15 
8.223548   0.01297899 
6   15 
8.223571   0.009743915 
6   15 
8.223579   0.009743915 
6   15 
8.223571   0.009744915 
6   15 
8.223588   0.00650896 
6   15 
8.223597   0.00650896 
6   15 
8.223588   0.00650996 
6   15 
8.2236   0.00327312 
6   15 
8.223608   0.00327312 
6   15 
8.2236   0.00327412 
6   15 
8.223606   3.638607e-05 
6   15 
8.223614   3.638607e-05 
6   15 
8.223606   3.738607e-05 
Fit Mean:  8.223606  Size:  -0.003201251  Code:  1 
Try Mean:  8.220779  Size:  0.01 
6   15 
8.220779   0.01 
6   15 
8.220779   0.01 
6   15 
8.220787   0.01 
6   15 
8.220779   0.010001 
6   15 
8.220797   0.006760197 
6   15 
8.220805   0.006760197 
6   15 
8.220797   0.006761197 
6   15 
8.220809   0.003519508 
6   15 
8.220817   0.003519508 
6   15 
8.220809   0.003520508 
6   15 
8.220815   0.0002779254 
6   15 
8.220823   0.0002779254 
6   15 
8.220815   0.0002789254 
Fit Mean:  8.220815  Size:  -0.00296456  Code:  1 
Try Mean:  8.220779  Size:  0.001 
6   15 
8.220779   0.001 
6   15 
8.220779   0.001 
6   15 
8.220787   0.001 
6   15 
8.220779   0.001001 
Fit Mean:  8.220781  Size:  -0.002242345  Code:  1 
Try Mean:  15  Size:  10000 
6   15 
15   10000 
6   15 
15   10000 
6   15 
15.00001   10000 
6   15 
15   10000.01 
6   15 
14.98551   10000 
6   15 
14.98553   10000 
6   15 
14.98551   10000.01 
6   15 
8.508791   10000 
6   15 
8.5088   10000 
6   15 
8.508791   10000.01 
6   15 
12.04937   10000 
6   15 
12.04938   10000 
6   15 
12.04937   10000.01 
6   15 
11.44437   10000 
6   15 
11.44438   10000 
6   15 
11.44437   10000.01 
6   15 
11.39086   10000 
6   15 
11.39087   10000 
6   15 
11.39086   10000.01 
6   15 
11.39328   10000 
6   15 
11.39329   10000 
6   15 
11.39328   10000.01 
6   15 
11.39327   10000 
6   15 
11.39442   10000 
6   15 
11.39214   10000 
6   15 
11.39328   10001 
6   15 
11.39328   9999 
6   15 
11.39328   10000 
6   15 
11.39442   10000 
6   15 
11.39214   10000 
6   15 
11.39328   10001 
6   15 
11.39328   9999 
Fit Mean:  11.39328  Size:  10000  Code:  2 
Try Mean:  15  Size:  1000 
6   15 
15   1000 
6   15 
15   1000 
6   15 
15.00001   1000 
6   15 
15   1000.001 
6   15 
14.9858   1000 
6   15 
14.98582   1000 
6   15 
14.9858   1000.001 
6   15 
8.498301   1000 
6   15 
8.49831   1000 
6   15 
8.498301   1000.001 
6   15 
12.07262   999.9998 
6   15 
12.07263   999.9998 
6   15 
12.07262   1000.001 
6   15 
11.45464   999.9998 
6   15 
11.45465   999.9998 
6   15 
11.45464   1000.001 
6   15 
11.39396   999.9998 
6   15 
11.39398   999.9998 
6   15 
11.39396   1000.001 
6   15 
11.39687   999.9997 
6   15 
11.39689   999.9997 
6   15 
11.39687   1000.001 
6   15 
11.39686   999.9997 
6   15 
11.39688   999.9997 
6   15 
11.39686   1000.001 
Fit Mean:  11.39686  Size:  999.9997  Code:  2 
Try Mean:  15  Size:  100 
6   15 
15   100 
6   15 
15   100 
6   15 
15.00001   100 
6   15 
15   100.0001 
6   15 
14.98831   99.99994 
6   15 
14.98832   99.99994 
6   15 
14.98831   100 
6   15 
8.423866   100.0204 
6   15 
11.72806   100.0101 
6   15 
11.72808   100.0101 
6   15 
11.72806   100.0102 
6   15 
11.28886   100.0091 
6   15 
11.28887   100.0091 
6   15 
11.28886   100.0092 
6   15 
11.4394   100.0037 
6   15 
11.43941   100.0037 
6   15 
11.4394   100.0038 
6   15 
11.43594   99.99824 
6   15 
11.43595   99.99824 
6   15 
11.43594   99.99834 
6   15 
11.43257   99.98195 
6   15 
11.43258   99.98195 
6   15 
11.43257   99.98205 
6   15 
11.42592   99.917 
6   15 
11.42593   99.917 
6   15 
11.42592   99.9171 
6   15 
11.4159   99.73687 
6   15 
11.41591   99.73687 
6   15 
11.4159   99.73697 
6   15 
11.39908   99.21414 
6   15 
11.39909   99.21414 
6   15 
11.39908   99.21424 
6   15 
11.37135   97.77252 
6   15 
11.37137   97.77252 
6   15 
11.37135   97.77261 
6   15 
11.3218   93.64553 
6   15 
11.32181   93.64553 
6   15 
11.3218   93.64563 
6   15 
11.21252   80.27308 
6   15 
11.21253   80.27308 
6   15 
11.21252   80.27316 
Fit Mean:  10.24851  Size:  -57.0066  Code:  1 
Try Mean:  15  Size:  10 
6   15 
15   10 
6   15 
15   10 
6   15 
15.00001   10 
6   15 
15   10.00001 
6   15 
14.99726   9.998875 
6   15 
14.99727   9.998875 
6   15 
14.99726   9.998885 
6   15 
10.78748   8.723911 
6   15 
10.78749   8.723911 
6   15 
10.78748   8.72392 
6   15 
12.67915   8.279814 
6   15 
12.67916   8.279814 
6   15 
12.67915   8.279822 
6   15 
12.4609   7.613894 
6   15 
12.46092   7.613894 
6   15 
12.4609   7.613902 
6   15 
11.92412   2.406634 
6   15 
11.92413   2.406634 
6   15 
11.92412   2.406637 
Fit Mean:  12.10015  Size:  -1.102036  Code:  1 
Try Mean:  15  Size:  1 
6   15 
15   1 
6   15 
15   1 
6   15 
15.00001   1 
6   15 
15   1.000001 
6   15 
15.00028   1.000904 
6   15 
15.00029   1.000904 
6   15 
15.00028   1.000905 
6   15 
15.4253   1.624426 
6   15 
15.42531   1.624426 
6   15 
15.4253   1.624428 
6   15 
15.68467   1.740853 
6   15 
15.68468   1.740853 
6   15 
15.68467   1.740855 
6   15 
16.25134   1.819201 
6   15 
16.25135   1.819201 
6   15 
16.25134   1.819202 
6   15 
17.36217   1.771045 
6   15 
17.36218   1.771045 
6   15 
17.36217   1.771047 
6   15 
20.6271   1.340041 
6   15 
20.62712   1.340041 
6   15 
20.6271   1.340042 
6   15 
25.50126   0.7726409 
6   15 
23.00326   1.063432 
6   15 
23.00329   1.063432 
6   15 
23.00326   1.063434 
6   15 
24.74189   1.024898 
6   15 
24.74191   1.024898 
6   15 
24.74189   1.024899 
6   15 
30.13356   1.040745 
6   15 
30.13359   1.040745 
6   15 
30.13356   1.040746 
6   15 
36.51845   0.8935164 
6   15 
36.51849   0.8935164 
6   15 
36.51845   0.8935174 
6   15 
43.55457   0.8674659 
6   15 
43.55461   0.8674659 
6   15 
43.55457   0.8674669 
6   15 
53.14065   0.8492529 
6   15 
53.1407   0.8492529 
6   15 
53.14065   0.8492539 
6   15 
66.71   0.7964251 
6   15 
66.71007   0.7964251 
6   15 
66.71   0.7964261 
6   15 
84.76552   0.8060716 
6   15 
84.76561   0.8060716 
6   15 
84.76552   0.8060726 
6   15 
110.5145   0.7506126 
6   15 
110.5146   0.7506126 
6   15 
110.5145   0.7506136 
6   15 
134.7592   0.7460357 
6   15 
134.7593   0.7460357 
6   15 
134.7592   0.7460367 
6   15 
172.4623   0.7444152 
6   15 
172.4625   0.7444152 
6   15 
172.4623   0.7444162 
6   15 
222.0117   0.7334962 
6   15 
222.012   0.7334962 
6   15 
222.0117   0.7334972 
6   15 
288.1309   0.7300484 
6   15 
288.1312   0.7300484 
6   15 
288.1309   0.7300494 
6   15 
375.4474   0.7230091 
6   15 
375.4478   0.7230091 
6   15 
375.4474   0.7230101 
6   15 
491.1322   0.7218475 
6   15 
491.1327   0.7218475 
6   15 
491.1322   0.7218485 
6   15 
645.4525   0.7164187 
6   15 
645.4531   0.7164187 
6   15 
645.4525   0.7164197 
6   15 
849.6743   0.7170803 
6   15 
849.6751   0.7170803 
6   15 
849.6743   0.7170813 
6   15 
1123.009   0.7127971 
6   15 
1123.01   0.7127971 
6   15 
1123.009   0.7127981 
6   15 
1483.39   0.7137154 
6   15 
1483.392   0.7137154 
6   15 
1483.39   0.7137164 
6   15 
1960.333   0.7114221 
6   15 
1960.335   0.7114221 
6   15 
1960.333   0.7114231 
6   15 
2591.545   0.7115734 
6   15 
2591.547   0.7115734 
6   15 
2591.545   0.7115744 
6   15 
3424.887   0.7106382 
6   15 
3424.891   0.7106382 
6   15 
3424.887   0.7106392 
6   15 
4530.687   0.7105107 
6   15 
4530.691   0.7105107 
6   15 
4530.687   0.7105117 
6   15 
5993.208   0.710095 
6   15 
5993.214   0.710095 
6   15 
5993.208   0.710096 
6   15 
7932.373   0.709961 
6   15 
7932.381   0.709961 
6   15 
7932.373   0.709962 
6   15 
10499.14   0.709757 
6   15 
10499.15   0.709757 
6   15 
10499.14   0.709758 
6   15 
13901.88   0.7096622 
6   15 
13901.89   0.7096622 
6   15 
13901.88   0.7096632 
6   15 
18406.31   0.709556 
6   15 
18406.33   0.709556 
6   15 
18406.31   0.709557 
6   15 
24374.94   0.7094965 
6   15 
24374.97   0.7094965 
6   15 
24374.94   0.7094975 
Fit Mean:  24374.94  Size:  0.7094965  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  24374.94  Size:  0.7094965  Code:  1  Try Size:  1 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
6 15
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
Fallback to calculating off an estimate of just variance = mu + mu^2/size
Mu estimate= 8.220779  Size estimate = 6.111089 
Double fallback to calculating as just 10% of the mean
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 0
> print(nb_fit_mu);
[1] 0
> 
> print(m)
[1] 8.220779
> print(v)
[1] 19.27956
> print(D)
[1] 2.345223
> 
> print(deletion_propagation_coverage)
[1] 1
> 
> warnings()
> 


R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | p3_out/07_error_calibration/98.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | p3_out/output/calibration/98.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00325472 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 567 to 1183.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  1084.765  Size:  10000 
567   1183 
1084.765   10000 
567   1183 
1084.765   10000 
567   1183 
1084.767   10000 
567   1183 
1084.765   10000.01 
567   1183 
1084.766   10000 
567   1183 
1084.767   10000 
567   1183 
1084.766   10000.01 
Fit Mean:  1084.766  Size:  10000  Code:  2 
Try Mean:  1084.765  Size:  1000 
567   1183 
1084.765   1000 
567   1183 
1084.765   1000 
567   1183 
1084.767   1000 
567   1183 
1084.765   1000.001 
567   1183 
1084.766   1000 
567   1183 
1084.767   1000 
567   1183 
1084.766   1000.001 
Fit Mean:  1084.766  Size:  1000  Code:  2 
Try Mean:  1084.765  Size:  100 
567   1183 
1084.765   100 
567   1183 
1084.765   100 
567   1183 
1084.767   100 
567   1183 
1084.765   100.0001 
567   1183 
1084.765   100 
567   1183 
1084.767   100 
567   1183 
1084.765   100.0001 
Fit Mean:  1084.765  Size:  100  Code:  2 
Try Mean:  1084.765  Size:  10 
567   1183 
1084.765   10 
567   1183 
1084.765   10 
567   1183 
1084.767   10 
567   1183 
1084.765   10.00001 
567   1183 
1084.765   10.00008 
567   1183 
1084.767   10.00008 
567   1183 
1084.765   10.00009 
567   1183 
1087.554   25.21178 
567   1183 
1087.555   25.21178 
567   1183 
1087.554   25.2118 
567   1183 
1091.996   37.397 
567   1183 
1091.997   37.397 
567   1183 
1091.996   37.39704 
567   1183 
1102.829   59.77642 
567   1183 
1102.83   59.77642 
567   1183 
1102.829   59.77648 
567   1183 
1122.41   93.99646 
567   1183 
1122.411   93.99646 
567   1183 
1122.41   93.99655 
567   1183 
1171.645   174.8236 
567   1183 
1171.646   174.8236 
567   1183 
1171.645   174.8238 
567   1183 
1181.734   191.4137 
567   1183 
1176.558   182.902 
567   1183 
1176.559   182.902 
567   1183 
1176.558   182.9022 
567   1183 
1176.646   183.1214 
567   1183 
1176.647   183.1214 
567   1183 
1176.646   183.1216 
567   1183 
1176.723   183.5213 
567   1183 
1176.724   183.5213 
567   1183 
1176.723   183.5215 
567   1183 
1176.782   184.7069 
567   1183 
1176.783   184.7069 
567   1183 
1176.782   184.7071 
567   1183 
1176.625   187.6073 
567   1183 
1176.626   187.6073 
567   1183 
1176.625   187.6075 
567   1183 
1175.556   196.9005 
567   1183 
1175.557   196.9005 
567   1183 
1175.556   196.9007 
567   1183 
1164.88   275.4442 
567   1183 
1164.881   275.4442 
567   1183 
1164.88   275.4445 
567   1183 
1121.377   599.0248 
567   1183 
1158.25   324.7593 
567   1183 
1158.251   324.7593 
567   1183 
1158.25   324.7596 
567   1183 
1102.395   744.2207 
567   1183 
1152.665   366.7054 
567   1183 
1152.666   366.7054 
567   1183 
1152.665   366.7058 
567   1183 
1121.268   625.803 
567   1183 
1148.823   398.4089 
567   1183 
1148.824   398.4089 
567   1183 
1148.823   398.4093 
567   1183 
1141.778   467.6837 
567   1183 
1141.779   467.6837 
567   1183 
1141.778   467.6842 
567   1183 
1144.141   456.0385 
567   1183 
1144.142   456.0385 
567   1183 
1144.141   456.0389 
567   1183 
1146.012   478.7895 
567   1183 
1146.013   478.7895 
567   1183 
1146.012   478.7899 
567   1183 
1146.964   606.0904 
567   1183 
1146.965   606.0904 
567   1183 
1146.964   606.091 
567   1183 
1142.18   927.5584 
567   1183 
1142.181   927.5584 
567   1183 
1142.18   927.5594 
567   1183 
1119.595   2399.864 
567   1183 
1136.99   1265.913 
567   1183 
1136.991   1265.913 
567   1183 
1136.99   1265.914 
567   1183 
1135.034   1703.631 
567   1183 
1135.035   1703.631 
567   1183 
1135.034   1703.633 
567   1183 
1136.531   2371.106 
567   1183 
1136.532   2371.106 
567   1183 
1136.531   2371.109 
567   1183 
1136.476   3250.409 
567   1183 
1136.477   3250.409 
567   1183 
1136.476   3250.412 
567   1183 
1135.845   4456.68 
567   1183 
1135.846   4456.68 
567   1183 
1135.845   4456.684 
567   1183 
1136.008   6005.15 
567   1183 
1136.009   6005.15 
567   1183 
1136.008   6005.156 
567   1183 
1135.533   8073.723 
567   1183 
1135.534   8073.723 
567   1183 
1135.533   8073.731 
567   1183 
1135.858   10805.45 
567   1183 
1135.859   10805.45 
567   1183 
1135.858   10805.46 
567   1183 
1135.418   14474.26 
567   1183 
1135.419   14474.26 
567   1183 
1135.418   14474.28 
567   1183 
1135.607   19231.96 
567   1183 
1135.609   19231.96 
567   1183 
1135.607   19231.98 
567   1183 
1135.484   25499.34 
567   1183 
1135.485   25499.34 
567   1183 
1135.484   25499.36 
567   1183 
1135.498   33793.67 
567   1183 
1135.499   33793.67 
567   1183 
1135.498   33793.7 
567   1183 
1135.465   44750.77 
567   1183 
1135.466   44750.77 
567   1183 
1135.465   44750.82 
567   1183 
1135.46   59271.65 
567   1183 
1135.461   59271.65 
567   1183 
1135.46   59271.71 
567   1183 
1135.446   78492.15 
567   1183 
1135.447   78492.15 
567   1183 
1135.446   78492.23 
567   1183 
1135.442   103955.4 
567   1183 
1135.443   103955.4 
567   1183 
1135.442   103955.5 
567   1183 
1135.435   137679.2 
567   1183 
1135.436   137679.2 
567   1183 
1135.435   137679.4 
567   1183 
1135.431   182353.9 
567   1183 
1135.433   182353.9 
567   1183 
1135.431   182354 
567   1183 
1135.428   241531.1 
567   1183 
1135.429   241531.1 
567   1183 
1135.428   241531.4 
567   1183 
1135.426   319925.1 
567   1183 
1135.427   319925.1 
567   1183 
1135.426   319925.4 
567   1183 
1135.424   423767.6 
567   1183 
1135.425   423767.6 
567   1183 
1135.424   423768 
567   1183 
1135.423   561341.5 
567   1183 
1135.424   561341.5 
567   1183 
1135.423   561342.1 
567   1183 
1135.421   743580 
567   1183 
1135.423   743580 
567   1183 
1135.421   743580.8 
567   1183 
1135.421   984969.6 
567   1183 
1135.422   984969.6 
567   1183 
1135.421   984970.6 
567   1183 
1135.42   1304733 
567   1183 
1135.421   1304733 
567   1183 
1135.42   1304734 
567   1183 
1135.42   1728204 
567   1183 
1135.421   1728204 
567   1183 
1135.42   1728206 
567   1183 
1135.419   2289183 
567   1183 
1135.421   2289183 
567   1183 
1135.419   2289186 
567   1183 
1135.419   3032183 
567   1183 
1135.42   3032183 
567   1183 
1135.419   3032186 
567   1183 
1135.419   4017698 
567   1183 
1135.42   4017698 
567   1183 
1135.419   4017702 
567   1183 
1135.419   5102510 
567   1183 
1135.42   5102510 
567   1183 
1135.419   5102515 
567   1183 
1135.419   6187321 
567   1183 
1135.42   6187321 
567   1183 
1135.419   6187327 
Fit Mean:  1135.419  Size:  6187321  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  1135.419  Size:  6187321  Code:  1  Try Size:  10 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
567 1183
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
6187321   1135.419 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 6187321
> print(nb_fit_mu);
[1] 1135.419
> 
> print(m)
[1] 1084.765
> print(v)
[1] 6581.207
> print(D)
[1] 6.06694
> 
> print(deletion_propagation_coverage)
[1] 1045
> 
> warnings()
> 


R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | 3a-_BHI_c50_out/07_error_calibration/59.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | 3a-_BHI_c50_out/output/calibration/59.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00103986 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 1 to 2.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  1.075163  Size:  10000 
1   2 
1.075163   10000 
1   2 
1.075163   10000 
1   2 
1.075164   10000 
1   2 
1.075163   10000.01 
1   2 
0.8430022   10000 
1   2 
0.8430032   10000 
1   2 
0.8430022   10000.01 
Fit Mean:  -3.044316  Size:  10000  Code:  1 
Try Mean:  1.075163  Size:  1000 
1   2 
1.075163   1000 
1   2 
1.075163   1000 
1   2 
1.075164   1000 
1   2 
1.075163   1000.001 
1   2 
0.8432443   1000 
1   2 
0.8432453   1000 
1   2 
0.8432443   1000.001 
Fit Mean:  -3.080048  Size:  1000  Code:  1 
Try Mean:  1.075163  Size:  100 
1   2 
1.075163   100 
1   2 
1.075163   100 
1   2 
1.075164   100 
1   2 
1.075163   100.0001 
1   2 
0.845638   100 
1   2 
0.845639   100 
1   2 
0.845638   100.0001 
Fit Mean:  -3.471403  Size:  100.0018  Code:  1 
Try Mean:  1.075163  Size:  10 
1   2 
1.075163   10 
1   2 
1.075163   10 
1   2 
1.075164   10 
1   2 
1.075163   10.00001 
1   2 
0.8671261   9.999847 
1   2 
0.8671271   9.999847 
1   2 
0.8671261   9.999857 
Fit Mean:  -37.62688  Size:  20.6801  Code:  1 
Try Mean:  1.075163  Size:  1 
1   2 
1.075163   1 
1   2 
1.075163   1 
1   2 
1.075164   1 
1   2 
1.075163   1.000001 
1   2 
0.9679051   0.9956661 
1   2 
0.9679061   0.9956661 
1   2 
0.9679051   0.9956671 
1   2 
0.8500291   0.9975089 
1   2 
0.8500301   0.9975089 
1   2 
0.8500291   0.9975099 
1   2 
0.7186705   1.005913 
1   2 
0.7186715   1.005913 
1   2 
0.7186705   1.005914 
1   2 
0.570476   1.020762 
1   2 
0.570477   1.020762 
1   2 
0.570476   1.020763 
1   2 
0.4029988   1.040657 
1   2 
0.4029998   1.040657 
1   2 
0.4029988   1.040658 
1   2 
0.2221181   1.06115 
1   2 
0.2221191   1.06115 
1   2 
0.2221181   1.061151 
Fit Mean:  -0.5212194  Size:  1.11999  Code:  1 
Try Mean:  1.075163  Size:  0.1 
1   2 
1.075163   0.1 
1   2 
1.075163   0.1 
1   2 
1.075164   0.1 
1   2 
1.075163   0.100001 
1   2 
1.056862   0.08655482 
1   2 
1.056863   0.08655482 
1   2 
1.056862   0.08655582 
1   2 
0.8819582   0.04050305 
1   2 
0.8819592   0.04050305 
1   2 
0.8819582   0.04050405 
1   2 
0.2853184   0.1023843 
1   2 
0.2853194   0.1023843 
1   2 
0.2853184   0.1023853 
Fit Mean:  -8.036165  Size:  0.8309351  Code:  1 
Try Mean:  1.075163  Size:  0.01 
1   2 
1.075163   0.01 
1   2 
1.075163   0.01 
1   2 
1.075164   0.01 
1   2 
1.075163   0.010001 
Fit Mean:  1.073195  Size:  -0.005750764  Code:  1 
Try Mean:  1.075163  Size:  0.001 
1   2 
1.075163   0.001 
1   2 
1.075163   0.001 
1   2 
1.075164   0.001 
1   2 
1.075163   0.001001 
Fit Mean:  1.074965  Size:  -0.01501338  Code:  1 
Try Mean:  2  Size:  10000 
1   2 
2   10000 
1   2 
2   10000 
1   2 
2.000002   10000 
1   2 
2   10000.01 
1   2 
1.787637   10000 
1   2 
1.787639   10000 
1   2 
1.787637   10000.01 
1   2 
1.566415   10000 
1   2 
1.566417   10000 
1   2 
1.566415   10000.01 
1   2 
1.337487   10000 
1   2 
1.337489   10000 
1   2 
1.337487   10000.01 
1   2 
1.103689   10000 
1   2 
1.10369   10000 
1   2 
1.103689   10000.01 
Fit Mean:  -57.91008  Size:  10000  Code:  1 
Try Mean:  2  Size:  1000 
1   2 
2   1000 
1   2 
2   1000 
1   2 
2.000002   1000 
1   2 
2   1000.001 
1   2 
1.78813   1000 
1   2 
1.788132   1000 
1   2 
1.78813   1000.001 
1   2 
1.567391   1000 
1   2 
1.567392   1000 
1   2 
1.567391   1000.001 
1   2 
1.338907   1000 
1   2 
1.338908   1000 
1   2 
1.338907   1000.001 
1   2 
1.105473   1000 
1   2 
1.105474   1000 
1   2 
1.105473   1000.001 
Fit Mean:  -68.96347  Size:  1000  Code:  1 
Try Mean:  2  Size:  100 
1   2 
2   100 
1   2 
2   100 
1   2 
2.000002   100 
1   2 
2   100.0001 
1   2 
1.792959   99.99996 
1   2 
1.792961   99.99996 
1   2 
1.792959   100.0001 
1   2 
1.576949   99.99993 
1   2 
1.57695   99.99993 
1   2 
1.576949   100 
1   2 
1.352855   99.99991 
1   2 
1.352857   99.99991 
1   2 
1.352855   100 
1   2 
1.123066   99.9999 
1   2 
1.123067   99.9999 
1   2 
1.123066   100 
1   2 
0.8926612   99.99989 
1   2 
0.8926622   99.99989 
1   2 
0.8926612   99.99999 
Fit Mean:  -4.845358  Size:  99.99995  Code:  1 
Try Mean:  2  Size:  10 
1   2 
2   10 
1   2 
2   10 
1   2 
2.000002   10 
1   2 
2   10.00001 
1   2 
1.83236   9.996952 
1   2 
1.832362   9.996952 
1   2 
1.83236   9.996962 
1   2 
1.656027   9.994506 
1   2 
1.656029   9.994506 
1   2 
1.656027   9.994516 
1   2 
1.470574   9.992672 
1   2 
1.470575   9.992672 
1   2 
1.470574   9.992682 
1   2 
1.276002   9.991446 
1   2 
1.276003   9.991446 
1   2 
1.276002   9.991456 
1   2 
1.073256   9.990796 
1   2 
1.073257   9.990796 
1   2 
1.073256   9.990806 
1   2 
0.8652119   9.990647 
1   2 
0.8652129   9.990647 
1   2 
0.8652119   9.990657 
Fit Mean:  -32.28609  Size:  10.02583  Code:  1 
Try Mean:  2  Size:  1 
1   2 
2   1 
1   2 
2   1 
1   2 
2.000002   1 
1   2 
2   1.000001 
1   2 
1.948026   0.9480262 
1   2 
1.948028   0.9480262 
1   2 
1.948026   0.9480272 
Fit Mean:  -4.329677  Size:  -5.329679  Code:  1 
Try Mean:  2  Size:  0.1 
1   2 
2   0.1 
1   2 
2   0.1 
1   2 
2.000002   0.1 
1   2 
2   0.100001 
Fit Mean:  1.99423  Size:  -0.004916595  Code:  1 
Try Mean:  2  Size:  0.01 
1   2 
2   0.01 
1   2 
2   0.01 
1   2 
2.000002   0.01 
1   2 
2   0.010001 
Fit Mean:  1.999426  Size:  -0.1037115  Code:  1 
Try Mean:  2  Size:  0.001 
1   2 
2   0.001 
1   2 
2   0.001 
1   2 
2.000002   0.001 
1   2 
2   0.001001 
Fit Mean:  1.999943  Size:  -0.1136386  Code:  1 
Try Mean:  1  Size:  10000 
1   2 
1   10000 
1   2 
1   10000 
1   2 
1.000001   10000 
1   2 
1   10000.01 
1   2 
0.7705385   10000 
1   2 
0.7705395   10000 
1   2 
0.7705385   10000.01 
Fit Mean:  -1.934007  Size:  10000  Code:  1 
Try Mean:  1  Size:  1000 
1   2 
1   1000 
1   2 
1   1000 
1   2 
1.000001   1000 
1   2 
1   1000.001 
1   2 
0.7707448   1000 
1   2 
0.7707458   1000 
1   2 
0.7707448   1000.001 
Fit Mean:  -1.952858  Size:  1000  Code:  1 
Try Mean:  1  Size:  100 
1   2 
1   100 
1   2 
1   100 
1   2 
1.000001   100 
1   2 
1   100.0001 
1   2 
0.7727877   100 
1   2 
0.7727887   100 
1   2 
0.7727877   100.0001 
Fit Mean:  -2.154161  Size:  100.0007  Code:  1 
Try Mean:  1  Size:  10 
1   2 
1   10 
1   2 
1   10 
1   2 
1.000001   10 
1   2 
1   10.00001 
1   2 
0.7913778   10 
1   2 
0.7913788   10 
1   2 
0.7913778   10.00001 
Fit Mean:  -7.710013  Size:  10.52874  Code:  1 
Try Mean:  1  Size:  1 
1   2 
1   1 
1   2 
1   1 
1   2 
1.000001   1 
1   2 
1   1.000001 
1   2 
0.8852579   1 
1   2 
0.8852589   1 
1   2 
0.8852579   1.000001 
1   2 
0.7579142   1.006468 
1   2 
0.7579152   1.006468 
1   2 
0.7579142   1.006469 
1   2 
0.6147161   1.019478 
1   2 
0.6147171   1.019478 
1   2 
0.6147161   1.019479 
1   2 
0.4526649   1.03812 
1   2 
0.4526659   1.03812 
1   2 
0.4526649   1.038121 
1   2 
0.2737154   1.059075 
1   2 
0.2737164   1.059075 
1   2 
0.2737154   1.059076 
Fit Mean:  -1.999015  Size:  1.26674  Code:  1 
Try Mean:  1  Size:  0.1 
1   2 
1   0.1 
1   2 
1   0.1 
1   2 
1.000001   0.1 
1   2 
1   0.100001 
1   2 
0.9791378   0.1 
1   2 
0.9791388   0.1 
1   2 
0.9791378   0.100001 
1   2 
0.9574694   0.1040238 
1   2 
0.9574704   0.1040238 
1   2 
0.9574694   0.1040248 
1   2 
0.9340985   0.1123107 
1   2 
0.9340995   0.1123107 
1   2 
0.9340985   0.1123117 
1   2 
0.9079535   0.125194 
1   2 
0.9079545   0.125194 
1   2 
0.9079535   0.125195 
1   2 
0.8777353   0.1431219 
1   2 
0.8777363   0.1431219 
1   2 
0.8777353   0.1431229 
1   2 
0.8418344   0.1666709 
1   2 
0.8418354   0.1666709 
1   2 
0.8418344   0.1666719 
1   2 
0.7981994   0.1965498 
1   2 
0.7982004   0.1965498 
1   2 
0.7981994   0.1965508 
1   2 
0.744127   0.2335843 
1   2 
0.744128   0.2335843 
1   2 
0.744127   0.2335853 
1   2 
0.6759169   0.2786564 
1   2 
0.6759179   0.2786564 
1   2 
0.6759169   0.2786574 
1   2 
0.5882885   0.3325294 
1   2 
0.5882895   0.3325294 
1   2 
0.5882885   0.3325304 
1   2 
0.473406   0.3953252 
1   2 
0.473407   0.3953252 
1   2 
0.473406   0.3953262 
1   2 
0.3197017   0.4647901 
1   2 
0.3197027   0.4647901 
1   2 
0.3197017   0.4647911 
1   2 
0.1166947   0.529642 
1   2 
0.1166957   0.529642 
1   2 
0.1166947   0.529643 
Fit Mean:  -0.2931735  Size:  0.5861123  Code:  1 
Try Mean:  1  Size:  0.01 
1   2 
1   0.01 
1   2 
1   0.01 
1   2 
1.000001   0.01 
1   2 
1   0.010001 
1   2 
0.9977279   0.01 
1   2 
0.9977289   0.01 
1   2 
0.9977279   0.010001 
1   2 
0.9954455   0.01051228 
1   2 
0.9954465   0.01051228 
1   2 
0.9954455   0.01051328 
1   2 
0.9930366   0.01154041 
1   2 
0.9930376   0.01154041 
1   2 
0.9930366   0.01154141 
1   2 
0.9903821   0.01311283 
1   2 
0.9903831   0.01311283 
1   2 
0.9903821   0.01311383 
1   2 
0.9873547   0.01528351 
1   2 
0.9873557   0.01528351 
1   2 
0.9873547   0.01528451 
1   2 
0.9838126   0.01813355 
1   2 
0.9838136   0.01813355 
1   2 
0.9838126   0.01813455 
1   2 
0.9795925   0.02177378 
1   2 
0.9795935   0.02177378 
1   2 
0.9795925   0.02177478 
1   2 
0.9745013   0.02634851 
1   2 
0.9745023   0.02634851 
1   2 
0.9745013   0.02634951 
1   2 
0.9683067   0.03204043 
1   2 
0.9683077   0.03204043 
1   2 
0.9683067   0.03204143 
1   2 
0.9607252   0.03907674 
1   2 
0.9607262   0.03907674 
1   2 
0.9607252   0.03907774 
1   2 
0.9514063   0.04773656 
1   2 
0.9514073   0.04773656 
1   2 
0.9514063   0.04773756 
1   2 
0.9399141   0.05835953 
1   2 
0.9399151   0.05835953 
1   2 
0.9399141   0.05836053 
1   2 
0.9257007   0.07135569 
1   2 
0.9257017   0.07135569 
1   2 
0.9257007   0.07135669 
1   2 
0.908072   0.08721608 
1   2 
0.908073   0.08721608 
1   2 
0.908072   0.08721708 
1   2 
0.8861402   0.1065237 
1   2 
0.8861412   0.1065237 
1   2 
0.8861402   0.1065247 
1   2 
0.8587567   0.1299636 
1   2 
0.8587577   0.1299636 
1   2 
0.8587567   0.1299646 
1   2 
0.8244133   0.1583294 
1   2 
0.8244143   0.1583294 
1   2 
0.8244133   0.1583304 
1   2 
0.7810934   0.1925218 
1   2 
0.7810944   0.1925218 
1   2 
0.7810934   0.1925228 
1   2 
0.7260365   0.2335259 
1   2 
0.7260375   0.2335259 
1   2 
0.7260365   0.2335269 
1   2 
0.6553491   0.282336 
1   2 
0.6553501   0.282336 
1   2 
0.6553491   0.282337 
1   2 
0.5633425   0.3397348 
1   2 
0.5633435   0.3397348 
1   2 
0.5633425   0.3397358 
1   2 
0.4414424   0.4056156 
1   2 
0.4414434   0.4056156 
1   2 
0.4414424   0.4056166 
1   2 
0.2772021   0.4766453 
1   2 
0.2772031   0.4766453 
1   2 
0.2772021   0.4766463 
1   2 
0.06521172   0.5369926 
1   2 
0.06521272   0.5369926 
1   2 
0.06521172   0.5369936 
1   2 
0.05856208   0.5374853 
1   2 
0.06355142   0.5371156 
1   2 
0.06355242   0.5371156 
1   2 
0.06355142   0.5371166 
1   2 
0.06351351   0.537118 
1   2 
0.06351451   0.537118 
1   2 
0.06351351   0.537119 
1   2 
0.06351401   0.5371178 
1   2 
0.06351501   0.5371178 
1   2 
0.06351401   0.5371188 
Fit Mean:  0.06351401  Size:  0.5371178  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  0.06351401  Size:  0.5371178  Code:  1  Try Size:  0.01 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
1 2
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
Fallback to calculating off an estimate of just variance = mu + mu^2/size
Mu estimate= 1.075163  Size estimate = -1.149743 
Double fallback to calculating as just 10% of the mean
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 0
> print(nb_fit_mu);
[1] 0
> 
> print(m)
[1] 1.075163
> print(v)
[1] 0.06974178
> print(D)
[1] 0.06486621
> 
> print(deletion_propagation_coverage)
[1] -1
> 
> warnings()
> 

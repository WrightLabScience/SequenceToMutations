
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | 4a-_BHI_c50_out/07_error_calibration/61.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | 4a-_BHI_c50_out/output/calibration/61.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00220755 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 14 to 44.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  27.93701  Size:  10000 
14   44 
27.93701   10000 
14   44 
27.93701   10000 
14   44 
27.93704   10000 
14   44 
27.93701   10000.01 
14   44 
27.94284   10000 
14   44 
27.94287   10000 
14   44 
27.94284   10000.01 
14   44 
30.08369   10000 
14   44 
30.08372   10000 
14   44 
30.08369   10000.01 
14   44 
30.14473   10000 
14   44 
30.14476   10000 
14   44 
30.14473   10000.01 
14   44 
30.15027   10000 
14   44 
30.1503   10000 
14   44 
30.15027   10000.01 
14   44 
30.1503   10000 
14   44 
30.15033   10000 
14   44 
30.1503   10000.01 
Fit Mean:  30.1503  Size:  10000  Code:  2 
Try Mean:  27.93701  Size:  1000 
14   44 
27.93701   1000 
14   44 
27.93701   1000 
14   44 
27.93704   1000 
14   44 
27.93701   1000.001 
14   44 
27.94276   1000 
14   44 
27.94278   1000 
14   44 
27.94276   1000.001 
14   44 
30.11002   1000 
14   44 
30.11005   1000 
14   44 
30.11002   1000.001 
14   44 
30.17788   1000 
14   44 
30.17791   1000 
14   44 
30.17788   1000.001 
14   44 
30.18426   1000.001 
14   44 
30.18429   1000.001 
14   44 
30.18426   1000.002 
14   44 
30.1843   1000.001 
14   44 
30.18433   1000.001 
14   44 
30.1843   1000.002 
14   44 
30.18477   1000.004 
14   44 
30.1848   1000.004 
14   44 
30.18477   1000.005 
14   44 
30.18528   1000.012 
14   44 
30.18531   1000.012 
14   44 
30.18528   1000.013 
14   44 
30.18627   1000.038 
14   44 
30.1863   1000.038 
14   44 
30.18627   1000.039 
14   44 
30.18777   1000.104 
14   44 
30.1878   1000.104 
14   44 
30.18777   1000.105 
14   44 
30.19024   1000.29 
14   44 
30.19027   1000.29 
14   44 
30.19024   1000.291 
14   44 
30.1942   1000.779 
14   44 
30.19423   1000.779 
14   44 
30.1942   1000.78 
14   44 
30.20059   1002.077 
14   44 
30.20062   1002.077 
14   44 
30.20059   1002.078 
14   44 
30.21075   1005.478 
14   44 
30.21078   1005.478 
14   44 
30.21075   1005.479 
14   44 
30.22667   1014.307 
14   44 
30.2267   1014.307 
14   44 
30.22667   1014.308 
14   44 
30.25047   1036.731 
14   44 
30.2505   1036.731 
14   44 
30.25047   1036.732 
14   44 
30.2824   1091.306 
14   44 
30.28243   1091.306 
14   44 
30.2824   1091.307 
14   44 
30.31549   1214.971 
14   44 
30.31552   1214.971 
14   44 
30.31549   1214.972 
14   44 
30.32902   1473.668 
14   44 
30.32905   1473.668 
14   44 
30.32902   1473.669 
14   44 
30.28948   1965.537 
14   44 
30.28951   1965.537 
14   44 
30.28948   1965.539 
14   44 
30.19799   2694.01 
14   44 
30.19802   2694.01 
14   44 
30.19799   2694.013 
14   44 
30.12857   3408.218 
14   44 
30.1286   3408.218 
14   44 
30.12857   3408.221 
14   44 
30.09962   4053.46 
14   44 
30.09965   4053.46 
14   44 
30.09962   4053.464 
14   44 
30.09005   5071.145 
14   44 
30.09008   5071.145 
14   44 
30.09005   5071.15 
14   44 
30.10712   6718.62 
14   44 
30.10715   6718.62 
14   44 
30.10712   6718.627 
14   44 
30.13988   8943.6 
14   44 
30.13991   8943.6 
14   44 
30.13988   8943.609 
14   44 
30.16313   11423.35 
14   44 
30.16316   11423.35 
14   44 
30.16313   11423.36 
14   44 
30.17279   14431.64 
14   44 
30.17282   14431.64 
14   44 
30.17279   14431.65 
14   44 
30.17035   18893.77 
14   44 
30.17038   18893.77 
14   44 
30.17035   18893.79 
14   44 
30.15781   25272.29 
14   44 
30.15784   25272.29 
14   44 
30.15781   25272.31 
14   44 
30.1447   33205.77 
14   44 
30.14473   33205.77 
14   44 
30.1447   33205.8 
14   44 
30.13731   42660.05 
14   44 
30.13734   42660.05 
14   44 
30.13731   42660.1 
14   44 
30.13591   55443.99 
14   44 
30.13594   55443.99 
14   44 
30.13591   55444.05 
14   44 
30.13986   73635.63 
14   44 
30.13989   73635.63 
14   44 
30.13986   73635.7 
14   44 
30.14589   97570.11 
14   44 
30.14592   97570.11 
14   44 
30.14589   97570.21 
14   44 
30.15024   127119.3 
14   44 
30.15027   127119.3 
14   44 
30.15024   127119.4 
14   44 
30.15176   165484.5 
14   44 
30.15179   165484.5 
14   44 
30.15176   165484.6 
14   44 
30.15061   218804.7 
14   44 
30.15064   218804.7 
14   44 
30.15061   218804.9 
14   44 
30.14791   290568.4 
14   44 
30.14794   290568.4 
14   44 
30.14791   290568.7 
14   44 
30.14543   383188.6 
14   44 
30.14546   383188.6 
14   44 
30.14543   383189 
14   44 
30.14424   499807 
14   44 
30.14427   499807 
14   44 
30.14424   499807.5 
14   44 
30.14437   661225.5 
14   44 
30.1444   661225.5 
14   44 
30.14437   661226.2 
14   44 
30.14547   880746 
14   44 
30.1455   880746 
14   44 
30.14547   880746.9 
14   44 
30.14673   1169662 
14   44 
30.14676   1169662 
14   44 
30.14673   1169663 
14   44 
30.14738   1485027 
14   44 
30.14741   1485027 
14   44 
30.14738   1485028 
14   44 
30.14752   1953017 
14   44 
30.14755   1953017 
14   44 
30.14752   1953019 
14   44 
30.14715   2488308 
14   44 
30.14718   2488308 
14   44 
30.14715   2488311 
14   44 
30.14695   3045566 
14   44 
30.14698   3045566 
14   44 
30.14695   3045570 
14   44 
30.14663   3663427 
14   44 
30.14666   3663427 
14   44 
30.14663   3663431 
14   44 
30.1463   4663817 
14   44 
30.14633   4663817 
14   44 
30.1463   4663822 
14   44 
30.14619   5424562 
14   44 
30.14622   5424562 
14   44 
30.14619   5424567 
14   44 
30.14632   5575644 
14   44 
30.14635   5575644 
14   44 
30.14632   5575650 
14   44 
30.14629   6576034 
14   44 
30.14632   6576034 
14   44 
30.14629   6576041 
14   44 
30.14632   7576425 
14   44 
30.14635   7576425 
14   44 
30.14632   7576432 
14   44 
30.14641   7693203 
14   44 
30.14644   7693203 
14   44 
30.14641   7693211 
14   44 
30.14643   7588338 
14   44 
30.14642   7651815 
14   44 
30.14641   7679559 
14   44 
30.14641   7688556 
14   44 
30.14641   7691628 
14   44 
30.14641   7692667 
14   44 
30.14641   7693022 
14   44 
30.14641   7693143 
14   44 
30.14641   7693183 
14   44 
30.14641   7693197 
14   44 
30.14942   7693203 
14   44 
30.14339   7693203 
14   44 
30.14641   7693973 
14   44 
30.14641   7692434 
14   44 
30.14648   7721566 
14   44 
30.1495   7721566 
14   44 
30.14347   7721566 
14   44 
30.14648   7722338 
14   44 
30.14648   7720794 
14   44 
30.14651   7748824 
14   44 
30.14953   7748824 
14   44 
30.1435   7748824 
14   44 
30.14651   7749599 
14   44 
30.14651   7748049 
Fit Mean:  30.14651  Size:  7748824  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  30.14651  Size:  7748824  Code:  1  Try Size:  1000 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
14 44
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
7748824   30.14651 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 7748824
> print(nb_fit_mu);
[1] 30.14651
> 
> print(m)
[1] 37.46973
> print(v)
[1] 217.3662
> print(D)
[1] 5.801114
> 
> print(deletion_propagation_coverage)
[1] 16
> 
> warnings()
> 

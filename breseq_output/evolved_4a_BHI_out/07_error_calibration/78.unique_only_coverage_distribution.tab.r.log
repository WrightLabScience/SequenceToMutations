
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | 4a-_BHI_c50_out/07_error_calibration/78.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | 4a-_BHI_c50_out/output/calibration/78.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.0032686 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 23 to 49.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  29.43646  Size:  10000 
23   49 
29.43646   10000 
23   49 
29.43646   10000 
23   49 
29.43649   10000 
23   49 
29.43646   10000.01 
23   49 
29.44444   10000 
23   49 
29.44447   10000 
23   49 
29.44444   10000.01 
23   49 
36.93982   10000 
23   49 
36.93986   10000 
23   49 
36.93982   10000.01 
23   49 
39.43696   10000 
23   49 
39.437   10000 
23   49 
39.43696   10000.01 
23   49 
42.04249   10000 
23   49 
42.04253   10000 
23   49 
42.04249   10000.01 
23   49 
42.82842   10000 
23   49 
42.82847   10000 
23   49 
42.82842   10000.01 
23   49 
42.85155   10000 
23   49 
42.85159   10000 
23   49 
42.85155   10000.01 
23   49 
42.85135   10000 
23   49 
42.85139   10000 
23   49 
42.85135   10000.01 
23   49 
42.85135   10000 
23   49 
42.85139   10000 
23   49 
42.85135   10000.01 
Fit Mean:  42.85135  Size:  10000  Code:  2 
Try Mean:  29.43646  Size:  1000 
23   49 
29.43646   1000 
23   49 
29.43646   1000 
23   49 
29.43649   1000 
23   49 
29.43646   1000.001 
23   49 
29.44436   1000 
23   49 
29.44439   1000 
23   49 
29.44436   1000.001 
23   49 
37.00796   999.9995 
23   49 
37.00799   999.9995 
23   49 
37.00796   1000.001 
23   49 
39.56522   999.9989 
23   49 
39.56526   999.9989 
23   49 
39.56522   999.9999 
23   49 
42.1212   999.9976 
23   49 
42.12125   999.9976 
23   49 
42.1212   999.9986 
23   49 
42.84561   999.9967 
23   49 
42.84566   999.9967 
23   49 
42.84561   999.9977 
23   49 
42.87753   999.996 
23   49 
42.87757   999.996 
23   49 
42.87753   999.997 
23   49 
42.87751   999.9954 
23   49 
42.87755   999.9954 
23   49 
42.87751   999.9964 
Fit Mean:  42.87751  Size:  999.9954  Code:  2 
Try Mean:  29.43646  Size:  100 
23   49 
29.43646   100 
23   49 
29.43646   100 
23   49 
29.43649   100 
23   49 
29.43646   100.0001 
23   49 
29.44364   99.99996 
23   49 
29.44367   99.99996 
23   49 
29.44364   100.0001 
23   49 
37.62631   99.97235 
23   49 
37.62635   99.97235 
23   49 
37.62631   99.97245 
23   49 
40.54425   99.94403 
23   49 
40.54429   99.94403 
23   49 
40.54425   99.94413 
23   49 
42.81959   99.88876 
23   49 
42.81964   99.88876 
23   49 
42.81959   99.88886 
23   49 
43.44223   99.83761 
23   49 
43.44228   99.83761 
23   49 
43.44223   99.83771 
23   49 
43.52852   99.79358 
23   49 
43.52856   99.79358 
23   49 
43.52852   99.79368 
23   49 
43.58792   99.703 
23   49 
43.58796   99.703 
23   49 
43.58792   99.7031 
23   49 
43.72901   99.29024 
23   49 
43.72905   99.29024 
23   49 
43.72901   99.29034 
23   49 
43.94208   98.19342 
23   49 
43.94212   98.19342 
23   49 
43.94208   98.19352 
23   49 
44.34945   94.84847 
23   49 
44.3495   94.84847 
23   49 
44.34945   94.84856 
23   49 
45.2416   84.33678 
23   49 
45.24165   84.33678 
23   49 
45.2416   84.33687 
Fit Mean:  51.7591  Size:  -4.520815  Code:  1 
Try Mean:  29.43646  Size:  10 
23   49 
29.43646   10 
23   49 
29.43646   10 
23   49 
29.43649   10 
23   49 
29.43646   10.00001 
23   49 
29.43982   9.999207 
23   49 
29.43985   9.999207 
23   49 
29.43982   9.999217 
23   49 
38.33756   9.991222 
23   49 
38.3376   9.991222 
23   49 
38.33756   9.991232 
23   49 
45.06448   12.12017 
23   49 
45.06453   12.12017 
23   49 
45.06448   12.12018 
23   49 
50.96204   14.43561 
23   49 
50.96209   14.43561 
23   49 
50.96204   14.43563 
23   49 
52.05441   14.72071 
23   49 
52.05447   14.72071 
23   49 
52.05441   14.72072 
23   49 
52.53326   14.6675 
23   49 
52.53332   14.6675 
23   49 
52.53326   14.66751 
23   49 
53.96943   14.11853 
23   49 
53.96949   14.11853 
23   49 
53.96943   14.11855 
23   49 
58.22848   11.75956 
23   49 
58.22854   11.75956 
23   49 
58.22848   11.75958 
23   49 
62.50075   9.29974 
23   49 
62.50081   9.29974 
23   49 
62.50075   9.299749 
23   49 
71.30353   4.808743 
23   49 
63.45931   8.810705 
23   49 
63.45937   8.810705 
23   49 
63.45931   8.810714 
23   49 
65.69661   7.910935 
23   49 
65.69668   7.910935 
23   49 
65.69661   7.910943 
23   49 
65.9868   7.9884 
23   49 
65.98687   7.9884 
23   49 
65.9868   7.988408 
23   49 
70.6595   7.65893 
23   49 
70.65957   7.65893 
23   49 
70.6595   7.658937 
23   49 
77.46093   6.732189 
23   49 
77.46101   6.732189 
23   49 
77.46093   6.732196 
23   49 
85.48632   5.965378 
23   49 
85.48641   5.965378 
23   49 
85.48632   5.965384 
23   49 
90.21497   5.934583 
23   49 
90.21506   5.934583 
23   49 
90.21497   5.934589 
23   49 
100.7118   5.445655 
23   49 
100.7119   5.445655 
23   49 
100.7118   5.445661 
23   49 
111.2587   5.17034 
23   49 
111.2588   5.17034 
23   49 
111.2587   5.170345 
23   49 
123.1803   4.938577 
23   49 
123.1805   4.938577 
23   49 
123.1803   4.938581 
23   49 
140.0041   4.629315 
23   49 
140.0042   4.629315 
23   49 
140.0041   4.62932 
23   49 
168.1191   4.505951 
23   49 
168.1192   4.505951 
23   49 
168.1191   4.505955 
23   49 
223.3967   3.832288 
23   49 
185.0211   4.299967 
23   49 
185.0213   4.299967 
23   49 
185.0211   4.299972 
23   49 
214.4098   4.029357 
23   49 
199.6556   4.165213 
23   49 
199.6558   4.165213 
23   49 
199.6556   4.165217 
23   49 
208.705   4.120601 
23   49 
208.7052   4.120601 
23   49 
208.705   4.120605 
23   49 
241.8211   4.016905 
23   49 
241.8214   4.016905 
23   49 
241.8211   4.016909 
23   49 
274.492   3.920671 
23   49 
274.4923   3.920671 
23   49 
274.492   3.920675 
23   49 
321.6718   3.850354 
23   49 
321.6721   3.850354 
23   49 
321.6718   3.850358 
23   49 
396.7126   3.685314 
23   49 
396.713   3.685314 
23   49 
396.7126   3.685317 
23   49 
403.5827   3.739441 
23   49 
403.5831   3.739441 
23   49 
403.5827   3.739445 
23   49 
454.7821   3.698753 
23   49 
454.7826   3.698753 
23   49 
454.7821   3.698756 
23   49 
580.4173   3.592985 
23   49 
580.4179   3.592985 
23   49 
580.4173   3.592989 
23   49 
621.5299   3.595286 
23   49 
621.5305   3.595286 
23   49 
621.5299   3.595289 
23   49 
758.6202   3.551703 
23   49 
758.621   3.551703 
23   49 
758.6202   3.551707 
23   49 
892.7568   3.529755 
23   49 
892.7577   3.529755 
23   49 
892.7568   3.529758 
23   49 
1096.524   3.492894 
23   49 
1096.525   3.492894 
23   49 
1096.524   3.492897 
23   49 
1349.156   3.483507 
23   49 
1349.158   3.483507 
23   49 
1349.156   3.483511 
23   49 
1749.696   3.439656 
23   49 
1749.698   3.439656 
23   49 
1749.696   3.439659 
23   49 
1918.432   3.443096 
23   49 
1918.434   3.443096 
23   49 
1918.432   3.4431 
23   49 
2405.523   3.431804 
23   49 
2405.525   3.431804 
23   49 
2405.523   3.431807 
23   49 
2967.003   3.421396 
23   49 
2967.006   3.421396 
23   49 
2967.003   3.421399 
23   49 
3742.417   3.413942 
23   49 
3742.42   3.413942 
23   49 
3742.417   3.413946 
23   49 
4751.139   3.405283 
23   49 
4751.144   3.405283 
23   49 
4751.139   3.405286 
23   49 
6087.358   3.403113 
23   49 
6087.364   3.403113 
23   49 
6087.358   3.403117 
23   49 
8122   3.390932 
23   49 
8122.008   3.390932 
23   49 
8122   3.390936 
23   49 
10059.14   3.392009 
23   49 
10059.15   3.392009 
23   49 
10059.14   3.392012 
23   49 
12919.59   3.38971 
23   49 
12919.6   3.38971 
23   49 
12919.59   3.389713 
23   49 
16767.85   3.387652 
23   49 
16767.87   3.387652 
23   49 
16767.85   3.387655 
23   49 
21821.33   3.386186 
23   49 
21821.35   3.386186 
23   49 
21821.33   3.386189 
23   49 
28515.72   3.384963 
23   49 
28515.75   3.384963 
23   49 
28515.72   3.384967 
23   49 
37377.78   3.384089 
23   49 
37377.81   3.384089 
23   49 
37377.78   3.384092 
23   49 
49126.91   3.383348 
23   49 
49126.96   3.383348 
23   49 
49126.91   3.383352 
23   49 
64651.95   3.382858 
23   49 
64652.02   3.382858 
23   49 
64651.95   3.382861 
23   49 
85192.43   3.3824 
23   49 
85192.52   3.3824 
23   49 
85192.43   3.382403 
23   49 
112500.5   3.382147 
23   49 
112500.7   3.382147 
23   49 
112500.5   3.382151 
23   49 
143589.2   3.381881 
23   49 
143589.4   3.381881 
23   49 
143589.2   3.381884 
23   49 
174677.9   3.381799 
23   49 
174678.1   3.381799 
23   49 
174677.9   3.381803 
Fit Mean:  174677.9  Size:  3.381799  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  174677.9  Size:  3.381799  Code:  1  Try Size:  10 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
23 49
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
Fallback to calculating off an estimate of just variance = mu + mu^2/size
Mu estimate= 29.43646  Size estimate = 4.153471 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 0
> print(nb_fit_mu);
[1] 0
> 
> print(m)
[1] 29.43646
> print(v)
[1] 238.0584
> print(D)
[1] 8.087196
> 
> print(deletion_propagation_coverage)
[1] 3
> 
> warnings()
> 

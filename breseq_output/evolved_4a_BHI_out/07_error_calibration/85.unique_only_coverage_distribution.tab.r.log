
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | 4a-_BHI_c50_out/07_error_calibration/85.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | 4a-_BHI_c50_out/output/calibration/85.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00396526 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 3 to 11.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  5.534091  Size:  10000 
3   11 
5.534091   10000 
3   11 
5.534091   10000 
3   11 
5.534096   10000 
3   11 
5.534091   10000.01 
3   11 
5.573127   10000 
3   11 
5.573133   10000 
3   11 
5.573127   10000.01 
3   11 
6.994745   10000 
3   11 
6.994752   10000 
3   11 
6.994745   10000.01 
3   11 
7.16107   10000 
3   11 
7.161077   10000 
3   11 
7.16107   10000.01 
3   11 
7.194092   10000 
3   11 
7.194099   10000 
3   11 
7.194092   10000.01 
3   11 
7.195077   10000 
3   11 
7.195084   10000 
3   11 
7.195077   10000.01 
3   11 
7.195082   10000 
3   11 
7.195089   10000 
3   11 
7.195082   10000.01 
Fit Mean:  7.195082  Size:  10000  Code:  2 
Try Mean:  5.534091  Size:  1000 
3   11 
5.534091   1000 
3   11 
5.534091   1000 
3   11 
5.534096   1000 
3   11 
5.534091   1000.001 
3   11 
5.572964   1000 
3   11 
5.572969   1000 
3   11 
5.572964   1000.001 
3   11 
6.992966   1000 
3   11 
6.992973   1000 
3   11 
6.992966   1000.001 
3   11 
7.162613   1000 
3   11 
7.16262   1000 
3   11 
7.162613   1000.001 
3   11 
7.196851   1000 
3   11 
7.196858   1000 
3   11 
7.196851   1000.001 
3   11 
7.197906   1000 
3   11 
7.197913   1000 
3   11 
7.197906   1000.001 
3   11 
7.197912   1000 
3   11 
7.197919   1000 
3   11 
7.197912   1000.001 
Fit Mean:  7.197912  Size:  1000  Code:  2 
Try Mean:  5.534091  Size:  100 
3   11 
5.534091   100 
3   11 
5.534091   100 
3   11 
5.534096   100 
3   11 
5.534091   100.0001 
3   11 
5.57139   100 
3   11 
5.571396   100 
3   11 
5.57139   100.0001 
3   11 
6.9771   100.0008 
3   11 
6.977107   100.0008 
3   11 
6.9771   100.0009 
3   11 
7.178269   100.0014 
3   11 
7.178276   100.0014 
3   11 
7.178269   100.0015 
3   11 
7.225349   100.0019 
3   11 
7.225356   100.0019 
3   11 
7.225349   100.002 
3   11 
7.227289   100.0023 
3   11 
7.227296   100.0023 
3   11 
7.227289   100.0024 
3   11 
7.227408   100.0027 
3   11 
7.227415   100.0027 
3   11 
7.227408   100.0028 
3   11 
7.229176   100.015 
3   11 
7.229183   100.015 
3   11 
7.229176   100.0151 
3   11 
7.231057   100.0407 
3   11 
7.231064   100.0407 
3   11 
7.231057   100.0408 
3   11 
7.23468   100.1276 
3   11 
7.234688   100.1276 
3   11 
7.23468   100.1277 
3   11 
7.240109   100.3521 
3   11 
7.240116   100.3521 
3   11 
7.240109   100.3522 
3   11 
7.248879   100.9664 
3   11 
7.248887   100.9664 
3   11 
7.248879   100.9665 
3   11 
7.262092   102.5508 
3   11 
7.2621   102.5508 
3   11 
7.262092   102.5509 
3   11 
7.280656   106.5287 
3   11 
7.280663   106.5287 
3   11 
7.280656   106.5288 
3   11 
7.301989   115.8532 
3   11 
7.301997   115.8532 
3   11 
7.301989   115.8533 
3   11 
7.316093   136.133 
3   11 
7.3161   136.133 
3   11 
7.316093   136.1331 
3   11 
7.302753   177.1499 
3   11 
7.30276   177.1499 
3   11 
7.302753   177.1501 
3   11 
7.247829   246.2075 
3   11 
7.247836   246.2075 
3   11 
7.247829   246.2078 
3   11 
7.19309   321.896 
3   11 
7.193097   321.896 
3   11 
7.19309   321.8963 
3   11 
7.169902   383.5196 
3   11 
7.169909   383.5196 
3   11 
7.169902   383.5199 
3   11 
7.160482   469.8951 
3   11 
7.160489   469.8951 
3   11 
7.160482   469.8956 
3   11 
7.16722   617.0933 
3   11 
7.167227   617.0933 
3   11 
7.16722   617.094 
3   11 
7.18728   824.3691 
3   11 
7.187287   824.3691 
3   11 
7.18728   824.3699 
3   11 
7.203591   1062.423 
3   11 
7.203598   1062.423 
3   11 
7.203591   1062.424 
3   11 
7.210862   1342.469 
3   11 
7.210869   1342.469 
3   11 
7.210862   1342.47 
3   11 
7.210341   1750.281 
3   11 
7.210349   1750.281 
3   11 
7.210341   1750.282 
3   11 
7.203014   2340.21 
3   11 
7.203021   2340.21 
3   11 
7.203014   2340.213 
3   11 
7.194599   3087.77 
3   11 
7.194606   3087.77 
3   11 
7.194599   3087.773 
3   11 
7.189609   3981.744 
3   11 
7.189617   3981.744 
3   11 
7.189609   3981.748 
3   11 
7.188448   5175.902 
3   11 
7.188455   5175.902 
3   11 
7.188448   5175.908 
3   11 
7.190677   6865.774 
3   11 
7.190684   6865.774 
3   11 
7.190677   6865.781 
3   11 
7.194312   9101.986 
3   11 
7.194319   9101.986 
3   11 
7.194312   9101.995 
3   11 
7.196986   11889.74 
3   11 
7.196993   11889.74 
3   11 
7.196986   11889.75 
3   11 
7.19792   15514.4 
3   11 
7.197928   15514.4 
3   11 
7.19792   15514.41 
3   11 
7.197215   20531.08 
3   11 
7.197222   20531.08 
3   11 
7.197215   20531.1 
3   11 
7.195588   27321.33 
3   11 
7.195595   27321.33 
3   11 
7.195588   27321.36 
3   11 
7.194149   35933.93 
3   11 
7.194156   35933.93 
3   11 
7.194149   35933.96 
3   11 
7.193458   47075.33 
3   11 
7.193465   47075.33 
3   11 
7.193458   47075.38 
3   11 
7.193571   62225.66 
3   11 
7.193578   62225.66 
3   11 
7.193571   62225.73 
3   11 
7.19423   83058.52 
3   11 
7.194238   83058.52 
3   11 
7.19423   83058.6 
3   11 
7.194934   109425.2 
3   11 
7.194942   109425.2 
3   11 
7.194934   109425.3 
3   11 
7.19532   141384.8 
3   11 
7.195328   141384.8 
3   11 
7.19532   141384.9 
3   11 
7.195349   183990.3 
3   11 
7.195356   183990.3 
3   11 
7.195349   183990.5 
3   11 
7.195107   254121.4 
3   11 
7.195115   254121.4 
3   11 
7.195107   254121.6 
3   11 
7.194802   354274.4 
3   11 
7.194809   354274.4 
3   11 
7.194802   354274.7 
3   11 
7.194742   383725.1 
3   11 
7.194749   383725.1 
3   11 
7.194742   383725.5 
3   11 
7.194665   440604.5 
3   11 
7.194673   440604.5 
3   11 
7.194665   440605 
3   11 
7.194623   540757.5 
3   11 
7.19463   540757.5 
3   11 
7.194623   540758.1 
3   11 
7.194674   626532.5 
3   11 
7.194681   626532.5 
3   11 
7.194674   626533.1 
3   11 
7.194731   659052.2 
3   11 
7.194738   659052.2 
3   11 
7.194731   659052.9 
3   11 
7.194773   759205.2 
3   11 
7.19478   759205.2 
3   11 
7.194773   759206 
Fit Mean:  7.194773  Size:  759205.2  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  7.194773  Size:  759205.2  Code:  1  Try Size:  100 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
3 11
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
759205.2   7.194773 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 759205.2
> print(nb_fit_mu);
[1] 7.194773
> 
> print(m)
[1] 5.707865
> print(v)
[1] 10.41369
> print(D)
[1] 1.824445
> 
> print(deletion_propagation_coverage)
[1] 1
> 
> warnings()
> 

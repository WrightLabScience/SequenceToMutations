
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | 4a-_BHI_c50_out/07_error_calibration/75.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | 4a-_BHI_c50_out/output/calibration/75.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00310685 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 6 to 20.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  13.11628  Size:  10000 
6   20 
13.11628   10000 
6   20 
13.11628   10000 
6   20 
13.11629   10000 
6   20 
13.11628   10000.01 
6   20 
13.11598   10000 
6   20 
13.11599   10000 
6   20 
13.11598   10000.01 
6   20 
13.0873   10000 
6   20 
13.08732   10000 
6   20 
13.0873   10000.01 
6   20 
13.08739   10000 
6   20 
13.08741   10000 
6   20 
13.08739   10000.01 
6   20 
13.08739   10000 
6   20 
13.0887   10000 
6   20 
13.08608   10000 
6   20 
13.08739   10001 
6   20 
13.08739   9999 
6   20 
13.0874   10000 
6   20 
13.08871   10000 
6   20 
13.08609   10000 
6   20 
13.0874   10001 
6   20 
13.0874   9999 
Fit Mean:  13.0874  Size:  10000  Code:  2 
Try Mean:  13.11628  Size:  1000 
6   20 
13.11628   1000 
6   20 
13.11628   1000 
6   20 
13.11629   1000 
6   20 
13.11628   1000.001 
6   20 
13.11607   1000 
6   20 
13.11608   1000 
6   20 
13.11607   1000.001 
6   20 
13.09562   1000 
6   20 
13.09563   1000 
6   20 
13.09562   1000.001 
6   20 
13.09566   1000 
6   20 
13.09568   1000 
6   20 
13.09566   1000.001 
6   20 
13.09569   1000 
6   20 
13.0957   1000 
6   20 
13.09569   1000.001 
6   20 
13.09576   1000.001 
6   20 
13.09578   1000.001 
6   20 
13.09576   1000.002 
6   20 
13.09586   1000.002 
6   20 
13.09588   1000.002 
6   20 
13.09586   1000.003 
6   20 
13.09604   1000.005 
6   20 
13.09605   1000.005 
6   20 
13.09604   1000.006 
6   20 
13.09631   1000.013 
6   20 
13.09633   1000.013 
6   20 
13.09631   1000.014 
6   20 
13.09676   1000.037 
6   20 
13.09678   1000.037 
6   20 
13.09676   1000.038 
6   20 
13.09749   1000.098 
6   20 
13.0975   1000.098 
6   20 
13.09749   1000.099 
6   20 
13.09866   1000.261 
6   20 
13.09867   1000.261 
6   20 
13.09866   1000.262 
6   20 
13.10055   1000.689 
6   20 
13.10056   1000.689 
6   20 
13.10055   1000.69 
6   20 
13.1036   1001.812 
6   20 
13.10361   1001.812 
6   20 
13.1036   1001.813 
6   20 
13.10848   1004.745 
6   20 
13.10849   1004.745 
6   20 
13.10848   1004.746 
6   20 
13.11618   1012.347 
6   20 
13.1162   1012.347 
6   20 
13.11618   1012.348 
6   20 
13.12789   1031.701 
6   20 
13.1279   1031.701 
6   20 
13.12789   1031.702 
6   20 
13.14417   1079.121 
6   20 
13.14418   1079.121 
6   20 
13.14417   1079.122 
6   20 
13.16248   1187.487 
6   20 
13.1625   1187.487 
6   20 
13.16248   1187.488 
6   20 
13.17373   1414.691 
6   20 
13.17374   1414.691 
6   20 
13.17373   1414.692 
6   20 
13.16157   1849.879 
6   20 
13.16158   1849.879 
6   20 
13.16157   1849.881 
6   20 
13.11975   2530.095 
6   20 
13.11976   2530.095 
6   20 
13.11975   2530.098 
6   20 
13.08074   3265.465 
6   20 
13.08076   3265.465 
6   20 
13.08074   3265.469 
6   20 
13.06285   3928 
6   20 
13.06286   3928 
6   20 
13.06285   3928.003 
6   20 
13.05611   4856.436 
6   20 
13.05612   4856.436 
6   20 
13.05611   4856.441 
6   20 
13.06237   6398.013 
6   20 
13.06238   6398.013 
6   20 
13.06237   6398.019 
6   20 
13.07891   8565.556 
6   20 
13.07892   8565.556 
6   20 
13.07891   8565.565 
6   20 
13.09261   11045.47 
6   20 
13.09262   11045.47 
6   20 
13.09261   11045.48 
6   20 
13.09909   13908.07 
6   20 
13.0991   13908.07 
6   20 
13.09909   13908.08 
6   20 
13.0994   18032.08 
6   20 
13.09941   18032.08 
6   20 
13.0994   18032.09 
6   20 
13.09388   24072.4 
6   20 
13.09389   24072.4 
6   20 
13.09388   24072.43 
6   20 
13.08674   31828.47 
6   20 
13.08675   31828.47 
6   20 
13.08674   31828.5 
6   20 
13.08215   40986.75 
6   20 
13.08216   40986.75 
6   20 
13.08215   40986.79 
6   20 
13.0807   52924.89 
6   20 
13.08071   52924.89 
6   20 
13.0807   52924.94 
6   20 
13.08217   70022.73 
6   20 
13.08218   70022.73 
6   20 
13.08217   70022.8 
6   20 
13.08529   93086.5 
6   20 
13.0853   93086.5 
6   20 
13.08529   93086.59 
6   20 
13.08792   121668.5 
6   20 
13.08793   121668.5 
6   20 
13.08792   121668.7 
6   20 
13.08914   157833.3 
6   20 
13.08915   157833.3 
6   20 
13.08914   157833.5 
6   20 
13.08892   208674.2 
6   20 
13.08893   208674.2 
6   20 
13.08892   208674.5 
6   20 
13.08765   275619 
6   20 
13.08766   275619 
6   20 
13.08765   275619.3 
6   20 
13.08622   363891.5 
6   20 
13.08623   363891.5 
6   20 
13.08622   363891.9 
6   20 
13.08531   480530.2 
6   20 
13.08533   480530.2 
6   20 
13.08531   480530.7 
6   20 
13.08493   686478.2 
6   20 
13.08495   686478.2 
6   20 
13.08493   686478.9 
6   20 
13.08545   857590.4 
6   20 
13.08546   857590.4 
6   20 
13.08545   857591.3 
6   20 
13.08622   1030051 
6   20 
13.08623   1030051 
6   20 
13.08622   1030052 
6   20 
13.08661   1195868 
6   20 
13.08662   1195868 
6   20 
13.08661   1195869 
6   20 
13.08664   1265570 
6   20 
13.08665   1265570 
6   20 
13.08664   1265572 
6   20 
13.08674   1402438 
6   20 
13.08675   1402438 
6   20 
13.08674   1402439 
6   20 
13.08661   1387051 
6   20 
13.08672   1400674 
6   20 
13.08674   1402248 
6   20 
13.08674   1402417 
6   20 
13.08674   1402436 
6   20 
13.08674   1402438 
6   20 
13.08805   1402438 
6   20 
13.08543   1402438 
6   20 
13.08674   1402578 
6   20 
13.08674   1402298 
6   20 
13.08666   1494771 
6   20 
13.08796   1494771 
6   20 
13.08535   1494771 
6   20 
13.08666   1494920 
6   20 
13.08666   1494621 
6   20 
13.08629   2112249 
6   20 
13.0876   2112249 
6   20 
13.08498   2112249 
6   20 
13.08629   2112460 
6   20 
13.08629   2112038 
6   20 
13.08619   2720489 
6   20 
13.0875   2720489 
6   20 
13.08488   2720489 
6   20 
13.08619   2720761 
6   20 
13.08619   2720217 
6   20 
13.08625   3673432 
6   20 
13.08755   3673432 
6   20 
13.08494   3673432 
6   20 
13.08625   3673799 
6   20 
13.08625   3673065 
6   20 
13.08637   4673518 
6   20 
13.08768   4673518 
6   20 
13.08507   4673518 
6   20 
13.08637   4673985 
6   20 
13.08637   4673051 
6   20 
13.08645   5375780 
6   20 
13.08776   5375780 
6   20 
13.08514   5375780 
6   20 
13.08645   5376317 
6   20 
13.08645   5375242 
6   20 
13.08648   5881878 
6   20 
13.08779   5881878 
6   20 
13.08517   5881878 
6   20 
13.08648   5882466 
6   20 
13.08648   5881289 
Fit Mean:  13.08648  Size:  5881878  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  13.08648  Size:  5881878  Code:  1  Try Size:  1000 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
6 20
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
5881878   13.08648 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 5881878
> print(nb_fit_mu);
[1] 13.08648
> 
> print(m)
[1] 14.3
> print(v)
[1] 13.35714
> print(D)
[1] 0.9340659
> 
> print(deletion_propagation_coverage)
[1] 4
> 
> warnings()
> 

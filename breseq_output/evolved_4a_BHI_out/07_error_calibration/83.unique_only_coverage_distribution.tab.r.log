
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | 4a-_BHI_c50_out/07_error_calibration/83.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | 4a-_BHI_c50_out/output/calibration/83.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00379049 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 8 to 18.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  13.975  Size:  10000 
8   18 
13.975   10000 
8   18 
13.975   10000 
8   18 
13.97501   10000 
8   18 
13.975   10000.01 
8   18 
14.01344   10000 
8   18 
14.01345   10000 
8   18 
14.01344   10000.01 
8   18 
29.16413   10000 
8   18 
29.16416   10000 
8   18 
29.16413   10000.01 
8   18 
27.345   10000 
8   18 
27.34503   10000 
8   18 
27.345   10000.01 
8   18 
23.16228   10000 
8   18 
23.1623   10000 
8   18 
23.16228   10000.01 
8   18 
25.13074   10000 
8   18 
25.13077   10000 
8   18 
25.13074   10000.01 
8   18 
24.7842   10000 
8   18 
24.78422   10000 
8   18 
24.7842   10000.01 
8   18 
24.72496   10000 
8   18 
24.72498   10000 
8   18 
24.72496   10000.01 
8   18 
24.72721   10000 
8   18 
24.72724   10000 
8   18 
24.72721   10000.01 
8   18 
24.7272   10000 
8   18 
24.72969   10000 
8   18 
24.72474   10000 
8   18 
24.72721   10001 
8   18 
24.72721   9999 
8   18 
24.72721   10000 
8   18 
24.72969   10000 
8   18 
24.72474   10000 
8   18 
24.72721   10001 
8   18 
24.72721   9999 
Fit Mean:  24.72721  Size:  10000  Code:  2 
Try Mean:  13.975  Size:  1000 
8   18 
13.975   1000 
8   18 
13.975   1000 
8   18 
13.97501   1000 
8   18 
13.975   1000.001 
8   18 
14.01306   1000 
8   18 
14.01307   1000 
8   18 
14.01306   1000.001 
8   18 
28.8633   1000.002 
8   18 
28.86333   1000.002 
8   18 
28.8633   1000.003 
8   18 
27.2644   1000.002 
8   18 
27.26443   1000.002 
8   18 
27.2644   1000.003 
8   18 
23.75825   1000 
8   18 
23.75827   1000 
8   18 
23.75825   1000.001 
8   18 
25.20712   1000.001 
8   18 
25.20715   1000.001 
8   18 
25.20712   1000.002 
8   18 
24.9641   1000.001 
8   18 
24.96413   1000.001 
8   18 
24.9641   1000.002 
8   18 
24.93402   1000.001 
8   18 
24.93404   1000.001 
8   18 
24.93402   1000.002 
8   18 
24.93479   1000.001 
8   18 
24.93482   1000.001 
8   18 
24.93479   1000.002 
8   18 
24.9348   1000.001 
8   18 
24.93482   1000.001 
8   18 
24.9348   1000.002 
Fit Mean:  24.9348  Size:  1000.001  Code:  2 
Try Mean:  13.975  Size:  100 
8   18 
13.975   100 
8   18 
13.975   100 
8   18 
13.97501   100 
8   18 
13.975   100.0001 
8   18 
14.00968   100 
8   18 
14.00969   100 
8   18 
14.00968   100.0001 
8   18 
26.71624   100.1645 
8   18 
26.71627   100.1645 
8   18 
26.71624   100.1646 
8   18 
26.90254   100.1762 
8   18 
26.90256   100.1762 
8   18 
26.90254   100.1763 
8   18 
27.20796   100.1998 
8   18 
27.20799   100.1998 
8   18 
27.20796   100.1999 
8   18 
27.22212   100.2053 
8   18 
27.22215   100.2053 
8   18 
27.22212   100.2054 
8   18 
27.22618   100.2124 
8   18 
27.2262   100.2124 
8   18 
27.22618   100.2125 
8   18 
27.24091   100.2657 
8   18 
27.24093   100.2657 
8   18 
27.24091   100.2658 
8   18 
27.25779   100.3924 
8   18 
27.25781   100.3924 
8   18 
27.25779   100.3925 
8   18 
27.28319   100.7828 
8   18 
27.28322   100.7828 
8   18 
27.28319   100.7829 
8   18 
27.31027   101.8014 
8   18 
27.31029   101.8014 
8   18 
27.31027   101.8015 
8   18 
27.32236   104.5379 
8   18 
27.32239   104.5379 
8   18 
27.32236   104.538 
8   18 
27.25988   111.9548 
8   18 
27.2599   111.9548 
8   18 
27.25988   111.955 
8   18 
26.88238   137.6686 
8   18 
26.8824   137.6686 
8   18 
26.88238   137.6688 
8   18 
18.98856   639.9309 
8   18 
26.09299   187.8949 
8   18 
26.09302   187.8949 
8   18 
26.09299   187.895 
8   18 
24.25922   311.1038 
8   18 
25.71394   213.3628 
8   18 
25.71397   213.3628 
8   18 
25.71394   213.363 
8   18 
25.5142   230.2123 
8   18 
25.51423   230.2123 
8   18 
25.5142   230.2125 
8   18 
25.47146   238.6389 
8   18 
25.47148   238.6389 
8   18 
25.47146   238.6392 
8   18 
25.30058   309.1676 
8   18 
25.30061   309.1676 
8   18 
25.30058   309.1679 
8   18 
25.24557   373.926 
8   18 
25.24559   373.926 
8   18 
25.24557   373.9264 
8   18 
25.11927   478.4399 
8   18 
25.1193   478.4399 
8   18 
25.11927   478.4404 
8   18 
25.02644   611.7239 
8   18 
25.02647   611.7239 
8   18 
25.02644   611.7246 
8   18 
24.95667   787.6722 
8   18 
24.9567   787.6722 
8   18 
24.95667   787.673 
8   18 
24.89603   1020.585 
8   18 
24.89605   1020.585 
8   18 
24.89603   1020.586 
8   18 
24.85758   1328.096 
8   18 
24.8576   1328.096 
8   18 
24.85758   1328.098 
8   18 
24.80857   1739.933 
8   18 
24.80859   1739.933 
8   18 
24.80857   1739.934 
8   18 
24.81101   2285.637 
8   18 
24.81103   2285.637 
8   18 
24.81101   2285.639 
8   18 
24.72911   3100.847 
8   18 
24.72913   3100.847 
8   18 
24.72911   3100.85 
8   18 
24.75105   4002.751 
8   18 
24.75108   4002.751 
8   18 
24.75105   4002.755 
8   18 
24.74062   5229.035 
8   18 
24.74064   5229.035 
8   18 
24.74062   5229.04 
8   18 
24.72954   6919.236 
8   18 
24.72957   6919.236 
8   18 
24.72954   6919.243 
8   18 
24.72341   9116.29 
8   18 
24.72344   9116.29 
8   18 
24.72341   9116.299 
8   18 
24.71886   12038.1 
8   18 
24.71888   12038.1 
8   18 
24.71886   12038.11 
8   18 
24.71533   15903.57 
8   18 
24.71535   15903.57 
8   18 
24.71533   15903.58 
8   18 
24.71266   21027.45 
8   18 
24.71268   21027.45 
8   18 
24.71266   21027.47 
8   18 
24.71063   27811.51 
8   18 
24.71066   27811.51 
8   18 
24.71063   27811.54 
8   18 
24.7091   36795.25 
8   18 
24.70913   36795.25 
8   18 
24.7091   36795.29 
8   18 
24.70794   48714.14 
8   18 
24.70796   48714.14 
8   18 
24.70794   48714.19 
8   18 
24.70706   64537.57 
8   18 
24.70708   64537.57 
8   18 
24.70706   64537.64 
8   18 
24.7064   85431.42 
8   18 
24.70642   85431.42 
8   18 
24.7064   85431.51 
8   18 
24.70592   112537 
8   18 
24.70595   112537 
8   18 
24.70592   112537.1 
8   18 
24.70548   151099.8 
8   18 
24.70551   151099.8 
8   18 
24.70548   151099.9 
8   18 
24.70525   198574.3 
8   18 
24.70527   198574.3 
8   18 
24.70525   198574.5 
8   18 
24.70497   269506.9 
8   18 
24.705   269506.9 
8   18 
24.70497   269507.2 
8   18 
24.70489   346541 
8   18 
24.70491   346541 
8   18 
24.70489   346541.3 
8   18 
24.70473   447512.8 
8   18 
24.70476   447512.8 
8   18 
24.70473   447513.2 
8   18 
24.70472   548484.5 
8   18 
24.70475   548484.5 
8   18 
24.70472   548485.1 
8   18 
24.70465   649456.3 
8   18 
24.70467   649456.3 
8   18 
24.70465   649457 
8   18 
24.70465   750428.1 
8   18 
24.70467   750428.1 
8   18 
24.70465   750428.9 
Fit Mean:  24.70465  Size:  750428.1  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  24.70465  Size:  750428.1  Code:  1  Try Size:  100 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
8 18
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
750428.1   24.70465 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 750428.1
> print(nb_fit_mu);
[1] 24.70465
> 
> print(m)
[1] 13.975
> print(v)
[1] 34.48654
> print(D)
[1] 2.467731
> 
> print(deletion_propagation_coverage)
[1] 13
> 
> warnings()
> 

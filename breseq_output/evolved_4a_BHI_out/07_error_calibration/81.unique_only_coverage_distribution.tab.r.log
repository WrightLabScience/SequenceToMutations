
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | 4a-_BHI_c50_out/07_error_calibration/81.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | 4a-_BHI_c50_out/output/calibration/81.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00345857 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 31 to 82.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  53.27778  Size:  10000 
31   82 
53.27778   10000 
31   82 
53.27778   10000 
31   82 
53.27783   10000 
31   82 
53.27778   10000.01 
31   82 
53.28263   10000 
31   82 
53.28268   10000 
31   82 
53.28263   10000.01 
31   82 
61.72449   10000 
31   82 
61.72456   10000 
31   82 
61.72449   10000.01 
31   82 
59.52801   10000 
31   82 
59.52807   10000 
31   82 
59.52801   10000.01 
31   82 
59.52928   10000 
31   82 
59.52934   10000 
31   82 
59.52928   10000.01 
31   82 
59.5292   10000 
31   82 
59.52926   10000 
31   82 
59.5292   10000.01 
31   82 
59.5292   10000 
31   82 
59.52926   10000 
31   82 
59.5292   10000.01 
Fit Mean:  59.5292  Size:  10000  Code:  2 
Try Mean:  53.27778  Size:  1000 
31   82 
53.27778   1000 
31   82 
53.27778   1000 
31   82 
53.27783   1000 
31   82 
53.27778   1000.001 
31   82 
53.28247   1000 
31   82 
53.28252   1000 
31   82 
53.28247   1000.001 
31   82 
61.61943   1000.002 
31   82 
61.61949   1000.002 
31   82 
61.61943   1000.003 
31   82 
59.5638   1000.002 
31   82 
59.56386   1000.002 
31   82 
59.5638   1000.003 
31   82 
59.55109   1000.002 
31   82 
59.55115   1000.002 
31   82 
59.55109   1000.003 
31   82 
59.55181   1000.003 
31   82 
59.55187   1000.003 
31   82 
59.55181   1000.004 
31   82 
59.55229   1000.005 
31   82 
59.55235   1000.005 
31   82 
59.55229   1000.006 
31   82 
59.5535   1000.013 
31   82 
59.55356   1000.013 
31   82 
59.5535   1000.014 
31   82 
59.55518   1000.034 
31   82 
59.55524   1000.034 
31   82 
59.55518   1000.035 
31   82 
59.55808   1000.097 
31   82 
59.55814   1000.097 
31   82 
59.55808   1000.098 
31   82 
59.56265   1000.265 
31   82 
59.56271   1000.265 
31   82 
59.56265   1000.266 
31   82 
59.5701   1000.72 
31   82 
59.57016   1000.72 
31   82 
59.5701   1000.721 
31   82 
59.58206   1001.924 
31   82 
59.58212   1001.924 
31   82 
59.58206   1001.925 
31   82 
59.60121   1005.093 
31   82 
59.60127   1005.093 
31   82 
59.60121   1005.094 
31   82 
59.63136   1013.327 
31   82 
59.63142   1013.327 
31   82 
59.63136   1013.328 
31   82 
59.67691   1034.283 
31   82 
59.67697   1034.283 
31   82 
59.67691   1034.284 
31   82 
59.73922   1085.349 
31   82 
59.73928   1085.349 
31   82 
59.73922   1085.35 
31   82 
59.8066   1200.922 
31   82 
59.80666   1200.922 
31   82 
59.8066   1200.923 
31   82 
59.84167   1441.096 
31   82 
59.84173   1441.096 
31   82 
59.84167   1441.097 
31   82 
59.78192   1895.338 
31   82 
59.78198   1895.338 
31   82 
59.78192   1895.34 
31   82 
59.62057   2577.007 
31   82 
59.62063   2577.007 
31   82 
59.62057   2577.01 
31   82 
59.4896   3276.069 
31   82 
59.48966   3276.069 
31   82 
59.4896   3276.073 
31   82 
59.43298   3928.632 
31   82 
59.43303   3928.632 
31   82 
59.43298   3928.636 
31   82 
59.41578   4918.812 
31   82 
59.41584   4918.812 
31   82 
59.41578   4918.817 
31   82 
59.44864   6521.083 
31   82 
59.4487   6521.083 
31   82 
59.44864   6521.089 
31   82 
59.51084   8687.472 
31   82 
59.5109   8687.472 
31   82 
59.51084   8687.481 
31   82 
59.55539   11107.29 
31   82 
59.55545   11107.29 
31   82 
59.55539   11107.3 
31   82 
59.5742   14030.26 
31   82 
59.57426   14030.26 
31   82 
59.5742   14030.27 
31   82 
59.57014   18347.58 
31   82 
59.5702   18347.58 
31   82 
59.57014   18347.6 
31   82 
59.54699   24507.61 
31   82 
59.54705   24507.61 
31   82 
59.54699   24507.64 
31   82 
59.52261   32185.49 
31   82 
59.52267   32185.49 
31   82 
59.52261   32185.52 
31   82 
59.50889   41375.02 
31   82 
59.50895   41375.02 
31   82 
59.50889   41375.06 
31   82 
59.50646   53812.34 
31   82 
59.50652   53812.34 
31   82 
59.50646   53812.4 
31   82 
59.51404   71482.96 
31   82 
59.5141   71482.96 
31   82 
59.51404   71483.03 
31   82 
59.52546   94729.99 
31   82 
59.52552   94729.99 
31   82 
59.52546   94730.08 
31   82 
59.53365   123421.4 
31   82 
59.53371   123421.4 
31   82 
59.53365   123421.6 
31   82 
59.53654   160773.6 
31   82 
59.5366   160773.6 
31   82 
59.53654   160773.7 
31   82 
59.53438   212577.2 
31   82 
59.53444   212577.2 
31   82 
59.53438   212577.4 
31   82 
59.52931   282572.6 
31   82 
59.52937   282572.6 
31   82 
59.52931   282572.9 
31   82 
59.52475   371435.5 
31   82 
59.52481   371435.5 
31   82 
59.52475   371435.9 
31   82 
59.5225   485946.6 
31   82 
59.52256   485946.6 
31   82 
59.5225   485947.1 
31   82 
59.52279   640516.8 
31   82 
59.52285   640516.8 
31   82 
59.52279   640517.5 
31   82 
59.52487   842579.2 
31   82 
59.52493   842579.2 
31   82 
59.52487   842580.1 
31   82 
59.52735   1127234 
31   82 
59.52741   1127234 
31   82 
59.52735   1127235 
31   82 
59.52875   1473251 
31   82 
59.52881   1473251 
31   82 
59.52875   1473252 
31   82 
59.52894   1948509 
31   82 
59.529   1948509 
31   82 
59.52894   1948511 
31   82 
59.52812   2616783 
31   82 
59.52818   2616783 
31   82 
59.52812   2616785 
31   82 
59.52695   3484676 
31   82 
59.52701   3484676 
31   82 
59.52695   3484680 
31   82 
59.52652   4003948 
31   82 
59.52658   4003948 
31   82 
59.52652   4003952 
31   82 
59.52615   4710137 
31   82 
59.52621   4710137 
31   82 
59.52615   4710141 
31   82 
59.52613   5711555 
31   82 
59.52619   5711555 
31   82 
59.52613   5711561 
31   82 
59.52631   6712973 
31   82 
59.52637   6712973 
31   82 
59.52631   6712980 
31   82 
59.52664   7531362 
31   82 
59.5267   7531362 
31   82 
59.52664   7531369 
31   82 
59.52678   8532780 
31   82 
59.52684   8532780 
31   82 
59.52678   8532788 
31   82 
59.52689   9534198 
31   82 
59.52695   9534198 
31   82 
59.52689   9534208 
31   82 
59.52687   9646026 
31   82 
59.52693   9646026 
31   82 
59.52687   9646036 
31   82 
59.52686   9550939 
31   82 
59.52687   9616648 
31   82 
59.52687   9638367 
31   82 
59.52687   9643975 
31   82 
59.52687   9645481 
31   82 
59.52687   9645883 
31   82 
59.52687   9645989 
31   82 
59.52687   9646018 
31   82 
59.53282   9646026 
31   82 
59.52092   9646026 
31   82 
59.52687   9646991 
31   82 
59.52687   9645062 
31   82 
59.52686   9703743 
31   82 
59.53281   9703743 
31   82 
59.5209   9703743 
31   82 
59.52686   9704713 
31   82 
59.52686   9702772 
Fit Mean:  59.52686  Size:  9703743  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  59.52686  Size:  9703743  Code:  1  Try Size:  1000 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
31 82
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
9703743   59.52686 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 9703743
> print(nb_fit_mu);
[1] 59.52686
> 
> print(m)
[1] 53.27778
> print(v)
[1] 347.4147
> print(D)
[1] 6.520818
> 
> print(deletion_propagation_coverage)
[1] 40
> 
> warnings()
> 

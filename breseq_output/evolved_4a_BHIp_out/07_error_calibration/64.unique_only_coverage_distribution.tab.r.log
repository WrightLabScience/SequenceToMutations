
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | 4a+_BHI_c50_out/07_error_calibration/64.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | 4a+_BHI_c50_out/output/calibration/64.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00250313 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 19 to 44.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  31.82571  Size:  10000 
19   44 
31.82571   10000 
19   44 
31.82571   10000 
19   44 
31.82575   10000 
19   44 
31.82571   10000.01 
19   44 
31.83317   10000 
19   44 
31.8332   10000 
19   44 
31.83317   10000.01 
19   44 
62.52103   10000 
19   44 
41.21109   10000 
19   44 
41.21113   10000 
19   44 
41.21109   10000.01 
19   44 
38.20441   10000 
19   44 
38.20444   10000 
19   44 
38.20441   10000.01 
19   44 
38.64932   10000 
19   44 
38.64936   10000 
19   44 
38.64932   10000.01 
19   44 
38.6169   10000 
19   44 
38.61694   10000 
19   44 
38.6169   10000.01 
19   44 
38.61671   10000 
19   44 
38.61675   10000 
19   44 
38.61671   10000.01 
19   44 
38.61671   10000 
19   44 
38.61675   10000 
19   44 
38.61671   10000.01 
Fit Mean:  38.61671  Size:  10000  Code:  2 
Try Mean:  31.82571  Size:  1000 
19   44 
31.82571   1000 
19   44 
31.82571   1000 
19   44 
31.82575   1000 
19   44 
31.82571   1000.001 
19   44 
31.833   1000 
19   44 
31.83304   1000 
19   44 
31.833   1000.001 
19   44 
58.08535   1000.012 
19   44 
40.43003   1000.004 
19   44 
40.43007   1000.004 
19   44 
40.43003   1000.005 
19   44 
38.3528   1000.002 
19   44 
38.35284   1000.002 
19   44 
38.3528   1000.003 
19   44 
38.68989   1000.003 
19   44 
38.68993   1000.003 
19   44 
38.68989   1000.004 
19   44 
38.67439   1000.004 
19   44 
38.67443   1000.004 
19   44 
38.67439   1000.005 
19   44 
38.6743   1000.005 
19   44 
38.67434   1000.005 
19   44 
38.6743   1000.006 
19   44 
38.67321   1000.022 
19   44 
38.67325   1000.022 
19   44 
38.67321   1000.023 
19   44 
38.67203   1000.06 
19   44 
38.67207   1000.06 
19   44 
38.67203   1000.061 
19   44 
38.66976   1000.188 
19   44 
38.6698   1000.188 
19   44 
38.66976   1000.189 
19   44 
38.66631   1000.521 
19   44 
38.66635   1000.521 
19   44 
38.66631   1000.522 
19   44 
38.66058   1001.44 
19   44 
38.66061   1001.44 
19   44 
38.66058   1001.441 
19   44 
38.65139   1003.866 
19   44 
38.65143   1003.866 
19   44 
38.65139   1003.867 
19   44 
38.63659   1010.249 
19   44 
38.63663   1010.249 
19   44 
38.63659   1010.25 
19   44 
38.61343   1026.644 
19   44 
38.61347   1026.644 
19   44 
38.61343   1026.645 
19   44 
38.57942   1067.185 
19   44 
38.57946   1067.185 
19   44 
38.57942   1067.186 
19   44 
38.53688   1160.14 
19   44 
38.53692   1160.14 
19   44 
38.53688   1160.141 
19   44 
38.50033   1352.658 
19   44 
38.50037   1352.658 
19   44 
38.50033   1352.659 
19   44 
38.49923   1716.018 
19   44 
38.49927   1716.018 
19   44 
38.49923   1716.02 
19   44 
38.55698   2301.736 
19   44 
38.55701   2301.736 
19   44 
38.55698   2301.739 
19   44 
38.62732   3008.187 
19   44 
38.62736   3008.187 
19   44 
38.62732   3008.19 
19   44 
38.66414   3729.651 
19   44 
38.66417   3729.651 
19   44 
38.66414   3729.655 
19   44 
38.67527   4691.874 
19   44 
38.67531   4691.874 
19   44 
38.67527   4691.879 
19   44 
38.66061   6229.895 
19   44 
38.66064   6229.895 
19   44 
38.66061   6229.901 
19   44 
38.62836   8371.938 
19   44 
38.62839   8371.938 
19   44 
38.62836   8371.946 
19   44 
38.60237   10851.55 
19   44 
38.60241   10851.55 
19   44 
38.60237   10851.57 
19   44 
38.59016   13784.41 
19   44 
38.5902   13784.41 
19   44 
38.59016   13784.42 
19   44 
38.59021   17969.75 
19   44 
38.59025   17969.75 
19   44 
38.59021   17969.77 
19   44 
38.60073   23927.34 
19   44 
38.60077   23927.34 
19   44 
38.60073   23927.37 
19   44 
38.61304   31506.85 
19   44 
38.61307   31506.85 
19   44 
38.61304   31506.89 
19   44 
38.62031   40739.04 
19   44 
38.62034   40739.04 
19   44 
38.62031   40739.08 
19   44 
38.62165   53132.69 
19   44 
38.62168   53132.69 
19   44 
38.62165   53132.75 
19   44 
38.61777   70588.17 
19   44 
38.61781   70588.17 
19   44 
38.61777   70588.24 
19   44 
38.6118   93683.83 
19   44 
38.61184   93683.83 
19   44 
38.6118   93683.93 
19   44 
38.60738   122497.1 
19   44 
38.60742   122497.1 
19   44 
38.60738   122497.3 
19   44 
38.60574   159851 
19   44 
38.60578   159851 
19   44 
38.60574   159851.2 
19   44 
38.60674   211406.8 
19   44 
38.60678   211406.8 
19   44 
38.60674   211407 
19   44 
38.60925   279941.5 
19   44 
38.60928   279941.5 
19   44 
38.60925   279941.8 
19   44 
38.6116   370852.6 
19   44 
38.61164   370852.6 
19   44 
38.6116   370853 
19   44 
38.61263   480645.8 
19   44 
38.61267   480645.8 
19   44 
38.61263   480646.3 
19   44 
38.61244   636612.8 
19   44 
38.61247   636612.8 
19   44 
38.61244   636613.4 
19   44 
38.61137   847282.3 
19   44 
38.61141   847282.3 
19   44 
38.61137   847283.1 
19   44 
38.61022   1112070 
19   44 
38.61026   1112070 
19   44 
38.61022   1112071 
19   44 
38.60941   1499476 
19   44 
38.60945   1499476 
19   44 
38.60941   1499478 
19   44 
38.60956   1771644 
19   44 
38.6096   1771644 
19   44 
38.60956   1771646 
19   44 
38.61011   2277601 
19   44 
38.61015   2277601 
19   44 
38.61011   2277603 
19   44 
38.61056   2812337 
19   44 
38.6106   2812337 
19   44 
38.61056   2812340 
19   44 
38.61088   3488815 
19   44 
38.61092   3488815 
19   44 
38.61088   3488819 
19   44 
38.61073   3798470 
19   44 
38.61077   3798470 
19   44 
38.61073   3798474 
19   44 
38.6107   4289601 
19   44 
38.61074   4289601 
19   44 
38.6107   4289605 
19   44 
38.61061   5290107 
19   44 
38.61065   5290107 
19   44 
38.61061   5290112 
19   44 
38.61054   4765447 
19   44 
38.61059   5121539 
19   44 
38.61061   5243221 
19   44 
38.61061   5276656 
19   44 
38.61061   5286259 
19   44 
38.61061   5289007 
19   44 
38.61061   5289794 
19   44 
38.61061   5290019 
19   44 
38.61061   5290083 
19   44 
38.61061   5290100 
19   44 
38.61061   5290105 
19   44 
38.61447   5290107 
19   44 
38.60675   5290107 
19   44 
38.61061   5290636 
19   44 
38.61061   5289578 
19   44 
38.61051   5555369 
19   44 
38.61437   5555369 
19   44 
38.60665   5555369 
19   44 
38.61051   5555925 
19   44 
38.61051   5554814 
19   44 
38.61046   5795178 
19   44 
38.61432   5795178 
19   44 
38.6066   5795178 
19   44 
38.61046   5795758 
19   44 
38.61046   5794599 
19   44 
38.61043   6015716 
19   44 
38.61429   6015716 
19   44 
38.60657   6015716 
19   44 
38.61043   6016318 
19   44 
38.61043   6015115 
Fit Mean:  38.61043  Size:  6015716  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  38.61043  Size:  6015716  Code:  1  Try Size:  1000 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
19 44
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
6015716   38.61043 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 6015716
> print(nb_fit_mu);
[1] 38.61043
> 
> print(m)
[1] 31.82571
> print(v)
[1] 103.3363
> print(D)
[1] 3.246944
> 
> print(deletion_propagation_coverage)
[1] 22
> 
> warnings()
> 


R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | 4a+_BHI_c50_out/07_error_calibration/65.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | 4a+_BHI_c50_out/output/calibration/65.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00250627 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 5 to 17.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  9.722628  Size:  10000 
5   17 
9.722628   10000 
5   17 
9.722628   10000 
5   17 
9.722637   10000 
5   17 
9.722628   10000.01 
5   17 
9.740552   10000 
5   17 
9.740562   10000 
5   17 
9.740552   10000.01 
5   17 
10.99103   10000 
5   17 
10.99104   10000 
5   17 
10.99103   10000.01 
5   17 
11.12107   10000 
5   17 
11.12108   10000 
5   17 
11.12107   10000.01 
5   17 
11.14123   10000 
5   17 
11.14124   10000 
5   17 
11.14123   10000.01 
5   17 
11.14161   10000 
5   17 
11.14162   10000 
5   17 
11.14161   10000.01 
5   17 
11.14161   10000 
5   17 
11.14163   10000 
5   17 
11.14161   10000.01 
Fit Mean:  11.14161  Size:  10000  Code:  2 
Try Mean:  9.722628  Size:  1000 
5   17 
9.722628   1000 
5   17 
9.722628   1000 
5   17 
9.722637   1000 
5   17 
9.722628   1000.001 
5   17 
9.740467   1000 
5   17 
9.740476   1000 
5   17 
9.740467   1000.001 
5   17 
10.99493   1000 
5   17 
10.99494   1000 
5   17 
10.99493   1000.001 
5   17 
11.12781   1000 
5   17 
11.12783   1000 
5   17 
11.12781   1000.001 
5   17 
11.14876   1000 
5   17 
11.14877   1000 
5   17 
11.14876   1000.001 
5   17 
11.14917   1000 
5   17 
11.14918   1000 
5   17 
11.14917   1000.001 
5   17 
11.14917   1000 
5   17 
11.14918   1000 
5   17 
11.14917   1000.001 
Fit Mean:  11.14917  Size:  1000  Code:  2 
Try Mean:  9.722628  Size:  100 
5   17 
9.722628   100 
5   17 
9.722628   100 
5   17 
9.722637   100 
5   17 
9.722628   100.0001 
5   17 
9.73965   100 
5   17 
9.73966   100 
5   17 
9.73965   100.0001 
5   17 
11.03382   100.0035 
5   17 
11.03384   100.0035 
5   17 
11.03382   100.0036 
5   17 
11.19572   100.0054 
5   17 
11.19573   100.0054 
5   17 
11.19572   100.0055 
5   17 
11.22553   100.0071 
5   17 
11.22554   100.0071 
5   17 
11.22553   100.0072 
5   17 
11.2264   100.0085 
5   17 
11.22641   100.0085 
5   17 
11.2264   100.0086 
5   17 
11.22926   100.0189 
5   17 
11.22927   100.0189 
5   17 
11.22926   100.019 
5   17 
11.23297   100.0457 
5   17 
11.23298   100.0457 
5   17 
11.23297   100.0458 
5   17 
11.23948   100.1298 
5   17 
11.23949   100.1298 
5   17 
11.23948   100.1299 
5   17 
11.24952   100.3547 
5   17 
11.24953   100.3547 
5   17 
11.24952   100.3548 
5   17 
11.26549   100.9651 
5   17 
11.2655   100.9651 
5   17 
11.26549   100.9652 
5   17 
11.2895   102.5487 
5   17 
11.28952   102.5487 
5   17 
11.2895   102.5488 
5   17 
11.32278   106.5219 
5   17 
11.32279   106.5219 
5   17 
11.32278   106.522 
5   17 
11.3601   115.8638 
5   17 
11.36011   115.8638 
5   17 
11.3601   115.8639 
5   17 
11.38228   136.3474 
5   17 
11.38229   136.3474 
5   17 
11.38228   136.3476 
5   17 
11.35066   178.5074 
5   17 
11.35067   178.5074 
5   17 
11.35066   178.5076 
5   17 
11.23926   250.223 
5   17 
11.23927   250.223 
5   17 
11.23926   250.2232 
5   17 
11.13694   325.1226 
5   17 
11.13695   325.1226 
5   17 
11.13694   325.1229 
5   17 
11.09868   382.1431 
5   17 
11.09869   382.1431 
5   17 
11.09868   382.1434 
5   17 
11.0827   470.6003 
5   17 
11.08271   470.6003 
5   17 
11.0827   470.6007 
5   17 
11.09775   619.0122 
5   17 
11.09776   619.0122 
5   17 
11.09775   619.0128 
5   17 
11.13434   823.2547 
5   17 
11.13435   823.2547 
5   17 
11.13434   823.2555 
5   17 
11.16094   1055.29 
5   17 
11.16095   1055.29 
5   17 
11.16094   1055.291 
5   17 
11.17142   1340.121 
5   17 
11.17143   1340.121 
5   17 
11.17142   1340.122 
5   17 
11.16757   1760.961 
5   17 
11.16758   1760.961 
5   17 
11.16757   1760.962 
5   17 
11.15291   2355.299 
5   17 
11.15292   2355.299 
5   17 
11.15291   2355.302 
5   17 
11.13871   3093.121 
5   17 
11.13873   3093.121 
5   17 
11.13871   3093.124 
5   17 
11.13127   3992.757 
5   17 
11.13128   3992.757 
5   17 
11.13127   3992.761 
5   17 
11.1307   5223.136 
5   17 
11.13071   5223.136 
5   17 
11.1307   5223.142 
5   17 
11.13559   6938.78 
5   17 
11.1356   6938.78 
5   17 
11.13559   6938.787 
5   17 
11.14171   9164.422 
5   17 
11.14172   9164.422 
5   17 
11.14171   9164.431 
5   17 
11.1455   11965.89 
5   17 
11.14551   11965.89 
5   17 
11.1455   11965.9 
5   17 
11.14617   15701.71 
5   17 
11.14618   15701.71 
5   17 
11.14617   15701.73 
5   17 
11.14423   20834.56 
5   17 
11.14424   20834.56 
5   17 
11.14423   20834.58 
5   17 
11.14134   27627.56 
5   17 
11.14136   27627.56 
5   17 
11.14134   27627.59 
5   17 
11.13924   36298.81 
5   17 
11.13925   36298.81 
5   17 
11.13924   36298.85 
5   17 
11.13855   47696.5 
5   17 
11.13856   47696.5 
5   17 
11.13855   47696.55 
5   17 
11.13916   63168.56 
5   17 
11.13917   63168.56 
5   17 
11.13916   63168.62 
5   17 
11.14039   83721.41 
5   17 
11.1404   83721.41 
5   17 
11.14039   83721.49 
5   17 
11.14144   110465.7 
5   17 
11.14145   110465.7 
5   17 
11.14144   110465.8 
5   17 
11.14187   145378.5 
5   17 
11.14188   145378.5 
5   17 
11.14187   145378.6 
5   17 
11.14167   191750.1 
5   17 
11.14168   191750.1 
5   17 
11.14167   191750.3 
5   17 
11.14112   254386 
5   17 
11.14113   254386 
5   17 
11.14112   254386.2 
5   17 
11.14059   334223 
5   17 
11.14061   334223 
5   17 
11.14059   334223.4 
5   17 
11.14034   434694.6 
5   17 
11.14035   434694.6 
5   17 
11.14034   434695 
5   17 
11.14039   535166.1 
5   17 
11.1404   535166.1 
5   17 
11.14039   535166.6 
5   17 
11.14048   635637.6 
5   17 
11.1405   635637.6 
5   17 
11.14048   635638.3 
5   17 
11.14066   699042.8 
5   17 
11.14067   699042.8 
5   17 
11.14066   699043.5 
5   17 
11.14076   791296.2 
5   17 
11.14077   791296.2 
5   17 
11.14076   791297 
5   17 
11.14082   891767.7 
5   17 
11.14083   891767.7 
5   17 
11.14082   891768.6 
5   17 
11.14084   992239.2 
5   17 
11.14085   992239.2 
5   17 
11.14084   992240.2 
5   17 
11.14082   1057183 
5   17 
11.14083   1057183 
5   17 
11.14082   1057184 
5   17 
11.1408   1085970 
5   17 
11.14081   1085970 
5   17 
11.1408   1085971 
5   17 
11.14078   1122811 
5   17 
11.1408   1122811 
5   17 
11.14078   1122812 
Fit Mean:  11.14078  Size:  1122811  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  11.14078  Size:  1122811  Code:  1  Try Size:  100 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
5 17
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
1122811   11.14078 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 1122811
> print(nb_fit_mu);
[1] 11.14078
> 
> print(m)
[1] 13.1133
> print(v)
[1] 35.65542
> print(D)
[1] 2.719027
> 
> print(deletion_propagation_coverage)
[1] 3
> 
> warnings()
> 


R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | 4a+_BHI_c50_out/07_error_calibration/59.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | 4a+_BHI_c50_out/output/calibration/59.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.0019146 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 3 to 11.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  7.455882  Size:  10000 
3   11 
7.455882   10000 
3   11 
7.455882   10000 
3   11 
7.45589   10000 
3   11 
7.455882   10000.01 
3   11 
7.470303   10000 
3   11 
7.470311   10000 
3   11 
7.470303   10000.01 
3   11 
8.395569   10000 
3   11 
8.395577   10000 
3   11 
8.395569   10000.01 
3   11 
8.484713   10000 
3   11 
8.484722   10000 
3   11 
8.484713   10000.01 
3   11 
8.495972   10000 
3   11 
8.495981   10000 
3   11 
8.495972   10000.01 
3   11 
8.496122   10000 
3   11 
8.496131   10000 
3   11 
8.496122   10000.01 
3   11 
8.496122   10000 
3   11 
8.496131   10000 
3   11 
8.496122   10000.01 
Fit Mean:  8.496122  Size:  10000  Code:  2 
Try Mean:  7.455882  Size:  1000 
3   11 
7.455882   1000 
3   11 
7.455882   1000 
3   11 
7.45589   1000 
3   11 
7.455882   1000.001 
3   11 
7.470271   1000 
3   11 
7.470278   1000 
3   11 
7.470271   1000.001 
3   11 
8.399871   1000 
3   11 
8.39988   1000 
3   11 
8.399871   1000.001 
3   11 
8.491601   1000 
3   11 
8.49161   1000 
3   11 
8.491601   1000.001 
3   11 
8.503468   1000 
3   11 
8.503476   1000 
3   11 
8.503468   1000.001 
3   11 
8.503633   1000 
3   11 
8.503642   1000 
3   11 
8.503633   1000.001 
3   11 
8.503634   1000 
3   11 
8.503642   1000 
3   11 
8.503634   1000.001 
Fit Mean:  8.503634  Size:  1000  Code:  2 
Try Mean:  7.455882  Size:  100 
3   11 
7.455882   100 
3   11 
7.455882   100 
3   11 
7.45589   100 
3   11 
7.455882   100.0001 
3   11 
7.469975   100 
3   11 
7.469983   100 
3   11 
7.469975   100.0001 
3   11 
8.444111   100.0011 
3   11 
8.44412   100.0011 
3   11 
8.444111   100.0012 
3   11 
8.562522   100.0016 
3   11 
8.56253   100.0016 
3   11 
8.562522   100.0017 
3   11 
8.58152   100.0018 
3   11 
8.581529   100.0018 
3   11 
8.58152   100.0019 
3   11 
8.581918   100.0021 
3   11 
8.581927   100.0021 
3   11 
8.581918   100.0022 
3   11 
8.582075   100.0025 
3   11 
8.582083   100.0025 
3   11 
8.582075   100.0026 
3   11 
8.582621   100.0052 
3   11 
8.58263   100.0052 
3   11 
8.582621   100.0053 
3   11 
8.583321   100.0117 
3   11 
8.583329   100.0117 
3   11 
8.583321   100.0118 
3   11 
8.584556   100.0319 
3   11 
8.584565   100.0319 
3   11 
8.584556   100.032 
3   11 
8.586464   100.0854 
3   11 
8.586473   100.0854 
3   11 
8.586464   100.0855 
3   11 
8.589527   100.2306 
3   11 
8.589536   100.2306 
3   11 
8.589527   100.2307 
3   11 
8.594268   100.6125 
3   11 
8.594276   100.6125 
3   11 
8.594268   100.6126 
3   11 
8.601378   101.6092 
3   11 
8.601387   101.6092 
3   11 
8.601378   101.6093 
3   11 
8.611166   104.1436 
3   11 
8.611175   104.1436 
3   11 
8.611166   104.1437 
3   11 
8.622254   110.359 
3   11 
8.622263   110.359 
3   11 
8.622254   110.3591 
3   11 
8.628788   124.9712 
3   11 
8.628797   124.9712 
3   11 
8.628788   124.9713 
3   11 
8.61649   158.619 
3   11 
8.616499   158.619 
3   11 
8.61649   158.6191 
3   11 
8.565201   228.2833 
3   11 
8.56521   228.2833 
3   11 
8.565201   228.2836 
3   11 
8.508257   307.8448 
3   11 
8.508266   307.8448 
3   11 
8.508257   307.8451 
3   11 
8.492294   348.3019 
3   11 
8.492302   348.3019 
3   11 
8.492294   348.3023 
3   11 
8.482463   412.3949 
3   11 
8.482471   412.3949 
3   11 
8.482463   412.3953 
3   11 
8.482706   526.3394 
3   11 
8.482714   526.3394 
3   11 
8.482706   526.3399 
3   11 
8.494623   691.4026 
3   11 
8.494632   691.4026 
3   11 
8.494623   691.4033 
3   11 
8.505461   887.7716 
3   11 
8.505469   887.7716 
3   11 
8.505461   887.7724 
3   11 
8.509661   1125.493 
3   11 
8.50967   1125.493 
3   11 
8.509661   1125.494 
3   11 
8.507958   1475.923 
3   11 
8.507966   1475.923 
3   11 
8.507958   1475.924 
3   11 
8.501879   1976.119 
3   11 
8.501888   1976.119 
3   11 
8.501879   1976.121 
3   11 
8.496031   2601.104 
3   11 
8.49604   2601.104 
3   11 
8.496031   2601.106 
3   11 
8.492937   3366.315 
3   11 
8.492945   3366.315 
3   11 
8.492937   3366.319 
3   11 
8.492596   4405.804 
3   11 
8.492604   4405.804 
3   11 
8.492596   4405.809 
3   11 
8.494285   5834.894 
3   11 
8.494294   5834.894 
3   11 
8.494285   5834.9 
3   11 
8.49629   7690.082 
3   11 
8.496299   7690.082 
3   11 
8.49629   7690.089 
3   11 
8.497369   10072.7 
3   11 
8.497378   10072.7 
3   11 
8.497369   10072.71 
3   11 
8.497301   13282.37 
3   11 
8.49731   13282.37 
3   11 
8.497301   13282.38 
3   11 
8.49642   17646.37 
3   11 
8.496429   17646.37 
3   11 
8.49642   17646.39 
3   11 
8.495419   23324.98 
3   11 
8.495428   23324.98 
3   11 
8.495419   23325.01 
3   11 
8.494803   30760.11 
3   11 
8.494811   30760.11 
3   11 
8.494803   30760.14 
3   11 
8.494709   40612.68 
3   11 
8.494717   40612.68 
3   11 
8.494709   40612.72 
3   11 
8.494997   53817.4 
3   11 
8.495005   53817.4 
3   11 
8.494997   53817.46 
3   11 
8.49538   71406.08 
3   11 
8.495388   71406.08 
3   11 
8.49538   71406.15 
3   11 
8.495628   95372.52 
3   11 
8.495636   95372.52 
3   11 
8.495628   95372.62 
3   11 
8.495652   127750.1 
3   11 
8.495661   127750.1 
3   11 
8.495652   127750.2 
3   11 
8.495505   151669.3 
3   11 
8.495514   151669.3 
3   11 
8.495505   151669.4 
3   11 
8.495427   179552.2 
3   11 
8.495436   179552.2 
3   11 
8.495427   179552.3 
3   11 
8.495351   199422.6 
3   11 
8.49536   199422.6 
3   11 
8.495351   199422.8 
3   11 
8.495301   225624.1 
3   11 
8.49531   225624.1 
3   11 
8.495301   225624.3 
3   11 
8.495209   325901.6 
3   11 
8.495218   325901.6 
3   11 
8.495209   325902 
3   11 
8.495206   426179.2 
3   11 
8.495215   426179.2 
3   11 
8.495206   426179.6 
3   11 
8.49526   394428.3 
3   11 
8.49522   417998.9 
3   11 
8.495209   424321.5 
3   11 
8.495207   425746.6 
3   11 
8.495206   426078.7 
3   11 
8.495206   426155.8 
3   11 
8.495206   426173.9 
3   11 
8.495206   426178.1 
3   11 
8.495206   426179 
3   11 
8.496056   426179.2 
3   11 
8.494357   426179.2 
3   11 
8.495206   426221.8 
3   11 
8.495206   426136.6 
3   11 
8.49526   454459.9 
3   11 
8.496109   454459.9 
3   11 
8.49441   454459.9 
3   11 
8.49526   454505.4 
3   11 
8.49526   454414.5 
3   11 
8.495366   554737.5 
3   11 
8.496216   554737.5 
3   11 
8.494517   554737.5 
3   11 
8.495366   554793 
3   11 
8.495366   554682 
3   11 
8.495407   655015.1 
3   11 
8.496256   655015.1 
3   11 
8.494557   655015.1 
3   11 
8.495407   655080.6 
3   11 
8.495407   654949.6 
3   11 
8.495407   755292.6 
3   11 
8.496257   755292.6 
3   11 
8.494557   755292.6 
3   11 
8.495407   755368.2 
3   11 
8.495407   755217.1 
3   11 
8.495392   855570.2 
3   11 
8.496241   855570.2 
3   11 
8.494542   855570.2 
3   11 
8.495392   855655.8 
3   11 
8.495392   855484.6 
3   11 
8.495369   955847.8 
3   11 
8.496218   955847.8 
3   11 
8.494519   955847.8 
3   11 
8.495369   955943.4 
3   11 
8.495369   955752.2 
Fit Mean:  8.495369  Size:  955847.8  Code:  5 
Try Mean:  7.455882  Size:  10 
3   11 
7.455882   10 
3   11 
7.455882   10 
3   11 
7.45589   10 
3   11 
7.455882   10.00001 
3   11 
7.468211   10.00077 
3   11 
7.468219   10.00077 
3   11 
7.468211   10.00078 
3   11 
8.92433   10.20794 
3   11 
8.924339   10.20794 
3   11 
8.92433   10.20795 
3   11 
9.374666   10.3347 
3   11 
9.374675   10.3347 
3   11 
9.374666   10.33471 
3   11 
9.581853   10.43059 
3   11 
9.581862   10.43059 
3   11 
9.581853   10.4306 
3   11 
9.614681   10.48202 
3   11 
9.61469   10.48202 
3   11 
9.614681   10.48203 
3   11 
9.657659   10.65587 
3   11 
9.657669   10.65587 
3   11 
9.657659   10.65588 
3   11 
9.686925   11.10608 
3   11 
9.686935   11.10608 
3   11 
9.686925   11.10609 
3   11 
9.65144   12.34702 
3   11 
9.65145   12.34702 
3   11 
9.65144   12.34703 
3   11 
9.353913   16.44989 
3   11 
9.353923   16.44989 
3   11 
9.353913   16.44991 
3   11 
7.724788   36.8612 
3   11 
8.975377   21.19258 
3   11 
8.975386   21.19258 
3   11 
8.975377   21.1926 
3   11 
8.579836   27.2572 
3   11 
8.579845   27.2572 
3   11 
8.579836   27.25723 
3   11 
8.762104   25.55656 
3   11 
8.762113   25.55656 
3   11 
8.762104   25.55659 
3   11 
8.787689   26.67633 
3   11 
8.787698   26.67633 
3   11 
8.787689   26.67635 
3   11 
8.787666   34.26578 
3   11 
8.787675   34.26578 
3   11 
8.787666   34.26582 
3   11 
8.694851   43.8579 
3   11 
8.694859   43.8579 
3   11 
8.694851   43.85794 
3   11 
8.593682   58.24143 
3   11 
8.593691   58.24143 
3   11 
8.593682   58.24149 
3   11 
8.570776   72.37232 
3   11 
8.570784   72.37232 
3   11 
8.570776   72.3724 
3   11 
8.570835   93.4201 
3   11 
8.570844   93.4201 
3   11 
8.570835   93.4202 
3   11 
8.554007   120.3948 
3   11 
8.554016   120.3948 
3   11 
8.554007   120.395 
3   11 
8.538437   157.2655 
3   11 
8.538445   157.2655 
3   11 
8.538437   157.2656 
3   11 
8.528696   205.097 
3   11 
8.528704   205.097 
3   11 
8.528696   205.0972 
3   11 
8.520416   268.5813 
3   11 
8.520424   268.5813 
3   11 
8.520416   268.5816 
3   11 
8.514598   352.3837 
3   11 
8.514606   352.3837 
3   11 
8.514598   352.384 
3   11 
8.50976   463.3373 
3   11 
8.509769   463.3373 
3   11 
8.50976   463.3378 
3   11 
8.506416   610.1696 
3   11 
8.506425   610.1696 
3   11 
8.506416   610.1702 
3   11 
8.503557   804.6268 
3   11 
8.503566   804.6268 
3   11 
8.503557   804.6276 
3   11 
8.501701   1062.12 
3   11 
8.50171   1062.12 
3   11 
8.501701   1062.122 
3   11 
8.499974   1403.226 
3   11 
8.499982   1403.226 
3   11 
8.499974   1403.227 
3   11 
8.499004   1854.988 
3   11 
8.499013   1854.988 
3   11 
8.499004   1854.99 
3   11 
8.497907   2453.553 
3   11 
8.497916   2453.553 
3   11 
8.497907   2453.555 
3   11 
8.497475   3246.293 
3   11 
8.497484   3246.293 
3   11 
8.497475   3246.297 
3   11 
8.496709   4296.94 
3   11 
8.496718   4296.94 
3   11 
8.496709   4296.944 
3   11 
8.49662   5687.947 
3   11 
8.496628   5687.947 
3   11 
8.49662   5687.953 
3   11 
8.496006   7531.974 
3   11 
8.496015   7531.974 
3   11 
8.496006   7531.982 
3   11 
8.496151   9973.696 
3   11 
8.49616   9973.696 
3   11 
8.496151   9973.706 
3   11 
8.495584   13220.54 
3   11 
8.495593   13220.54 
3   11 
8.495584   13220.55 
3   11 
8.495899   17511.56 
3   11 
8.495908   17511.56 
3   11 
8.495899   17511.58 
3   11 
8.495337   23222.87 
3   11 
8.495346   23222.87 
3   11 
8.495337   23222.89 
3   11 
8.495746   30811.53 
3   11 
8.495754   30811.53 
3   11 
8.495746   30811.56 
3   11 
8.495241   40430.14 
3   11 
8.49525   40430.14 
3   11 
8.495241   40430.18 
3   11 
8.49557   52903.72 
3   11 
8.495578   52903.72 
3   11 
8.49557   52903.77 
3   11 
8.495338   65377.3 
3   11 
8.495346   65377.3 
3   11 
8.495338   65377.37 
3   11 
8.495392   77850.88 
3   11 
8.495401   77850.88 
3   11 
8.495392   77850.96 
Fit Mean:  8.495392  Size:  77850.88  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  8.495392  Size:  77850.88  Code:  1  Try Size:  10 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
3 11
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
77850.88   8.495392 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 77850.88
> print(nb_fit_mu);
[1] 8.495392
> 
> print(m)
[1] 19.41873
> print(v)
[1] 158.1235
> print(D)
[1] 8.142834
> 
> print(deletion_propagation_coverage)
[1] 1
> 
> warnings()
> 

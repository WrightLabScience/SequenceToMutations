
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | 4a+_BHI_c50_out/07_error_calibration/89.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | 4a+_BHI_c50_out/output/calibration/89.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00422577 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 2 to 8.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  4.022727  Size:  10000 
2   8 
4.022727   10000 
2   8 
4.022727   10000 
2   8 
4.022731   10000 
2   8 
4.022727   10000.01 
2   8 
3.998214   10000 
2   8 
3.998218   10000 
2   8 
3.998214   10000.01 
2   8 
3.505293   10000 
2   8 
3.505296   10000 
2   8 
3.505293   10000.01 
2   8 
3.616262   10000 
2   8 
3.616265   10000 
2   8 
3.616262   10000.01 
2   8 
3.59931   10000 
2   8 
3.599314   10000 
2   8 
3.59931   10000.01 
2   8 
3.598594   10000 
2   8 
3.598597   10000 
2   8 
3.598594   10000.01 
2   8 
3.598599   10000 
2   8 
3.598603   10000 
2   8 
3.598599   10000.01 
2   8 
3.598599   10000 
2   8 
3.598603   10000 
2   8 
3.598599   10000.01 
Fit Mean:  3.598599  Size:  10000  Code:  2 
Try Mean:  4.022727  Size:  1000 
2   8 
4.022727   1000 
2   8 
4.022727   1000 
2   8 
4.022731   1000 
2   8 
4.022727   1000.001 
2   8 
3.998403   1000 
2   8 
3.998407   1000 
2   8 
3.998403   1000.001 
2   8 
3.506916   1000 
2   8 
3.50692   1000 
2   8 
3.506916   1000.001 
2   8 
3.61735   1000 
2   8 
3.617353   1000 
2   8 
3.61735   1000.001 
2   8 
3.600493   1000 
2   8 
3.600496   1000 
2   8 
3.600493   1000.001 
2   8 
3.599782   1000 
2   8 
3.599786   1000 
2   8 
3.599782   1000.001 
2   8 
3.599788   1000 
2   8 
3.599792   1000 
2   8 
3.599788   1000.001 
2   8 
3.599789   1000 
2   8 
3.599793   1000 
2   8 
3.599789   1000.001 
Fit Mean:  3.599789  Size:  1000  Code:  2 
Try Mean:  4.022727  Size:  100 
2   8 
4.022727   100 
2   8 
4.022727   100 
2   8 
4.022731   100 
2   8 
4.022727   100.0001 
2   8 
4.000202   100 
2   8 
4.000206   100 
2   8 
4.000202   100.0001 
2   8 
3.522978   100.0006 
2   8 
3.522982   100.0006 
2   8 
3.522978   100.0007 
2   8 
3.628125   100.0007 
2   8 
3.628129   100.0007 
2   8 
3.628125   100.0008 
2   8 
3.61221   100.001 
2   8 
3.612214   100.001 
2   8 
3.61221   100.0011 
2   8 
3.611556   100.0013 
2   8 
3.611559   100.0013 
2   8 
3.611556   100.0014 
2   8 
3.611462   100.0017 
2   8 
3.611466   100.0017 
2   8 
3.611462   100.0018 
2   8 
3.61067   100.0085 
2   8 
3.610673   100.0085 
2   8 
3.61067   100.0086 
2   8 
3.609783   100.0231 
2   8 
3.609787   100.0231 
2   8 
3.609783   100.0232 
2   8 
3.608104   100.0712 
2   8 
3.608108   100.0712 
2   8 
3.608104   100.0713 
2   8 
3.605544   100.1964 
2   8 
3.605547   100.1964 
2   8 
3.605544   100.1965 
2   8 
3.601335   100.5393 
2   8 
3.601339   100.5393 
2   8 
3.601335   100.5394 
2   8 
3.594726   101.4336 
2   8 
3.594729   101.4336 
2   8 
3.594726   101.4337 
2   8 
3.584624   103.729 
2   8 
3.584628   103.729 
2   8 
3.584624   103.7291 
2   8 
3.570697   109.3094 
2   8 
3.570701   109.3094 
2   8 
3.570697   109.3095 
2   8 
3.555448   121.8163 
2   8 
3.555451   121.8163 
2   8 
3.555448   121.8164 
2   8 
3.546939   147.2982 
2   8 
3.546942   147.2982 
2   8 
3.546939   147.2984 
2   8 
3.557821   193.8909 
2   8 
3.557824   193.8909 
2   8 
3.557821   193.8911 
2   8 
3.586959   260.9095 
2   8 
3.586962   260.9095 
2   8 
3.586959   260.9098 
2   8 
3.609995   332.0525 
2   8 
3.609998   332.0525 
2   8 
3.609995   332.0529 
2   8 
3.620602   407.2014 
2   8 
3.620605   407.2014 
2   8 
3.620602   407.2018 
2   8 
3.622559   518.7202 
2   8 
3.622562   518.7202 
2   8 
3.622559   518.7207 
2   8 
3.614585   693.4022 
2   8 
3.614589   693.4022 
2   8 
3.614585   693.4029 
2   8 
3.601781   925.1998 
2   8 
3.601784   925.1998 
2   8 
3.601781   925.2007 
2   8 
3.592951   1183.002 
2   8 
3.592954   1183.002 
2   8 
3.592951   1183.003 
2   8 
3.589318   1498.057 
2   8 
3.589322   1498.057 
2   8 
3.589318   1498.059 
2   8 
3.5904   1964.218 
2   8 
3.590404   1964.218 
2   8 
3.5904   1964.22 
2   8 
3.595199   2620.598 
2   8 
3.595202   2620.598 
2   8 
3.595199   2620.601 
2   8 
3.599977   3432.728 
2   8 
3.599981   3432.728 
2   8 
3.599977   3432.731 
2   8 
3.602555   4415.571 
2   8 
3.602559   4415.571 
2   8 
3.602555   4415.575 
2   8 
3.602837   5758.821 
2   8 
3.60284   5758.821 
2   8 
3.602837   5758.826 
2   8 
3.601119   7663.968 
2   8 
3.601122   7663.968 
2   8 
3.601119   7663.975 
2   8 
3.598726   10149.25 
2   8 
3.59873   10149.25 
2   8 
3.598726   10149.26 
2   8 
3.597055   13213.26 
2   8 
3.597059   13213.26 
2   8 
3.597055   13213.27 
2   8 
3.596484   17237.02 
2   8 
3.596488   17237.02 
2   8 
3.596484   17237.03 
2   8 
3.596966   22751.09 
2   8 
3.59697   22751.09 
2   8 
3.596966   22751.11 
2   8 
3.598032   30207.05 
2   8 
3.598035   30207.05 
2   8 
3.598032   30207.08 
2   8 
3.598971   39733.12 
2   8 
3.598975   39733.12 
2   8 
3.598971   39733.16 
2   8 
3.5994   51693.79 
2   8 
3.599404   51693.79 
2   8 
3.5994   51693.84 
2   8 
3.599338   69340.33 
2   8 
3.599342   69340.33 
2   8 
3.599338   69340.4 
2   8 
3.598899   92211.83 
2   8 
3.598903   92211.83 
2   8 
3.598899   92211.92 
2   8 
3.598403   121355.5 
2   8 
3.598406   121355.5 
2   8 
3.598403   121355.7 
2   8 
3.598167   150442.9 
2   8 
3.59817   150442.9 
2   8 
3.598167   150443.1 
2   8 
3.597982   221993 
2   8 
3.597985   221993 
2   8 
3.597982   221993.2 
2   8 
3.597982   322073.9 
2   8 
3.597985   322073.9 
2   8 
3.597982   322074.2 
2   8 
3.598203   332103.7 
2   8 
3.598207   332103.7 
2   8 
3.598203   332104.1 
2   8 
3.598324   374256.6 
2   8 
3.598327   374256.6 
2   8 
3.598324   374256.9 
2   8 
3.59842   392539.9 
2   8 
3.598423   392539.9 
2   8 
3.59842   392540.3 
2   8 
3.598468   408468.1 
2   8 
3.598471   408468.1 
2   8 
3.598468   408468.5 
Fit Mean:  3.598468  Size:  408468.1  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  3.598468  Size:  408468.1  Code:  1  Try Size:  100 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
2 8
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
408468.1   3.598468 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 408468.1
> print(nb_fit_mu);
[1] 3.598468
> 
> print(m)
[1] 7.118644
> print(v)
[1] 34.65809
> print(D)
[1] 4.868637
> 
> print(deletion_propagation_coverage)
[1] 1
> 
> warnings()
> 

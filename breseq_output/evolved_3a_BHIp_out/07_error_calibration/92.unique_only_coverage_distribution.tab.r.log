
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | 3a+_BHI_c50_out/07_error_calibration/92.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | 3a+_BHI_c50_out/output/calibration/92.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.0029361 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 4 to 12.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  10  Size:  10000 
4   12 
10   10000 
4   12 
10   10000 
4   12 
10.00001   10000 
4   12 
10   10000.01 
4   12 
10.02611   10000 
4   12 
10.02612   10000 
4   12 
10.02611   10000.01 
4   12 
11.39533   10000 
4   12 
11.39535   10000 
4   12 
11.39533   10000.01 
4   12 
11.55557   10000 
4   12 
11.55558   10000 
4   12 
11.55557   10000.01 
4   12 
11.58462   10000 
4   12 
11.58463   10000 
4   12 
11.58462   10000.01 
4   12 
11.58534   10000 
4   12 
11.58536   10000 
4   12 
11.58534   10000.01 
4   12 
11.58535   10000 
4   12 
11.58536   10000 
4   12 
11.58535   10000.01 
Fit Mean:  11.58535  Size:  10000  Code:  2 
Try Mean:  10  Size:  1000 
4   12 
10   1000 
4   12 
10   1000 
4   12 
10.00001   1000 
4   12 
10   1000.001 
4   12 
10.02607   1000 
4   12 
10.02608   1000 
4   12 
10.02607   1000.001 
4   12 
11.41316   1000 
4   12 
11.41317   1000 
4   12 
11.41316   1000.001 
4   12 
11.58   1000 
4   12 
11.58001   1000 
4   12 
11.58   1000.001 
4   12 
11.61111   1000 
4   12 
11.61113   1000 
4   12 
11.61111   1000.001 
4   12 
11.61193   1000 
4   12 
11.61194   1000 
4   12 
11.61193   1000.001 
4   12 
11.61194   1000 
4   12 
11.61195   1000 
4   12 
11.61194   1000.001 
Fit Mean:  11.61194  Size:  1000  Code:  2 
Try Mean:  10  Size:  100 
4   12 
10   100 
4   12 
10   100 
4   12 
10.00001   100 
4   12 
10   100.0001 
4   12 
10.02557   100.0001 
4   12 
10.02558   100.0001 
4   12 
10.02557   100.0002 
4   12 
11.58771   100.0093 
4   12 
11.58772   100.0093 
4   12 
11.58771   100.0094 
4   12 
11.82704   100.0138 
4   12 
11.82706   100.0138 
4   12 
11.82704   100.0139 
4   12 
11.88472   100.0175 
4   12 
11.88473   100.0175 
4   12 
11.88472   100.0176 
4   12 
11.88733   100.0203 
4   12 
11.88735   100.0203 
4   12 
11.88733   100.0204 
4   12 
11.89133   100.0313 
4   12 
11.89134   100.0313 
4   12 
11.89133   100.0314 
4   12 
11.89778   100.0667 
4   12 
11.89779   100.0667 
4   12 
11.89778   100.0668 
4   12 
11.90802   100.1692 
4   12 
11.90803   100.1692 
4   12 
11.90802   100.1693 
4   12 
11.92411   100.4535 
4   12 
11.92413   100.4535 
4   12 
11.92411   100.4536 
4   12 
11.94866   101.2153 
4   12 
11.94867   101.2153 
4   12 
11.94866   101.2154 
4   12 
11.98386   103.1977 
4   12 
11.98387   103.1977 
4   12 
11.98386   103.1978 
4   12 
12.0277   108.1558 
4   12 
12.02771   108.1558 
4   12 
12.0277   108.1559 
4   12 
12.06522   119.9928 
4   12 
12.06523   119.9928 
4   12 
12.06522   119.9929 
4   12 
12.05477   147.5963 
4   12 
12.05479   147.5963 
4   12 
12.05477   147.5964 
4   12 
11.91301   210.316 
4   12 
11.91303   210.316 
4   12 
11.91301   210.3162 
4   12 
11.6593   306.5424 
4   12 
11.65931   306.5424 
4   12 
11.6593   306.5427 
4   12 
11.56761   360.5847 
4   12 
11.56762   360.5847 
4   12 
11.56761   360.5851 
4   12 
11.5341   414.797 
4   12 
11.53412   414.797 
4   12 
11.5341   414.7975 
4   12 
11.53103   538.6609 
4   12 
11.53104   538.6609 
4   12 
11.53103   538.6615 
4   12 
11.57523   709.8051 
4   12 
11.57524   709.8051 
4   12 
11.57523   709.8058 
4   12 
11.617   920.65 
4   12 
11.61701   920.65 
4   12 
11.617   920.651 
4   12 
11.63281   1175.981 
4   12 
11.63282   1175.981 
4   12 
11.63281   1175.982 
4   12 
11.62605   1550.563 
4   12 
11.62607   1550.563 
4   12 
11.62605   1550.565 
4   12 
11.60392   2076.762 
4   12 
11.60393   2076.762 
4   12 
11.60392   2076.764 
4   12 
11.58368   2737.098 
4   12 
11.5837   2737.098 
4   12 
11.58368   2737.1 
4   12 
11.57383   3563.706 
4   12 
11.57384   3563.706 
4   12 
11.57383   3563.709 
4   12 
11.57404   4690.649 
4   12 
11.57405   4690.649 
4   12 
11.57404   4690.653 
4   12 
11.58053   6217.955 
4   12 
11.58054   6217.955 
4   12 
11.58053   6217.961 
4   12 
11.5869   8197.966 
4   12 
11.58691   8197.966 
4   12 
11.5869   8197.975 
4   12 
11.58958   10781.67 
4   12 
11.5896   10781.67 
4   12 
11.58958   10781.68 
4   12 
11.58841   14267.11 
4   12 
11.58842   14267.11 
4   12 
11.58841   14267.13 
4   12 
11.58511   18943.89 
4   12 
11.58513   18943.89 
4   12 
11.58511   18943.91 
4   12 
11.58212   25041.73 
4   12 
11.58213   25041.73 
4   12 
11.58212   25041.76 
4   12 
11.58072   33074.28 
4   12 
11.58073   33074.28 
4   12 
11.58072   33074.31 
4   12 
11.58096   43725.95 
4   12 
11.58097   43725.95 
4   12 
11.58096   43725.99 
4   12 
11.58207   58008.58 
4   12 
11.58209   58008.58 
4   12 
11.58207   58008.64 
4   12 
11.58309   76733.58 
4   12 
11.5831   76733.58 
4   12 
11.58309   76733.65 
4   12 
11.58348   101039.5 
4   12 
11.58349   101039.5 
4   12 
11.58348   101039.6 
4   12 
11.58325   132379.5 
4   12 
11.58326   132379.5 
4   12 
11.58325   132379.7 
4   12 
11.5827   180578.4 
4   12 
11.58271   180578.4 
4   12 
11.5827   180578.6 
4   12 
11.58233   229197.3 
4   12 
11.58234   229197.3 
4   12 
11.58233   229197.5 
4   12 
11.58211   310703 
4   12 
11.58212   310703 
4   12 
11.58211   310703.3 
4   12 
11.58216   410446.3 
4   12 
11.58217   410446.3 
4   12 
11.58216   410446.7 
4   12 
11.58228   510945 
4   12 
11.5823   510945 
4   12 
11.58228   510945.6 
4   12 
11.5824   611443.8 
4   12 
11.58241   611443.8 
4   12 
11.5824   611444.4 
4   12 
11.58245   665270.6 
4   12 
11.58247   665270.6 
4   12 
11.58245   665271.2 
4   12 
11.5825   765769.3 
4   12 
11.58251   765769.3 
4   12 
11.5825   765770.1 
4   12 
11.58253   866268.1 
4   12 
11.58254   866268.1 
4   12 
11.58253   866269 
4   12 
11.58248   848032 
4   12 
11.58253   863703.8 
4   12 
11.58253   865939.7 
4   12 
11.58253   866225.7 
4   12 
11.58253   866262.6 
4   12 
11.58253   866267.4 
4   12 
11.58369   866268.1 
4   12 
11.58138   866268.1 
4   12 
11.58253   866354.7 
4   12 
11.58253   866181.5 
4   12 
11.58249   912516.3 
4   12 
11.58365   912516.3 
4   12 
11.58134   912516.3 
4   12 
11.58249   912607.5 
4   12 
11.58249   912425 
4   12 
11.58244   1013015 
4   12 
11.5836   1013015 
4   12 
11.58129   1013015 
4   12 
11.58244   1013116 
4   12 
11.58244   1012914 
Fit Mean:  11.58244  Size:  1013015  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  11.58244  Size:  1013015  Code:  1  Try Size:  100 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
4 12
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
1013015   11.58244 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 1013015
> print(nb_fit_mu);
[1] 11.58244
> 
> print(m)
[1] 26.91837
> print(v)
[1] 432.4932
> print(D)
[1] 16.06684
> 
> print(deletion_propagation_coverage)
[1] 3
> 
> warnings()
> 

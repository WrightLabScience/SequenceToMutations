
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | 3a+_BHI_c50_out/07_error_calibration/81.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | 3a+_BHI_c50_out/output/calibration/81.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.0023338 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 5 to 16.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  11.61925  Size:  10000 
5   16 
11.61925   10000 
5   16 
11.61925   10000 
5   16 
11.61926   10000 
5   16 
11.61925   10000.01 
5   16 
11.62907   10000 
5   16 
11.62909   10000 
5   16 
11.62907   10000.01 
5   16 
12.48055   10000 
5   16 
12.48056   10000 
5   16 
12.48055   10000.01 
5   16 
12.55207   10000 
5   16 
12.55208   10000 
5   16 
12.55207   10000.01 
5   16 
12.55985   10000 
5   16 
12.55986   10000 
5   16 
12.55985   10000.01 
5   16 
12.55992   10000 
5   16 
12.55994   10000 
5   16 
12.55992   10000.01 
5   16 
12.55992   10000 
5   16 
12.55994   10000 
5   16 
12.55992   10000.01 
Fit Mean:  12.55992  Size:  10000  Code:  2 
Try Mean:  11.61925  Size:  1000 
5   16 
11.61925   1000 
5   16 
11.61925   1000 
5   16 
11.61926   1000 
5   16 
11.61925   1000.001 
5   16 
11.6291   1000 
5   16 
11.62911   1000 
5   16 
11.6291   1000.001 
5   16 
12.49419   1000 
5   16 
12.4942   1000 
5   16 
12.49419   1000.001 
5   16 
12.5689   1000 
5   16 
12.56891   1000 
5   16 
12.5689   1000.001 
5   16 
12.57726   1000 
5   16 
12.57727   1000 
5   16 
12.57726   1000.001 
5   16 
12.57735   1000 
5   16 
12.57736   1000 
5   16 
12.57735   1000.001 
5   16 
12.57736   1000 
5   16 
12.57737   1000 
5   16 
12.57736   1000.001 
Fit Mean:  12.57736  Size:  1000  Code:  2 
Try Mean:  11.61925  Size:  100 
5   16 
11.61925   100 
5   16 
11.61925   100 
5   16 
11.61926   100 
5   16 
11.61925   100.0001 
5   16 
11.62928   100 
5   16 
11.62929   100 
5   16 
11.62928   100.0001 
5   16 
12.6306   100.0061 
5   16 
12.63061   100.0061 
5   16 
12.6306   100.0062 
5   16 
12.74128   100.0089 
5   16 
12.74129   100.0089 
5   16 
12.74128   100.009 
5   16 
12.75756   100.0114 
5   16 
12.75757   100.0114 
5   16 
12.75756   100.0115 
5   16 
12.75818   100.0137 
5   16 
12.7582   100.0137 
5   16 
12.75818   100.0138 
5   16 
12.76723   100.0792 
5   16 
12.76724   100.0792 
5   16 
12.76723   100.0793 
5   16 
12.77671   100.2173 
5   16 
12.77672   100.2173 
5   16 
12.77671   100.2174 
5   16 
12.79445   100.6816 
5   16 
12.79446   100.6816 
5   16 
12.79445   100.6817 
5   16 
12.81945   101.8641 
5   16 
12.81946   101.8641 
5   16 
12.81945   101.8642 
5   16 
12.85494   104.9957 
5   16 
12.85495   104.9957 
5   16 
12.85494   104.9958 
5   16 
12.89483   112.5844 
5   16 
12.89485   112.5844 
5   16 
12.89483   112.5845 
5   16 
12.91927   130.1806 
5   16 
12.91928   130.1806 
5   16 
12.91927   130.1807 
5   16 
12.88127   169.5099 
5   16 
12.88129   169.5099 
5   16 
12.88127   169.5101 
5   16 
12.72599   246.0984 
5   16 
12.72601   246.0984 
5   16 
12.72599   246.0987 
5   16 
12.57065   328.3387 
5   16 
12.57067   328.3387 
5   16 
12.57065   328.3391 
5   16 
12.52585   376.803 
5   16 
12.52586   376.803 
5   16 
12.52585   376.8033 
5   16 
12.50183   461.9776 
5   16 
12.50184   461.9776 
5   16 
12.50183   461.9781 
5   16 
12.51675   603.9022 
5   16 
12.51676   603.9022 
5   16 
12.51675   603.9028 
5   16 
12.55941   800.1555 
5   16 
12.55942   800.1555 
5   16 
12.55941   800.1563 
5   16 
12.58892   1025.741 
5   16 
12.58894   1025.741 
5   16 
12.58892   1025.742 
5   16 
12.5984   1313.349 
5   16 
12.59841   1313.349 
5   16 
12.5984   1313.351 
5   16 
12.58999   1739.613 
5   16 
12.59   1739.613 
5   16 
12.58999   1739.615 
5   16 
12.57095   2326.918 
5   16 
12.57097   2326.918 
5   16 
12.57095   2326.92 
5   16 
12.5553   3049.348 
5   16 
12.55531   3049.348 
5   16 
12.5553   3049.351 
5   16 
12.54832   3958.892 
5   16 
12.54833   3958.892 
5   16 
12.54832   3958.896 
5   16 
12.54951   5214.476 
5   16 
12.54952   5214.476 
5   16 
12.54951   5214.481 
5   16 
12.55573   6918.317 
5   16 
12.55575   6918.317 
5   16 
12.55573   6918.324 
5   16 
12.5616   9107.831 
5   16 
12.56161   9107.831 
5   16 
12.5616   9107.841 
5   16 
12.5642   11944.96 
5   16 
12.56421   11944.96 
5   16 
12.5642   11944.97 
5   16 
12.56336   15791.23 
5   16 
12.56337   15791.23 
5   16 
12.56336   15791.25 
5   16 
12.56044   20970.28 
5   16 
12.56045   20970.28 
5   16 
12.56044   20970.3 
5   16 
12.55758   27723.72 
5   16 
12.5576   27723.72 
5   16 
12.55758   27723.75 
5   16 
12.55612   36498.95 
5   16 
12.55614   36498.95 
5   16 
12.55612   36498.99 
5   16 
12.55621   48259.04 
5   16 
12.55622   48259.04 
5   16 
12.55621   48259.09 
5   16 
12.55728   63980.06 
5   16 
12.55729   63980.06 
5   16 
12.55728   63980.12 
5   16 
12.55842   84614.16 
5   16 
12.55843   84614.16 
5   16 
12.55842   84614.25 
5   16 
12.55902   111490.2 
5   16 
12.55903   111490.2 
5   16 
12.55902   111490.4 
5   16 
12.55897   148051.3 
5   16 
12.55898   148051.3 
5   16 
12.55897   148051.5 
5   16 
12.55849   196136.3 
5   16 
12.5585   196136.3 
5   16 
12.55849   196136.5 
5   16 
12.55797   256417.6 
5   16 
12.55798   256417.6 
5   16 
12.55797   256417.8 
5   16 
12.5576   348892.5 
5   16 
12.55761   348892.5 
5   16 
12.5576   348892.9 
5   16 
12.5576   449565.3 
5   16 
12.55762   449565.3 
5   16 
12.5576   449565.7 
5   16 
12.55773   550238.1 
5   16 
12.55775   550238.1 
5   16 
12.55773   550238.6 
5   16 
12.55786   650910.8 
5   16 
12.55787   650910.8 
5   16 
12.55786   650911.5 
5   16 
12.55796   751583.6 
5   16 
12.55797   751583.6 
5   16 
12.55796   751584.4 
5   16 
12.55803   852256.4 
5   16 
12.55805   852256.4 
5   16 
12.55803   852257.2 
Fit Mean:  12.55803  Size:  852256.4  Code:  5 
Try Mean:  11.61925  Size:  10 
5   16 
11.61925   10 
5   16 
11.61925   10 
5   16 
11.61926   10 
5   16 
11.61925   10.00001 
5   16 
11.62877   10.00174 
5   16 
11.62878   10.00174 
5   16 
11.62877   10.00175 
5   16 
13.95421   10.92141 
5   16 
13.95422   10.92141 
5   16 
13.95421   10.92142 
5   16 
14.64174   11.4615 
5   16 
14.64175   11.4615 
5   16 
14.64174   11.46151 
5   16 
14.91402   11.87946 
5   16 
14.91404   11.87946 
5   16 
14.91402   11.87947 
5   16 
14.99241   12.3183 
5   16 
14.99243   12.3183 
5   16 
14.99241   12.31831 
5   16 
14.96376   13.95386 
5   16 
14.96377   13.95386 
5   16 
14.96376   13.95387 
5   16 
14.39992   18.8228 
5   16 
14.39993   18.8228 
5   16 
14.39992   18.82282 
5   16 
9.162366   57.22874 
5   16 
13.76697   23.46408 
5   16 
13.76698   23.46408 
5   16 
13.76697   23.46411 
5   16 
11.5703   41.67776 
5   16 
13.11475   28.87199 
5   16 
13.11476   28.87199 
5   16 
13.11475   28.87202 
5   16 
12.82921   33.09583 
5   16 
12.82922   33.09583 
5   16 
12.82921   33.09587 
5   16 
12.75308   38.1962 
5   16 
12.75309   38.1962 
5   16 
12.75308   38.19623 
5   16 
12.84418   52.38169 
5   16 
12.84419   52.38169 
5   16 
12.84418   52.38174 
5   16 
12.82866   67.76531 
5   16 
12.82867   67.76531 
5   16 
12.82866   67.76538 
5   16 
12.7262   91.86951 
5   16 
12.72621   91.86951 
5   16 
12.7262   91.8696 
5   16 
12.67957   122.1655 
5   16 
12.67958   122.1655 
5   16 
12.67957   122.1656 
5   16 
12.6539   162.5535 
5   16 
12.65391   162.5535 
5   16 
12.6539   162.5536 
5   16 
12.62812   216.0062 
5   16 
12.62813   216.0062 
5   16 
12.62812   216.0064 
5   16 
12.61313   286.923 
5   16 
12.61315   286.923 
5   16 
12.61313   286.9233 
5   16 
12.59753   380.8948 
5   16 
12.59754   380.8948 
5   16 
12.59753   380.8952 
5   16 
12.59019   505.3717 
5   16 
12.59021   505.3717 
5   16 
12.59019   505.3722 
5   16 
12.57959   670.42 
5   16 
12.5796   670.42 
5   16 
12.57959   670.4207 
5   16 
12.5776   888.9547 
5   16 
12.57762   888.9547 
5   16 
12.5776   888.9556 
5   16 
12.56867   1179.014 
5   16 
12.56869   1179.014 
5   16 
12.56867   1179.015 
5   16 
12.5712   1563.276 
5   16 
12.57121   1563.276 
5   16 
12.5712   1563.278 
5   16 
12.56156   2074.829 
5   16 
12.56158   2074.829 
5   16 
12.56156   2074.831 
5   16 
12.56805   2754.483 
5   16 
12.56806   2754.483 
5   16 
12.56805   2754.486 
5   16 
12.5579   3662.209 
5   16 
12.55792   3662.209 
5   16 
12.5579   3662.212 
5   16 
12.56428   4864.863 
5   16 
12.56429   4864.863 
5   16 
12.56428   4864.868 
5   16 
12.55848   6455.8 
5   16 
12.55849   6455.8 
5   16 
12.55848   6455.806 
5   16 
12.56064   8558.113 
5   16 
12.56065   8558.113 
5   16 
12.56064   8558.122 
5   16 
12.55888   11339.22 
5   16 
12.55889   11339.22 
5   16 
12.55888   11339.24 
5   16 
12.55918   15024.08 
5   16 
12.5592   15024.08 
5   16 
12.55918   15024.1 
5   16 
12.55865   19901.71 
5   16 
12.55866   19901.71 
5   16 
12.55865   19901.73 
5   16 
12.5586   26368.46 
5   16 
12.55862   26368.46 
5   16 
12.5586   26368.48 
5   16 
12.5584   34917.75 
5   16 
12.55841   34917.75 
5   16 
12.5584   34917.79 
5   16 
12.55833   46272.41 
5   16 
12.55834   46272.41 
5   16 
12.55833   46272.45 
5   16 
12.55823   61284.07 
5   16 
12.55825   61284.07 
5   16 
12.55823   61284.13 
5   16 
12.55819   76614.01 
5   16 
12.5582   76614.01 
5   16 
12.55819   76614.08 
5   16 
12.55816   91943.94 
5   16 
12.55817   91943.94 
5   16 
12.55816   91944.03 
5   16 
12.55814   107273.9 
5   16 
12.55815   107273.9 
5   16 
12.55814   107274 
5   16 
12.55812   122603.8 
5   16 
12.55813   122603.8 
5   16 
12.55812   122603.9 
5   16 
12.55811   137933.7 
5   16 
12.55812   137933.7 
5   16 
12.55811   137933.9 
Fit Mean:  12.55811  Size:  137933.7  Code:  5 
Try Mean:  11.61925  Size:  1 
5   16 
11.61925   1 
5   16 
11.61925   1 
5   16 
11.61926   1 
5   16 
11.61925   1.000001 
5   16 
11.62242   1.01354 
5   16 
11.62243   1.01354 
5   16 
11.62242   1.013541 
5   16 
15.95262   6.277361 
5   16 
15.95264   6.277361 
5   16 
15.95262   6.277367 
5   16 
17.19609   7.650923 
5   16 
17.1961   7.650923 
5   16 
17.19609   7.650931 
5   16 
17.16081   7.777775 
5   16 
17.16083   7.777775 
5   16 
17.16081   7.777783 
5   16 
14.44992   12.97117 
5   16 
14.44993   12.97117 
5   16 
14.44992   12.97119 
5   16 
9.8948   22.7165 
5   16 
13.99441   13.94571 
5   16 
13.99442   13.94571 
5   16 
13.99441   13.94572 
5   16 
13.4223   16.46992 
5   16 
13.42232   16.46992 
5   16 
13.4223   16.46994 
5   16 
13.19645   20.21024 
5   16 
13.19647   20.21024 
5   16 
13.19645   20.21026 
5   16 
13.32188   27.35439 
5   16 
13.32189   27.35439 
5   16 
13.32188   27.35442 
5   16 
12.98059   36.91211 
5   16 
12.9806   36.91211 
5   16 
12.98059   36.91215 
5   16 
12.88681   50.22287 
5   16 
12.88683   50.22287 
5   16 
12.88681   50.22292 
5   16 
12.80035   66.76097 
5   16 
12.80036   66.76097 
5   16 
12.80035   66.76103 
5   16 
12.75458   89.45234 
5   16 
12.75459   89.45234 
5   16 
12.75458   89.45243 
5   16 
12.67153   119.6346 
5   16 
12.67154   119.6346 
5   16 
12.67153   119.6348 
5   16 
12.72537   160.4358 
5   16 
12.72538   160.4358 
5   16 
12.72537   160.4359 
5   16 
12.53473   224.1376 
5   16 
12.53474   224.1376 
5   16 
12.53473   224.1378 
5   16 
12.59352   282.8771 
5   16 
12.59353   282.8771 
5   16 
12.59352   282.8774 
5   16 
12.60639   376.1256 
5   16 
12.60641   376.1256 
5   16 
12.60639   376.126 
5   16 
12.59106   497.5673 
5   16 
12.59107   497.5673 
5   16 
12.59106   497.5678 
5   16 
12.57919   661.4321 
5   16 
12.5792   661.4321 
5   16 
12.57919   661.4328 
5   16 
12.57392   876.1797 
5   16 
12.57394   876.1797 
5   16 
12.57392   876.1805 
5   16 
12.57039   1161.437 
5   16 
12.57041   1161.437 
5   16 
12.57039   1161.439 
5   16 
12.56741   1539.001 
5   16 
12.56742   1539.001 
5   16 
12.56741   1539.002 
5   16 
12.56508   2039.433 
5   16 
12.56509   2039.433 
5   16 
12.56508   2039.435 
5   16 
12.56334   2702.231 
5   16 
12.56335   2702.231 
5   16 
12.56334   2702.234 
5   16 
12.56203   3580.335 
5   16 
12.56205   3580.335 
5   16 
12.56203   3580.339 
5   16 
12.56104   4743.541 
5   16 
12.56106   4743.541 
5   16 
12.56104   4743.546 
5   16 
12.5603   6284.436 
5   16 
12.56031   6284.436 
5   16 
12.5603   6284.442 
5   16 
12.55973   8325.747 
5   16 
12.55975   8325.747 
5   16 
12.55973   8325.755 
5   16 
12.55931   11030.03 
5   16 
12.55932   11030.03 
5   16 
12.55931   11030.04 
5   16 
12.55899   14611.88 
5   16 
12.559   14611.88 
5   16 
12.55899   14611.89 
5   16 
12.55874   19357.81 
5   16 
12.55875   19357.81 
5   16 
12.55874   19357.83 
5   16 
12.55856   25642.44 
5   16 
12.55857   25642.44 
5   16 
12.55856   25642.47 
5   16 
12.55842   33978.59 
5   16 
12.55843   33978.59 
5   16 
12.55842   33978.62 
5   16 
12.55832   45007.13 
5   16 
12.55833   45007.13 
5   16 
12.55832   45007.17 
5   16 
12.55825   56669.33 
5   16 
12.55827   56669.33 
5   16 
12.55825   56669.39 
5   16 
12.55821   68331.53 
5   16 
12.55822   68331.53 
5   16 
12.55821   68331.6 
5   16 
12.55818   79993.73 
5   16 
12.5582   79993.73 
5   16 
12.55818   79993.81 
5   16 
12.55816   91655.93 
5   16 
12.55817   91655.93 
5   16 
12.55816   91656.02 
5   16 
12.55814   103318.1 
5   16 
12.55816   103318.1 
5   16 
12.55814   103318.2 
Fit Mean:  12.55814  Size:  103318.1  Code:  5 
Try Mean:  11.61925  Size:  0.1 
5   16 
11.61925   0.1 
5   16 
11.61925   0.1 
5   16 
11.61926   0.1 
5   16 
11.61925   0.100001 
5   16 
11.61964   0.1197034 
5   16 
11.61965   0.1197034 
5   16 
11.61964   0.1197044 
5   16 
12.70954   2.818436 
5   16 
12.70955   2.818436 
5   16 
12.70954   2.818439 
5   16 
15.00622   6.212708 
5   16 
15.00623   6.212708 
5   16 
15.00622   6.212714 
5   16 
16.41848   8.241177 
5   16 
16.41849   8.241177 
5   16 
16.41848   8.241185 
5   16 
16.58726   8.593125 
5   16 
16.58727   8.593125 
5   16 
16.58726   8.593134 
5   16 
16.62334   8.862479 
5   16 
16.62336   8.862479 
5   16 
16.62334   8.862488 
5   16 
16.53249   9.71388 
5   16 
16.53251   9.71388 
5   16 
16.53249   9.71389 
5   16 
15.83967   12.4676 
5   16 
15.83968   12.4676 
5   16 
15.83967   12.46762 
5   16 
15.06825   15.06459 
5   16 
15.06827   15.06459 
5   16 
15.06825   15.06461 
5   16 
14.22116   18.12711 
5   16 
14.22117   18.12711 
5   16 
14.22116   18.12713 
5   16 
10.08383   35.07828 
5   16 
13.7009   20.2587 
5   16 
13.70091   20.2587 
5   16 
13.7009   20.25872 
5   16 
12.83894   24.76328 
5   16 
12.83895   24.76328 
5   16 
12.83894   24.7633 
5   16 
13.15919   24.06372 
5   16 
13.1592   24.06372 
5   16 
13.15919   24.06375 
5   16 
13.29154   25.46978 
5   16 
13.29155   25.46978 
5   16 
13.29154   25.46981 
5   16 
13.37305   32.2308 
5   16 
13.37306   32.2308 
5   16 
13.37305   32.23084 
5   16 
13.14366   42.74985 
5   16 
13.14367   42.74985 
5   16 
13.14366   42.7499 
5   16 
12.68387   62.53778 
5   16 
12.68389   62.53778 
5   16 
12.68387   62.53784 
5   16 
12.65996   75.1564 
5   16 
12.65997   75.1564 
5   16 
12.65996   75.15647 
5   16 
12.72856   102.1547 
5   16 
12.72858   102.1547 
5   16 
12.72856   102.1548 
5   16 
12.67454   134.0993 
5   16 
12.67455   134.0993 
5   16 
12.67454   134.0994 
5   16 
12.64204   179.7971 
5   16 
12.64206   179.7971 
5   16 
12.64204   179.7972 
5   16 
12.62255   238.1927 
5   16 
12.62256   238.1927 
5   16 
12.62255   238.1929 
5   16 
12.60599   316.6208 
5   16 
12.606   316.6208 
5   16 
12.60599   316.6212 
5   16 
12.59482   420.006 
5   16 
12.59483   420.006 
5   16 
12.59482   420.0064 
5   16 
12.58532   557.2568 
5   16 
12.58533   557.2568 
5   16 
12.58532   557.2573 
5   16 
12.5791   738.9419 
5   16 
12.57911   738.9419 
5   16 
12.5791   738.9427 
5   16 
12.57348   979.7291 
5   16 
12.57349   979.7291 
5   16 
12.57348   979.7301 
5   16 
12.57016   1298.646 
5   16 
12.57017   1298.646 
5   16 
12.57016   1298.647 
5   16 
12.56668   1721.205 
5   16 
12.56669   1721.205 
5   16 
12.56668   1721.207 
5   16 
12.5651   2280.906 
5   16 
12.56511   2280.906 
5   16 
12.5651   2280.908 
5   16 
12.56276   3022.507 
5   16 
12.56277   3022.507 
5   16 
12.56276   3022.51 
5   16 
12.56225   4004.789 
5   16 
12.56227   4004.789 
5   16 
12.56225   4004.794 
5   16 
12.56047   5306.447 
5   16 
12.56048   5306.447 
5   16 
12.56047   5306.453 
5   16 
12.56069   7030.694 
5   16 
12.5607   7030.694 
5   16 
12.56069   7030.701 
5   16 
12.5591   9316.006 
5   16 
12.55912   9316.006 
5   16 
12.5591   9316.015 
5   16 
12.55986   12343.77 
5   16 
12.55987   12343.77 
5   16 
12.55986   12343.78 
5   16 
12.55827   16359.41 
5   16 
12.55828   16359.41 
5   16 
12.55827   16359.43 
5   16 
12.55943   21682.88 
5   16 
12.55944   21682.88 
5   16 
12.55943   21682.91 
5   16 
12.55778   28746.72 
5   16 
12.55779   28746.72 
5   16 
12.55778   28746.75 
5   16 
12.55913   38107.58 
5   16 
12.55914   38107.58 
5   16 
12.55913   38107.61 
5   16 
12.55773   49727.25 
5   16 
12.55774   49727.25 
5   16 
12.55773   49727.3 
5   16 
12.55845   61346.93 
5   16 
12.55846   61346.93 
5   16 
12.55845   61346.99 
5   16 
12.55813   72966.61 
5   16 
12.55814   72966.61 
5   16 
12.55813   72966.68 
5   16 
12.55819   84586.28 
5   16 
12.55821   84586.28 
5   16 
12.55819   84586.37 
5   16 
12.55815   96205.96 
5   16 
12.55816   96205.96 
5   16 
12.55815   96206.06 
Fit Mean:  12.55815  Size:  96205.96  Code:  5 
Try Mean:  11.61925  Size:  0.01 
5   16 
11.61925   0.01 
5   16 
11.61925   0.01 
5   16 
11.61926   0.01 
5   16 
11.61925   0.010001 
5   16 
11.61929   0.03052884 
5   16 
11.6193   0.03052884 
5   16 
11.61929   0.03052984 
5   16 
12.56125   2.601151 
5   16 
12.56126   2.601151 
5   16 
12.56125   2.601154 
5   16 
14.63921   5.826374 
5   16 
14.63922   5.826374 
5   16 
14.63921   5.82638 
5   16 
16.30309   8.274397 
5   16 
16.30311   8.274397 
5   16 
16.30309   8.274405 
5   16 
16.51266   8.687181 
5   16 
16.51268   8.687181 
5   16 
16.51266   8.68719 
5   16 
16.55314   8.930269 
5   16 
16.55315   8.930269 
5   16 
16.55314   8.930278 
5   16 
16.49588   9.697155 
5   16 
16.4959   9.697155 
5   16 
16.49588   9.697165 
5   16 
15.97733   11.95097 
5   16 
15.97734   11.95097 
5   16 
15.97733   11.95098 
Fit Mean:  -17.06031  Size:  142.6742  Code:  1 
Try Mean:  11.61925  Size:  0.001 
5   16 
11.61925   0.001 
5   16 
11.61925   0.001 
5   16 
11.61926   0.001 
5   16 
11.61925   0.001001 
5   16 
11.61925   0.02161406 
5   16 
11.61926   0.02161406 
5   16 
11.61925   0.02161506 
5   16 
12.54733   2.580133 
5   16 
12.54735   2.580133 
5   16 
12.54733   2.580135 
5   16 
14.60332   5.787371 
5   16 
14.60334   5.787371 
5   16 
14.60332   5.787377 
5   16 
16.29097   8.276982 
5   16 
16.29099   8.276982 
5   16 
16.29097   8.27699 
5   16 
16.50506   8.69672 
5   16 
16.50508   8.69672 
5   16 
16.50506   8.696729 
5   16 
16.54601   8.937969 
5   16 
16.54603   8.937969 
5   16 
16.54601   8.937978 
5   16 
16.49182   9.696439 
5   16 
16.49184   9.696439 
5   16 
16.49182   9.696448 
5   16 
15.98798   11.90808 
5   16 
15.98799   11.90808 
5   16 
15.98798   11.90809 
Fit Mean:  -9.171252  Size:  111.263  Code:  1 
Try Mean:  16  Size:  10000 
5   16 
16   10000 
5   16 
16   10000 
5   16 
16.00002   10000 
5   16 
16   10000.01 
5   16 
15.98088   10000 
5   16 
15.98089   10000 
5   16 
15.98088   10000.01 
5   16 
8.086265   10000 
5   16 
13.35266   10000 
5   16 
13.35267   10000 
5   16 
13.35266   10000.01 
5   16 
11.93401   10000 
5   16 
11.93402   10000 
5   16 
11.93401   10000.01 
5   16 
12.62373   10000 
5   16 
12.62374   10000 
5   16 
12.62373   10000.01 
5   16 
12.56451   10000 
5   16 
12.56453   10000 
5   16 
12.56451   10000.01 
5   16 
12.55989   10000 
5   16 
12.5599   10000 
5   16 
12.55989   10000.01 
5   16 
12.55992   10000 
5   16 
12.55994   10000 
5   16 
12.55992   10000.01 
5   16 
12.55992   10000 
5   16 
12.55994   10000 
5   16 
12.55992   10000.01 
Fit Mean:  12.55992  Size:  10000  Code:  2 
Try Mean:  16  Size:  1000 
5   16 
16   1000 
5   16 
16   1000 
5   16 
16.00002   1000 
5   16 
16   1000.001 
5   16 
15.98131   1000 
5   16 
15.98132   1000 
5   16 
15.98131   1000.001 
5   16 
8.180419   1000.001 
5   16 
13.36527   1000 
5   16 
13.36528   1000 
5   16 
13.36527   1000.001 
5   16 
11.95867   1000.001 
5   16 
11.95868   1000.001 
5   16 
11.95867   1000.002 
5   16 
12.64063   1000.001 
5   16 
12.64064   1000.001 
5   16 
12.64063   1000.002 
5   16 
12.5819   1000.001 
5   16 
12.58192   1000.001 
5   16 
12.5819   1000.002 
5   16 
12.57731   1000.001 
5   16 
12.57733   1000.001 
5   16 
12.57731   1000.002 
5   16 
12.57735   1000.001 
5   16 
12.57736   1000.001 
5   16 
12.57735   1000.002 
5   16 
12.57742   1000.001 
5   16 
12.57743   1000.001 
5   16 
12.57742   1000.002 
5   16 
12.57752   1000.003 
5   16 
12.57753   1000.003 
5   16 
12.57752   1000.004 
5   16 
12.57768   1000.007 
5   16 
12.5777   1000.007 
5   16 
12.57768   1000.008 
5   16 
12.57795   1000.018 
5   16 
12.57797   1000.018 
5   16 
12.57795   1000.019 
5   16 
12.57839   1000.049 
5   16 
12.5784   1000.049 
5   16 
12.57839   1000.05 
5   16 
12.5791   1000.131 
5   16 
12.57911   1000.131 
5   16 
12.5791   1000.132 
5   16 
12.58024   1000.348 
5   16 
12.58025   1000.348 
5   16 
12.58024   1000.349 
5   16 
12.58207   1000.922 
5   16 
12.58209   1000.922 
5   16 
12.58207   1000.923 
5   16 
12.58502   1002.429 
5   16 
12.58503   1002.429 
5   16 
12.58502   1002.43 
5   16 
12.58971   1006.362 
5   16 
12.58972   1006.362 
5   16 
12.58971   1006.363 
5   16 
12.597   1016.523 
5   16 
12.59701   1016.523 
5   16 
12.597   1016.524 
5   16 
12.60776   1042.198 
5   16 
12.60777   1042.198 
5   16 
12.60776   1042.199 
5   16 
12.62179   1104.169 
5   16 
12.6218   1104.169 
5   16 
12.62179   1104.17 
5   16 
12.63534   1243.27 
5   16 
12.63536   1243.27 
5   16 
12.63534   1243.271 
5   16 
12.6384   1531.969 
5   16 
12.63842   1531.969 
5   16 
12.6384   1531.97 
5   16 
12.61652   2069.472 
5   16 
12.61654   2069.472 
5   16 
12.61652   2069.474 
5   16 
12.57563   2822.499 
5   16 
12.57564   2822.499 
5   16 
12.57563   2822.502 
5   16 
12.5482   3520.367 
5   16 
12.54821   3520.367 
5   16 
12.5482   3520.37 
5   16 
12.53686   4178.076 
5   16 
12.53687   4178.076 
5   16 
12.53686   4178.081 
5   16 
12.53373   5267.796 
5   16 
12.53374   5267.796 
5   16 
12.53373   5267.802 
5   16 
12.54232   6998.012 
5   16 
12.54233   6998.012 
5   16 
12.54232   6998.019 
5   16 
12.5566   9283.328 
5   16 
12.55661   9283.328 
5   16 
12.5566   9283.338 
5   16 
12.56607   11804.11 
5   16 
12.56608   11804.11 
5   16 
12.56607   11804.12 
5   16 
12.56977   14932.22 
5   16 
12.56978   14932.22 
5   16 
12.56977   14932.23 
5   16 
12.56819   19615.6 
5   16 
12.5682   19615.6 
5   16 
12.56819   19615.62 
5   16 
12.56246   26245.77 
5   16 
12.56247   26245.77 
5   16 
12.56246   26245.8 
5   16 
12.55686   34385.19 
5   16 
12.55687   34385.19 
5   16 
12.55686   34385.23 
5   16 
12.55383   44122.23 
5   16 
12.55384   44122.23 
5   16 
12.55383   44122.27 
5   16 
12.55341   57417.76 
5   16 
12.55342   57417.76 
5   16 
12.55341   57417.82 
5   16 
12.55527   76436.74 
5   16 
12.55529   76436.74 
5   16 
12.55527   76436.82 
5   16 
12.5579   100961.4 
5   16 
12.55791   100961.4 
5   16 
12.5579   100961.5 
5   16 
12.55974   131574 
5   16 
12.55975   131574 
5   16 
12.55974   131574.1 
5   16 
12.56033   171272.4 
5   16 
12.56034   171272.4 
5   16 
12.56033   171272.6 
5   16 
12.55975   226024.9 
5   16 
12.55977   226024.9 
5   16 
12.55975   226025.2 
5   16 
12.55852   302842.6 
5   16 
12.55853   302842.6 
5   16 
12.55852   302842.9 
5   16 
12.5574   407167.4 
5   16 
12.55741   407167.4 
5   16 
12.5574   407167.8 
5   16 
12.55693   533908.3 
5   16 
12.55694   533908.3 
5   16 
12.55693   533908.8 
5   16 
12.55712   677810 
5   16 
12.55714   677810 
5   16 
12.55712   677810.7 
5   16 
12.55766   846789.4 
5   16 
12.55768   846789.4 
5   16 
12.55766   846790.2 
5   16 
12.55818   1056993 
5   16 
12.55819   1056993 
5   16 
12.55818   1056994 
5   16 
12.55846   1274248 
5   16 
12.55848   1274248 
5   16 
12.55846   1274249 
5   16 
12.55844   1541316 
5   16 
12.55845   1541316 
5   16 
12.55844   1541317 
5   16 
12.55823   1550600 
5   16 
12.55824   1550600 
5   16 
12.55823   1550601 
5   16 
12.55811   1701818 
5   16 
12.55813   1701818 
5   16 
12.55811   1701820 
5   16 
12.55805   1963058 
5   16 
12.55806   1963058 
5   16 
12.55805   1963060 
5   16 
12.55797   2361457 
5   16 
12.55798   2361457 
5   16 
12.55797   2361460 
5   16 
12.55793   2792376 
5   16 
12.55794   2792376 
5   16 
12.55793   2792379 
5   16 
12.55795   3002300 
5   16 
12.55796   3002300 
5   16 
12.55795   3002303 
5   16 
12.55793   3731024 
5   16 
12.55795   3731024 
5   16 
12.55793   3731027 
5   16 
12.55797   3684243 
5   16 
12.55794   3723682 
5   16 
12.55793   3729985 
5   16 
12.55793   3730876 
5   16 
12.55793   3731001 
5   16 
12.55793   3731020 
5   16 
12.55793   3731023 
5   16 
12.55919   3731024 
5   16 
12.55668   3731024 
5   16 
12.55793   3731397 
5   16 
12.55793   3730651 
5   16 
12.55797   3841069 
5   16 
12.55922   3841069 
5   16 
12.55671   3841069 
5   16 
12.55797   3841453 
5   16 
12.55797   3840685 
5   16 
12.55798   3938974 
5   16 
12.55924   3938974 
5   16 
12.55673   3938974 
5   16 
12.55798   3939368 
5   16 
12.55798   3938580 
5   16 
12.55799   4042230 
5   16 
12.55925   4042230 
5   16 
12.55674   4042230 
5   16 
12.55799   4042634 
5   16 
12.55799   4041825 
5   16 
12.55803   4843928 
5   16 
12.55929   4843928 
5   16 
12.55678   4843928 
5   16 
12.55803   4844412 
5   16 
12.55803   4843443 
5   16 
12.55805   5413479 
5   16 
12.5593   5413479 
5   16 
12.55679   5413479 
5   16 
12.55805   5414020 
5   16 
12.55805   5412938 
5   16 
12.55805   6413607 
5   16 
12.5593   6413607 
5   16 
12.55679   6413607 
5   16 
12.55805   6414248 
5   16 
12.55805   6412966 
5   16 
12.55804   7413735 
5   16 
12.55929   7413735 
5   16 
12.55678   7413735 
5   16 
12.55804   7414476 
5   16 
12.55804   7412994 
5   16 
12.55803   8413863 
5   16 
12.55928   8413863 
5   16 
12.55677   8413863 
5   16 
12.55803   8414704 
5   16 
12.55803   8413022 
5   16 
12.55802   9413991 
5   16 
12.55927   9413991 
5   16 
12.55676   9413991 
5   16 
12.55802   9414932 
5   16 
12.55802   9413049 
5   16 
12.55801   10315256 
5   16 
12.55927   10315256 
5   16 
12.55675   10315256 
5   16 
12.55801   10316287 
5   16 
12.55801   10314224 
Fit Mean:  12.55801  Size:  10315256  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  12.55801  Size:  10315256  Code:  1  Try Size:  1000 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
5 16
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
10315256   12.55801 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 10315256
> print(nb_fit_mu);
[1] 12.55801
> 
> print(m)
[1] 11.61925
> print(v)
[1] 7.724166
> print(D)
[1] 0.6647734
> 
> print(deletion_propagation_coverage)
[1] 4
> 
> warnings()
> 

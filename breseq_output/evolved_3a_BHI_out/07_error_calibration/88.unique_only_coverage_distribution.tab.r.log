
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2022 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs(TRUE)) {
+   ta = strsplit(e,"=",fixed=TRUE)[[1]]
+   if(length(ta)>1) {
+     temp = ta[2]
+     assign(ta[1],temp)
+     cat("assigned ",ta[1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[1]," the value of TRUE\n")
+   }
+ }
assigned  distribution_file  the value of | 3a-_BHI_c50_out/07_error_calibration/88.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | 3a-_BHI_c50_out/output/calibration/88.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.00273588 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 1 to 5.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  2.493827  Size:  10000 
1   5 
2.493827   10000 
1   5 
2.493827   10000 
1   5 
2.49383   10000 
1   5 
2.493827   10000.01 
1   5 
2.484128   10000 
1   5 
2.48413   10000 
1   5 
2.484128   10000.01 
1   5 
2.395458   10000 
1   5 
2.39546   10000 
1   5 
2.395458   10000.01 
1   5 
2.400677   10000 
1   5 
2.400679   10000 
1   5 
2.400677   10000.01 
1   5 
2.400421   10000 
1   5 
2.400423   10000 
1   5 
2.400421   10000.01 
1   5 
2.40042   10000 
1   5 
2.400661   10000 
1   5 
2.400181   10000 
1   5 
2.400421   10001 
1   5 
2.400421   9999 
1   5 
2.400421   10000 
1   5 
2.400661   10000 
1   5 
2.400181   10000 
1   5 
2.400421   10001 
1   5 
2.400421   9999 
Fit Mean:  2.400421  Size:  10000  Code:  2 
Try Mean:  2.493827  Size:  1000 
1   5 
2.493827   1000 
1   5 
2.493827   1000 
1   5 
2.49383   1000 
1   5 
2.493827   1000.001 
1   5 
2.484265   1000 
1   5 
2.484268   1000 
1   5 
2.484265   1000.001 
1   5 
2.39659   1000 
1   5 
2.396592   1000 
1   5 
2.39659   1000.001 
1   5 
2.401699   1000 
1   5 
2.401701   1000 
1   5 
2.401699   1000.001 
1   5 
2.40145   1000 
1   5 
2.401452   1000 
1   5 
2.40145   1000.001 
1   5 
2.401449   1000 
1   5 
2.40169   1000 
1   5 
2.40121   1000 
1   5 
2.40145   1000.1 
1   5 
2.40145   999.9 
1   5 
2.401451   1000 
1   5 
2.401691   1000 
1   5 
2.40121   1000 
1   5 
2.401451   1000.1 
1   5 
2.401451   999.9 
Fit Mean:  2.401451  Size:  1000  Code:  2 
Try Mean:  2.493827  Size:  100 
1   5 
2.493827   100 
1   5 
2.493827   100 
1   5 
2.49383   100 
1   5 
2.493827   100.0001 
1   5 
2.485602   100 
1   5 
2.485605   100 
1   5 
2.485602   100.0001 
1   5 
2.407893   100.0001 
1   5 
2.407895   100.0001 
1   5 
2.407893   100.0002 
1   5 
2.411951   100.0002 
1   5 
2.411954   100.0002 
1   5 
2.411951   100.0003 
1   5 
2.411774   100.0003 
1   5 
2.411776   100.0003 
1   5 
2.411774   100.0004 
1   5 
2.411749   100.0003 
1   5 
2.411751   100.0003 
1   5 
2.411749   100.0004 
1   5 
2.41155   100.0018 
1   5 
2.411553   100.0018 
1   5 
2.41155   100.0019 
1   5 
2.411327   100.0048 
1   5 
2.411329   100.0048 
1   5 
2.411327   100.0049 
1   5 
2.410904   100.015 
1   5 
2.410906   100.015 
1   5 
2.410904   100.0151 
1   5 
2.410257   100.0416 
1   5 
2.410259   100.0416 
1   5 
2.410257   100.0417 
1   5 
2.409186   100.1146 
1   5 
2.409188   100.1146 
1   5 
2.409186   100.1147 
1   5 
2.40747   100.3072 
1   5 
2.407472   100.3072 
1   5 
2.40747   100.3073 
1   5 
2.404705   100.8144 
1   5 
2.404708   100.8144 
1   5 
2.404705   100.8145 
1   5 
2.400361   102.1236 
1   5 
2.400363   102.1236 
1   5 
2.400361   102.1237 
1   5 
2.393881   105.4008 
1   5 
2.393884   105.4008 
1   5 
2.393881   105.4009 
1   5 
2.385441   113.0925 
1   5 
2.385444   113.0925 
1   5 
2.385441   113.0926 
1   5 
2.377422   129.4949 
1   5 
2.377424   129.4949 
1   5 
2.377422   129.495 
1   5 
2.375402   161.2647 
1   5 
2.375404   161.2647 
1   5 
2.375402   161.2648 
1   5 
2.385357   214.7176 
1   5 
2.385359   214.7176 
1   5 
2.385357   214.7178 
1   5 
2.400675   283.0072 
1   5 
2.400677   283.0072 
1   5 
2.400675   283.0075 
1   5 
2.410039   353.0308 
1   5 
2.410041   353.0308 
1   5 
2.410039   353.0311 
1   5 
2.413731   437.9133 
1   5 
2.413734   437.9133 
1   5 
2.413731   437.9137 
1   5 
2.412411   571.9813 
1   5 
2.412413   571.9813 
1   5 
2.412411   571.9819 
1   5 
2.406311   769.7228 
1   5 
2.406313   769.7228 
1   5 
2.406311   769.7236 
1   5 
2.399946   1010.148 
1   5 
2.399948   1010.148 
1   5 
2.399946   1010.149 
1   5 
2.396427   1279.131 
1   5 
2.396429   1279.131 
1   5 
2.396427   1279.132 
1   5 
2.395502   1642.428 
1   5 
2.395505   1642.428 
1   5 
2.395502   1642.43 
1   5 
2.397079   2177.433 
1   5 
2.397082   2177.433 
1   5 
2.397079   2177.436 
1   5 
2.399868   2889.29 
1   5 
2.39987   2889.29 
1   5 
2.399868   2889.293 
1   5 
2.401948   3745.988 
1   5 
2.40195   3745.988 
1   5 
2.401948   3745.992 
1   5 
2.402775   4836.213 
1   5 
2.402777   4836.213 
1   5 
2.402775   4836.218 
1   5 
2.402393   6375.925 
1   5 
2.402395   6375.925 
1   5 
2.402393   6375.931 
1   5 
2.401182   8499.577 
1   5 
2.401185   8499.577 
1   5 
2.401182   8499.586 
1   5 
2.400002   11164.72 
1   5 
2.400005   11164.72 
1   5 
2.400002   11164.73 
1   5 
2.399361   14482.54 
1   5 
2.399364   14482.54 
1   5 
2.399361   14482.55 
1   5 
2.399293   19180.5 
1   5 
2.399296   19180.5 
1   5 
2.399293   19180.52 
1   5 
2.39973   24785.28 
1   5 
2.399732   24785.28 
1   5 
2.39973   24785.31 
1   5 
2.400395   34084.73 
1   5 
2.400397   34084.73 
1   5 
2.400395   34084.76 
1   5 
2.400767   44538.64 
1   5 
2.400769   44538.64 
1   5 
2.400767   44538.68 
1   5 
2.400815   57121.78 
1   5 
2.400817   57121.78 
1   5 
2.400815   57121.84 
1   5 
2.400618   71776.53 
1   5 
2.400621   71776.53 
1   5 
2.400618   71776.6 
1   5 
2.400219   107497.7 
1   5 
2.400222   107497.7 
1   5 
2.400219   107497.8 
1   5 
2.400092   135608.8 
1   5 
2.400094   135608.8 
1   5 
2.400092   135608.9 
1   5 
2.40002   164003.6 
1   5 
2.400022   164003.6 
1   5 
2.40002   164003.8 
1   5 
2.400094   208765 
1   5 
2.400096   208765 
1   5 
2.400094   208765.2 
1   5 
2.400254   308796.1 
1   5 
2.400256   308796.1 
1   5 
2.400254   308796.4 
1   5 
2.400268   293818.1 
1   5 
2.400257   305744.1 
1   5 
2.400254   308240.8 
1   5 
2.400254   308693 
1   5 
2.400254   308776.9 
1   5 
2.400254   308792.4 
1   5 
2.400254   308795.3 
1   5 
2.400254   308795.8 
1   5 
2.400494   308796.1 
1   5 
2.400014   308796.1 
1   5 
2.400254   308827 
1   5 
2.400254   308765.2 
1   5 
2.400299   330817.5 
1   5 
2.400539   330817.5 
1   5 
2.400059   330817.5 
1   5 
2.400299   330850.6 
1   5 
2.400299   330784.4 
1   5 
2.400414   430848.6 
1   5 
2.400654   430848.6 
1   5 
2.400174   430848.6 
1   5 
2.400414   430891.7 
1   5 
2.400414   430805.5 
1   5 
2.400438   530879.7 
1   5 
2.400678   530879.7 
1   5 
2.400198   530879.7 
1   5 
2.400438   530932.8 
1   5 
2.400438   530826.6 
1   5 
2.400427   630910.8 
1   5 
2.400667   630910.8 
1   5 
2.400187   630910.8 
1   5 
2.400427   630973.9 
1   5 
2.400427   630847.7 
1   5 
2.4004   730941.9 
1   5 
2.40064   730941.9 
1   5 
2.40016   730941.9 
1   5 
2.4004   731015 
1   5 
2.4004   730868.8 
1   5 
2.40037   830973 
1   5 
2.40061   830973 
1   5 
2.400129   830973 
1   5 
2.40037   831056.1 
1   5 
2.40037   830889.9 
Fit Mean:  2.40037  Size:  830973  Code:  5 
Try Mean:  2.493827  Size:  10 
1   5 
2.493827   10 
1   5 
2.493827   10 
1   5 
2.49383   10 
1   5 
2.493827   10.00001 
1   5 
2.495695   10.00063 
1   5 
2.495697   10.00063 
1   5 
2.495695   10.00064 
1   5 
2.521223   10.01916 
1   5 
2.521226   10.01916 
1   5 
2.521223   10.01917 
1   5 
2.524659   10.03277 
1   5 
2.524662   10.03277 
1   5 
2.524659   10.03278 
1   5 
2.546971   10.21155 
1   5 
2.546973   10.21155 
1   5 
2.546971   10.21156 
1   5 
2.567443   10.57209 
1   5 
2.567445   10.57209 
1   5 
2.567443   10.5721 
1   5 
2.590802   11.59418 
1   5 
2.590804   11.59418 
1   5 
2.590802   11.59419 
1   5 
2.595492   13.81384 
1   5 
2.595495   13.81384 
1   5 
2.595492   13.81385 
1   5 
2.548423   18.88506 
1   5 
2.548425   18.88506 
1   5 
2.548423   18.88508 
1   5 
2.43915   27.53489 
1   5 
2.439153   27.53489 
1   5 
2.43915   27.53491 
1   5 
2.393868   33.20557 
1   5 
2.393871   33.20557 
1   5 
2.393868   33.20561 
1   5 
2.381615   38.70676 
1   5 
2.381617   38.70676 
1   5 
2.381615   38.7068 
1   5 
2.388131   51.47551 
1   5 
2.388133   51.47551 
1   5 
2.388131   51.47556 
1   5 
2.407702   67.35252 
1   5 
2.407704   67.35252 
1   5 
2.407702   67.35259 
1   5 
2.418853   86.97723 
1   5 
2.418855   86.97723 
1   5 
2.418853   86.97731 
1   5 
2.419178   113.5006 
1   5 
2.41918   113.5006 
1   5 
2.419178   113.5007 
1   5 
2.411659   151.4343 
1   5 
2.411661   151.4343 
1   5 
2.411659   151.4345 
1   5 
2.403408   200.6519 
1   5 
2.403411   200.6519 
1   5 
2.403408   200.6521 
1   5 
2.399094   263.3781 
1   5 
2.399096   263.3781 
1   5 
2.399094   263.3784 
1   5 
2.39883   347.463 
1   5 
2.398833   347.463 
1   5 
2.39883   347.4633 
1   5 
2.400698   460.0195 
1   5 
2.4007   460.0195 
1   5 
2.400698   460.02 
1   5 
2.402307   607.737 
1   5 
2.40231   607.737 
1   5 
2.402307   607.7376 
1   5 
2.402628   803.3544 
1   5 
2.402631   803.3544 
1   5 
2.402628   803.3552 
1   5 
2.401907   1064.696 
1   5 
2.40191   1064.696 
1   5 
2.401907   1064.697 
1   5 
2.40093   1410.818 
1   5 
2.400932   1410.818 
1   5 
2.40093   1410.82 
1   5 
2.400309   1867.498 
1   5 
2.400312   1867.498 
1   5 
2.400309   1867.5 
1   5 
2.40018   2472.678 
1   5 
2.400182   2472.678 
1   5 
2.40018   2472.68 
1   5 
2.400342   3274.803 
1   5 
2.400345   3274.803 
1   5 
2.400342   3274.807 
1   5 
2.400526   4337.063 
1   5 
2.400528   4337.063 
1   5 
2.400526   4337.068 
1   5 
2.400583   5744.95 
1   5 
2.400585   5744.95 
1   5 
2.400583   5744.956 
1   5 
2.400516   7614.76 
1   5 
2.400518   7614.76 
1   5 
2.400516   7614.767 
1   5 
2.400406   10070.54 
1   5 
2.400409   10070.54 
1   5 
2.400406   10070.55 
1   5 
2.400326   13348.79 
1   5 
2.400328   13348.79 
1   5 
2.400326   13348.81 
1   5 
2.4003   17633.92 
1   5 
2.400303   17633.92 
1   5 
2.4003   17633.94 
1   5 
2.400311   23459.06 
1   5 
2.400314   23459.06 
1   5 
2.400311   23459.09 
1   5 
2.40033   31364.98 
1   5 
2.400332   31364.98 
1   5 
2.40033   31365.01 
1   5 
2.400337   40283.39 
1   5 
2.40034   40283.39 
1   5 
2.400337   40283.43 
1   5 
2.400334   50589.66 
1   5 
2.400336   50589.66 
1   5 
2.400334   50589.71 
1   5 
2.400327   60895.93 
1   5 
2.40033   60895.93 
1   5 
2.400327   60895.99 
1   5 
2.400322   71202.19 
1   5 
2.400324   71202.19 
1   5 
2.400322   71202.27 
Fit Mean:  2.400322  Size:  71202.19  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  2.400322  Size:  71202.19  Code:  1  Try Size:  10 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
1 5
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
71202.19   2.400322 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 71202.19
> print(nb_fit_mu);
[1] 2.400322
> 
> print(m)
[1] 15.81818
> print(v)
[1] 278.9545
> print(D)
[1] 17.63506
> 
> print(deletion_propagation_coverage)
[1] 1
> 
> warnings()
> 
